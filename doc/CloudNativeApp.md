# 1 클라우드 네이티브

- 일반적으로 클라우드 네이티브란 클라우드 컴퓨팅을 활용하여 "**퍼블릭, 프라이빗 및 하이브리드 클라우드와 같은 현대적이고 동적인 환경에서 확장 가능한 애플리케이션 을 구축하고 실행**" 하는 소프트웨어 개발 방식을 의미한다.
- 2015년에 창설된 리눅스 재단 산하의 오픈소스 운영 기구로, 클라우드 네이티브 애플리케이션을 위한 다양한 오픈소스 프로젝트들을 주도하여 진행하는 CNCF(Cloud Native Computing Foundation)에서는 클라우드 네이티브를, **컨테이너화 가능한 오픈소스 소프트웨어 스택을 사용**하는 것을 의미한다고 정리하고 있다.
- 이러한 클라우드 네이티브를 기반으로 개발된 애플리케이션들은 **선언적 코드를 통해 배포되는 컨테이너(Container), 마이크로서비스(Microservice), 서버리스(Serverless) 기능 및 불변의 인프라(Immutable Infrastructure)와 같은 공통 기술 요소들을 포함** 하고 있다.
- 클라우드 네이티브 애플리케이션은 **상호운용성과 이식성을 향상** 시킬 수 있는 여러 가지 특징을 지니고 있다.

  

## 1.1 클라우드 네이티브 기술 특징

### 1.1.1  Container

- **클라우드 네이티브 애플리케이션을 위하 여 필수적으로 가장 먼저 도입 해야하는 기술은 컨테이너 기술**이라고 할 수 있다. 
- 컨테이너는 기존 클라우드 환경에서 많이 활용되는 가상 머신(Virtual Machine)처럼 애플리케이션과 관련된 라이브러리나 종속되는 항목들을 패키지로 묶어 서비스 구동을 위한 격리된 환경을 제공한다는 점에서 유사한 점이 있다. 
- **가상머신은 하드웨어 자원을** **하이퍼바이져라는 미들웨어를 통해 가상화시켜 가상화된 컴퓨팅 자원을 제공**하는 반면, **컨테이너는 운영체제 수준에서 가상화를 수행하여 다수의 컨테이너를 운영체제 커널에서 직접 구동**한다. 
- **컨테이너는 운영체제 커널을 공유**하여 훨씬 **가볍고 구동이 빠르며, 운영체제 전체 부팅보다 메모리를 훨씬 적게 차지**하게 된다.
- 컨테이너 기술은 운영체제와 독립적으로 분리되어 애플리케이션을 실행할 수 있도록 지원하므로, 동일한 **컨테이너 런타임만 사용한다면 어떤 클라우드 환경에서든 컨테이너를 자유롭게 이식**하여 실행시킬 수 있다.

![img](./assets/clip_image076.gif)

 

가상머신 VS 컨테이너



### 1.1.2  Docker 

- 가상머신 체계에서 가상화를 위해 하이퍼바이져가 하는 역할을 컨테이너 체계에서는 컨테이너 런타임이 한다고 볼 수 있다. 

- 컨테이너 생성 및 실행을 위한 다양한 컨테이너 런타임이 존재하며 그 중에서도 Docker는 최근까지도 많이 활용되고 있는 오픈소스 기술이다.

- Docker는 **컨테이너 정보를 Dockerfile로 관리**하고 이 코드를 기반으로 컨테이너 이미지의 복제 및 애플리케이션 배포가 이루어지기 때문에 애플리케이션을 쉽게 다시 빌드하고 배포할 수 있다. 
  
  -  Docker는 이미지 버전 관리, 레이어 구조를 갖는 이미지 포맷 제공, 도커 이미지 레지스트리, 프로그램이 가능한 다양한 기능의 API를 제공하는 등의 특징을 가지고 있다.
  
- 동일한 컨테이너 런타임 환경에서는 컨테이너의 이식이 자유롭게 가능하므로 Docker와 같은 활용도가 높은 컨테이너 런타임을 적용하면 이식성을 향상 시킬 수 있다.

  

### 1.1.3 Podman

-  2017년에 Docker가 엔터프라이즈 버전을 상용화하면서 레드햇은 또다른 컨테이너 오픈소스 기술인 Podman을 사용하여 레드햇의 엔터프라이즈 제품들을 출시하였다. 
- 2019년 3월에 릴리즈한 Red Hat Enterprise Linux 8에 Podman이 추가되었고 릴리즈 된 Red Hat OpenShift Container Platform 4와 Red Hat OpenStack Platform 16 모두 Docker에서 Podman으로 변경되었다.
- Podman은 **daemon 없이** 커맨드로 컨테이너 레지스트리로부터 이미지를 받아와 Podman 호스트의 로컬 이미지 저장소에 이미지를 저장하고, 해당 이미지를 이용하여 컨테이너를 실행하는 방식이다.
- 이때 podman 라이브러리를 통해 바로 컨테이너를 실행하기 때문에 **컨테이너 간에 서로 영향을 주지 않으며, 컨테이너와 이미지 사이, 커맨드 명령어로 컨테이너를 제어하거나 이미지를 관리할 때도 서로 영향을 주지 않는다**.



## 1.2  MSA(MicroService Architecture)

### 1.2.1  개요

- 대부분의 기업용 애플리케이션은 하나의 통합된 서비스 형태로 개발되어 왔다. **모놀리식(Monolithic) 아키텍쳐라고 불리는 이러한 단순한 애플리케이션의 구조 는 개발과 관리가 용이**하다는 장점이 있다.
- 애플리케이션의 종류가 다양해지고 여러 가지 기능을 제공하는 대규모 시스템이 생겨나면서 규모가 커질 경우 **복잡도가 증가해 코드의 분석과 통합이 어려워지고 작은 수정사항에도 전체를 빌드 배포해야하는 비효율이 발생하는 등의 개선과 확장이 어렵다는 단점**이 발생하게 되었다.
- **확장성에 초점을 맞추어 탄생한 아키텍쳐링 방법이 MSA**(MicroService Architecture)이다. 
  - MSA는 대용량 웹서비스가 많아짐에 따라 탄생한 아키텍쳐 인데 그 근간은 SOA(Service Oriented Architecture)에 두고 있다. SOA가 엔터 프라이즈 시스템을 중심으로 고안된 아키텍쳐라면, MSA는 SOA 사상에 근간을 두고, 대용량 웹서비스 개발에 맞는 구조로 사상이 경량화되고 대규모 개발팀의 조직 구조에 맞도록 변형된 아키텍쳐이다.
- **MSA는 경량화되고 독립적인 여러 개의 서비스를 조합하여 애플리케이션을 구현하는 방식으로 서비스마다 자체 데이터베이스를 가지고 동작할 수 있기 때문에 개발부터 빌드 배포까지 효율적으로 수행**할 수 있으며 **독립적인 서비스의 형태로 존재하기 때문에 이식성 측면에서 높은 효과**를 보인다.
- 각각의 서비스들은 독립적인 서비스로 볼 수 있으며 서로 호환성이 높도록 구현되어 있기 때문에 각각의 서비스 구현 과정에서 **공통된 데이터 포맷이나 표준 기반의 API를 동일하게 사용한다면 타 클라우드 서비스와도 높은 상호운용성 수준을 확보**할 수 있다.

> **MSA 구성은 기존 모놀로식 구조와 비교해서 결코 심플하지 않다. 하나의 서비스를 잘게 쪼갬으로써, 서비스 간 복잡도가 증가 될 수 있으며, 라우터, Circuit breaker, 각 서비스들의 관리 등 고려해야 할 것들이 기존보다 더 많아질 수도 있다. 그럼에도 불구하고 서비스들을 나누고 권한을 위임하면서, 고가용성, 유연한 스케일링, 빠르고 쉬운 배포 등의 큰 장점들이 있기 때문에 협업 부서가 많거나 규모가 좀 있는 시스템이라면 충분히 고려해 볼 만한 가치가 있다.**

 

## 1.3  오픈소스 생태계

https://landscape.cncf.io/

### 1.3.1  개요

- 활용도가 높은(또는 여러 애플리케이션에서 활용되는) **오픈소스의 도입은 표준 준용과 함께 상호운용성과 이식성 확보를 위한 대표적인 방법**이라고 할 수 있다.
- 최근 들어 **클라우드 네이티브 애플리케이션을 구성하기 위하여 필요한 기술들은 다양한 오픈소스들을 통해 구현되어 있으며, 이러한 오픈소스들이 모여 풍부한 오픈소스 생태계를 구축**하고 있다.
  - CNCF에서는 클라우드 네이티브 기술 구현을 위한 백여 가지 오픈소스 프로젝트들이 진행 중
- 풍부한 오픈소스 생태계를 통해 활용도가 높은 **오픈소스를 도입한다면 해당 솔루션을 사용한 애플리케이션 간의 상호운용성과 이식성 수준을 향상** 시킬 수 있다.

![image-20220830094110933](./assets/image-20220830094110933.png)

CNCF Cloud Native Landscape

 

### 1.3.2  쿠버네티스(Kubernetes, K8S)

- **쿠버네티스는 클라우드 네이티브 애플리케이션에서 활용되는 대표적인 오픈소스 중 하나로 이미 산업 표준(De-facto Standard)이라 할 만큼 널리 활용**되고 있는 솔루션이다.
- 쿠버네티스는 클라우드 환경의 컨테이너 기반 인프라를 추상화하여 하위에 어떤 클라우드가 있는지 종류에 상관없이 쿠버네티스 상에 애플리케이션을 배포하고 관리가 가능하다. 
  - 최근에는 주요 클라우드 벤더는 **관리형 쿠버네티스 서비스(Amazon Kubernetes Service, Google Kubernetes Engine, Azure Kubernetes Service, NCP(Naver Cloud Platform) - Kubernetes Services 등)를 제공**하고 있으므로 쿠버네티스 기반으로 구성된 애플리케이션의 경우에는 쿠버네티스 환경만 지원한다면 높은 이식성을 확보할 수 있다.

 

##  1.3. 클라우드 네이티브 애플리케이션 체크리스트

![image-20220830094307915](./assets/image-20220830094307915.png)

 

![image-20220830094337378](./assets/image-20220830094337378.png)



## 1.4 클라우드 네이티브 애플리케이션 기술

- 클라우드 컴퓨팅 환경이란, 클라우드 공간에 가상화된 공유자원을 사용자의 요구에 따라 할당하고 해제할 수 있는 동적인 컴퓨팅 환경을 말하며, 클라우드에서 제공하는 **서비스의 유형에 따라서, Publilc 클라우드, Private 클라우드, Hybrid 클라우드** 등의 환경으로 나뉜다.

- 클라우드 컴퓨팅 모델의 장점을 가지고 개발된 애플리케이션을 클라우드 네이티브 애플리케이션이라 하며, **클라우드 네이티브 애플리케이션이 가져야 하는 특징**은 다음과 같다.

  ◾  서비스 및 API 기반의 개발을 보다 민첩하게 처리

  ◾  구현된 결과물을 지속적이고 자동으로 배포할 수 있는 시스템 구축

  ◾  개발 및 운영팀과의 효율적인 커뮤니케이션

  ◾  보다 발전된 모듈식 아키텍처의 구성

  ◾  사용자의 요구에 따른 수평적 확장 가능

  ◾  ‘개발 → 테스트 → 프로덕션’과 같은 여러 형태의 운영 및 테스트 환경 지원

  ◾  모든 인프라에서 DevOps의 협업 시스템을 통해 애플리케이션 이식성 제공

 

### 1.4.1  클라우드 네이티브 애플리케이션의 정의

- **클라우드 네이티브 애플리케이션은 기존 및 새로운 소프트웨어 개발 패턴의 조합**이라 고 볼 수 있다. 
- 기존 패턴을 소프트웨어 자동화(인프라 및 시스템), API 통합 및 서비스 지향의 아키텍처라고 한다면, **클라우드 네이티브 패턴은 마이크로 서비스 아키텍처, 컨테이너화된 서비스, 분산 관리 및 오케스트레이션**으로 구성되어 있다. 
- **클라우드 네이티브 애플리케이션을 성공적으로 개발하려면 클라우드 네이티브 아키텍처에 의해 설계하는 것과 개발된 애플리케이션이 인프라에 미치는 영향을 이해**하는 것이 중요하다.

> **클라우드 네이티브는 개발자가 담당해야하는 개발 대한 범위가 넒어졌고 공부할께 많아졌지만 완결적으로 서비스를 출시할 수 있는 기반을 제공한다.**



### 1.4.2 클라우드 네이티브 애플리케이션의 특성

- PC 가상화 솔루션을 제공하는 VMWare에서는 **DevOps, CI/CD, 마이크로 서비스, 컨테이너 기술**을 클라우드 네이티브 애플리케이션을 구성하는 4가지 주요 기술 이라고 소개 하였다. 

- 클라우드 네이티브 애플리케이션은 조직 내 인력과 이들의 **협업 프로세스를 자동화**하는 것에서 시작되며, **DevOps를 도입하여 공통의 목적을 가지고 주기적인 피드백을 통해 개발팀과 운영팀의 협업**을 지원할 수 있어야 한다.

 

![img](./assets/1-1.jpg)

클라우드 네이티브 애플리케이션 구성요소

 

- 컨테이너 가상화 기술을 도입하면 이상적인 **애플리케이션 배포 및 각 서비스에 대한 독립적인 실행 환경을 제공**할 수 있으며, 하나의 대규모 릴리스 및 업데이트가 아닌 **수많은 마이크로서비스가 탄력적으로 결합된 하나의 컬렉션 형태로 애플리케이션을 쉽게 릴리스 및 업데이트**할 수 있게 된다.

- 클라우드 네이티브 애플리케이션의 개발은 **아키텍처의 모듈의 독립성, 탄력적인 결합 그리고 독립적인 서비스에 중점**을 둔다. 

- 애플리케이션을 구성하는 각 **마이크로서비스는 비즈니스 로직을 구현하고 자체 프로세스로 실행되며, 서비스간에 또는 다른 애플리 케이션 간에 애플리케이션 프로그래밍 인터페이스(Application Programming Interfaces, API) 나 메시지 큐잉(Message Queuing) 방식을 통해 커뮤니케이션** 하게 된다. 

- 이러한 커뮤니케이션은 마이크로서비스 아키텍처에서 서비스 메쉬 레이어(Service Mesh Layer)를 통해 관리할 수 있다.

  - ISTIO
  
  

### 1.4.4  12 Factors

https://12factor.net/ko/

  ![img](./assets/V9nAWbd-c9635361688ff77f82ccc7b1bdefd891.png)

- **12 Factors란, 클라우드 플랫폼 제공 회사인 헤로쿠(Heroku)라는 기업에서 자사의 클라우드 플랫폼 모델을 사용하는 기업들의 애플리케이션 개발, 운영, 확장 등을 관찰하고, 개발 엔지니어와 개발 회사로부터의 얻은 노하우를 바탕으로 정리한 개발 방법론**이자 안내서이다. 
-  **클라우드 플랫폼의 일반적인 동적 환경 프로비저닝 요구 사항을 충족하도록 애플리케이션을 이식 가능하게 만드는것**이다.
  - **선언적 형식** 을 사용하여 설정을 자동화한다.
  - 실행 환경 **간 이식성 극대화**
  - **Cloud Platform** 에 배포하기에 적합
  - 민첩성을 극대화하기 위해 지속적인 배포를 가능하게 하여 **개발과 생산 간의 차이 최소화**
  - 도구, 아키텍처 또는 개발 방식을 **크게 변경하지 않고 확장할** 수 있는 능력 .



#### 1)  Codebase - 모든 환경에 대한 버전 관리를 받는 단일 코드베이스

> 계정 제어에서 추적되는 하나의 코드베이스, 많은 배포.

- **이는 단일 개인 또는 그룹과 함께 애플리케이션의 명확한 소유권을 설정하는 데 도움이 된다.** 애플리케이션에는 새로운 기능, 결함 수정 및 기존 기능에 대한 업그레이드로 발전하는 단일 코드베이스가 있다. 애플리케이션 소유자는 애플리케이션 수명 동안 다양한 버전을 빌드하고 테스트, 스테이징 및 프로덕션과 같은 여러 환경에 배포할 책임이 있다.

- 이 원칙은 여러 환경에 구축 및 배포할 수 있는 단일 코드베이스를 갖는 것을 옹호한다. 각 환경에는 데이터베이스, 구성 데이터 및 API URL과 같은 특정 리소스 구성이 있다. 이를 달성하려면 모든 환경 종속성을 애플리케이션의 빌드 및 실행 단계에서 지정할 수 있는 형식으로 분리해야 한다.

- 이는 선언적 형식을 사용하여 환경 간 이식성을 극대화하는 Twelve-Factor App의 처음 두 가지 목표를 달성하는 데 도움이 된다..

- **이 원칙에 따라 Spring Boot 애플리케이션의 소스 코드를 포함하는 단일 Git 리포지토리를 갖게 됩니다. 이 코드는 컴파일 및 패키징된 다음 하나 이상의 환경에 배포된다.**

- [Spring 프로필](https://reflectoring.io/spring-boot-profiles/) 및 [환경별 속성](https://reflectoring.io/profile-specific-logging-spring-boot/) 을 사용하여 런타임 시 특정 환경에 대한 애플리케이션을 구성한다.

> **특정 환경에 맞게 구성하기 위해 소스 코드를 변경해야** 하거나 개발 및 프로덕션과 같은 다양한 환경에 대해 별도의 리포지토리가 있는 경우 이 규칙을 위반하는 것이다.

```sh
git init
git add .
git commit -m "Adding the bootstrap of the application."
git remote add origin https://github.com/<username>/12-factor-app.git
git push -u origin master
```

#### 2) Dependencies

> 종속성을 명시적으로 선언하고 격리한다..

- **종속성은 애플리케이션 간에 코드를 재사용하기 위한 지침을 제공한다. 재사용 가능한 코드 자체는 단일 코드베이스로 유지되지만 라이브러리 형태로 패키지화되어 여러 애플리케이션에 배포된다.**

- 애플리케이션의 가장 가능성 있는 종속성은 오픈 소스 라이브러리 또는 다른 팀에서 사내 구축한 라이브러리이다. 종속성은 호스트 시스템에 설치된 특정 소프트웨어의 형태를 취할 수도 있다. 플랫폼의 종속성 관리 도구를 활용하여 외부 파일에 종속성을 선언한다.

- Spring Boot 애플리케이션의 경우 파일에 종속성을 선언 `pom.xml`한다.(또는 `build.gradle`Gradle을 사용하는 경우). `spring-boot-starter-web`다음은 종속성 중 하나로 사용하는 Spring Boot 애플리케이션의 예이다.

```xml
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
```

- 이 원칙은 공유 클래스 경로에 라이브러리를 저장하여 애플리케이션 간에 라이브러리를 공유하는 이전 관행에서 발전된 것이다. 이 접근 방식을 사용하면 호스트 시스템 구성과의 결합이 발생하게 된다.

- 종속성을 지정하는 선언적 스타일은 이 결합을 제거한다.

- Spring Boot를 사용하는 맥락에서 Maven/Gradle과 같은 종속성 도구를 사용할 때 다음을 장점을 제공한다.
  - 애플리케이션이 작동하는 종속성의 특정 버전을 선언하여 **버전 관리**

  - 애플리케이션과 종속성을 번들링하여 **격리 .**

  

#### 3) Configurations - Configuration Properties의 외부화

> 환경에 구성을 저장한다..

- 환경이 클라우드에서 동적으로 프로비저닝 될때 결정이 되므로 애플리케이션을 개발하는 동안 사용할 수 있는 Configuration Properties가 거의 없다.

- **Configuration Properties을 환경 변수로 분리하면 코드 변경 없이 애플리케이션을 다른 환경에 쉽고 빠르게 배포할 수 있다.**

- Configuration 의 몇 가지 예는 데이터베이스 연결 URL 및 자격 증명, 응용 프로그램이 의존하는 서비스의 URL이다. 

- 이 정보는 환경에 따라 다른 값을 가지는 경우가 많으며 이 정보가 애플리케이션과 함께 번들로 제공되는 코드 또는 속성 파일에 하드 코딩되어 있는 경우 다른 환경에 배포하기 위해 애플리케이션을 업데이트해야 해야하는 상황이 발생한다.

- 대신 환경 변수를 사용하여 Configuration을 외부화 하는 것이 더 나은 방법이다.  

- 환경 변수의 값은 런타임에 제공되며 애플리케이션이 독립 실행형으로 실행되는 경우 명령줄에서 값을 제공할 수 있다.

  ```properties
  spring.datasource.url=jdbc:mysql://${MYSQL_HOST}:${MYSQL_PORT}/movies
  spring.datasource.username=${MYSQL_USER}
  spring.datasource.password=${MYSQL_PASSWORD}
  ```

- Spring Boot 애플리케이션의 기본 동작은 환경 변수의 값을 적용하여 속성 파일에 선언된 모든 값을 재정의 하는 것이다.

  ```properties
  set MYSQL_HOST=localhost
  set MYSQL_PORT=3306
  set MYSQL_USER=movies
  set MYSQL_PASSWORD=password
  ```

-  Configuration Properties 을 사용하여 코드에서 구성 매개변수를 사용할 수 있다.

#### 4) Backing Services - 플러그인형 데이터 소스 및 대기열

> 지원 서비스를 연결된 리소스로 취급한다.

- **이 원칙은 애플리케이션을 크게 변경하지 않고 지원 서비스 구현을 변경할 수 있는 유연성을 제공한다.**

- 플러그인형  RDBMS 데이터 소스를 통해 JPA와 같은 추상화를 사용하고 연결을 구성하기 위해 Configuration Properties(예: JDBC URL)을 사용하여 가장 잘 달성할 수 있다.

  ```java
  @Repository
  public interface MovieRepository extends JpaRepository<Movie, Long> {
  }
  ```

- 이런 식으로 JDBC URL을 변경하여 데이터베이스를 교체할 수 있다. 그리고 종속성을 변경하여 기본 데이터베이스를 교체할 수 있다.

- H2 데이터베이스에 대한 종속성의 스니펫은 다음과 같다.

```xml
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-jpa</artifactId>
    </dependency>
    <dependency>
      <groupId>com.h2database</groupId>
      <artifactId>h2</artifactId>
      <scope>runtime</scope>
    </dependency>
```

- H2 데이터베이스를 Oracle 또는 MySQL과 같은 다른 RDBMS로 쉽게 교체할 수 있다. JPA와 유사하게 메시징에는 JMS를, 메일에는 SMTP를 사용할 수 있다.

#### 5) Build, Release and Run - 개발 워크플로를 위한 컨테이너 활용

> 빌드 및 실행 단계를 엄격하게 분리한다.

- **빌드, 릴리스 및 실행 단계를 별도로 유지해야 한다. 이 분리는 응용 프로그램 충실도와 무결성을 유지하는 데 중요하다.**

- 이러한 단계는 순서대로 발생한다. 각 단계는 다른 목표를 갖고 다음 단계로 전파되는 아웃풋을 생성한다.

- 긴급 수정을 포함한 모든 코드 변경은 빌드 단계에서 발생해야 하며 프로덕션으로 승격되기 전에 설정된 릴리스 주기를 따라야 한다. 예를 들어 프로덕션 환경에서 작은 수정을 함으로써 이 원칙을 위반하면 빌드 단계로 전파하기 어렵게 만들고 기존 분기를 방해하며 무엇보다도 이 관행을 따르는 데 따른 위험과 전체 비용을 증가시킨다.

- Spring Boot 애플리케이션의 경우 컨테이너용 개발 워크플로우를 사용하여 쉽게 달성할 수 있다.
  - **Build** : 소스 코드를 컴파일하고 Docker 이미지를 빌드한다.

    ```shell
    mvn clean compile jib:build
    or
    mvn clean package
    docker build <image_id> Dockerfile
    ```

  - **릴리스** : 이미지에 태그를 지정하고 레지스트리에 푸시한다.

    ```
    docker tag <image_id> <image_registry>/<image_id>
    docker push <image_registry>/<image_id>
    ```

  - **실행** : 레지스트리에서 이미지를 가져와 컨테이너 인스턴스로 실행한다.

    ```
    docker run --name <container_id> -it <image_id>
    or
    kuebctl apply -f menifest.yaml
    ```

- 이런 기술을 활용하여 컨테이너를 사용하여 애플리케이션을 패키징하고 실행하는 경우 이 Twelve-Factor App 원칙을 준수하기 위해 애플리케이션을 변경할 필요가 없다.



#### 6) Processes - 상태 비저장 애플리케이션

> 앱을 하나 이상의 상태 비저장 프로세스로 실행한다.

- **상태 비저장 프로세스는 애플리케이션이 트래픽의 급격한 증가를 처리하기 위해 빠르게 확장하고 시스템에 대한 트래픽이 감소할 때 축소할 수 있는 기능을 제공한다.**
-  상태 비저장으로 만들려면 모든 데이터를 애플리케이션 외부에 저장해야 한다..

- Spring Boot 애플리케이션은 호스트 시스템 또는 Docker와 같은 컨테이너 런타임 환경 내부에서 Java 프로세스로 실행된다. 이 원칙은 프로세스가 무상태(stateless)이고 무공유(share-no)여야 한다.
-  지속해야 하는 모든 데이터는 데이터베이스와 같은 상태 기반 지원 서비스에 저장해야 한다.

- 이것은 응용 프로그램 프로세스의 메모리에 사용자 세션 데이터를 캐시하고 동일한 세션의 향후 요청이 동일한 프로세스로 라우팅될 것으로 예상하는 웹 응용 프로그램에서 "고정 세션"을 사용하는 방법에서 전환된 것이다.

- 고정 세션은 12 Factors을 위반하는 것이다. 세션 상태 데이터는 Memcached/Caffeine 또는 Redis와 같이 시간 만료를 제공하는 데이터 저장소의 애플리케이션 외부에 저장되어야 한다.



#### 7) Port Binding - 환경 속성으로 정의된 포트

> 포트 바인딩을 통해 서비스를 노출한다.

- **포트 바인딩은 특정 포트에 자신을 바인딩하고 해당 포트에서 관심 있는 소비자의 모든 요청을 수신하는 응용 프로그램을 지칭한다.**
-  포트는 환경 변수로 선언되어 실행 중에 제공된다.

- 이 원칙에 따라 구축된 애플리케이션은 웹 서버에 의존하지 않는다. 응용 프로그램은 완전히 독립적이며 독립 실행형으로 실행됩니다. 웹 서버는 라이브러리로 패키지되어 애플리케이션과 함께 번들로 제공한다.

- 포트 바인딩은 마이크로 서비스가 자율적이고 독립적이어야 하는 기본 요구 사항 중 하나이다.

- Spring Boot는 애플리케이션에 Tomcat을 포함하고 포트에 바인딩하고 해당 포트로 들어오는 요청을 수신하여 HTTP를 서비스로 노출한다.
  - `server.port`Configuration Properties 을 설정하여 포트를 구성할 수 있다.(기본값은 8080)

```
java -jar application.jar
```



#### 8) Concurrency - 확장을 지원하는 상태 비저장 애플리케이션

> 프로세스 모델을 통해 확장하여야 한다.

- 전통적으로 애플리케이션이 용량 한계에 도달할 때마다 해결 방법은 RAM, CPU 및 기타 리소스를 추가하여 용량을 늘리는 것이다.(수직 확장이라고 하는 프로세스).

- 반면 수평적 확장 또는 "확장"은 클라우드 환경의 탄력적인 확장성과 잘 작동하도록 하는 보다 현대적인 접근 방식이며 **하나의 프로세스를 더 크게 만드는 대신 여러 프로세스를 만든 다음 이러한 프로세스 간에 응용 프로그램의 로드를 분산한다.**

- Spring Boot는 이 요소에 많은 도움이 되지 않는다. 애플리케이션이 상태 비저장인지 확인해야 하므로 증가된 로드를 지원하기 위해 많은 동시 작업자로 확장할 수 있다. 모든 종류의 상태는 애플리케이션 외부에서 관리해야 한다.

- 또한 **특정 프로세스를 독립적으로 확장하려면 애플리케이션을 여러 개의 더 작은 애플리케이션(예: 마이크로서비스)으로 분할해야 한다. 확장은 Kubernetes 및 Docker Swarm과 같은 컨테이너 오케스트레이션 시스템에서 처리**한다.



#### 9) Disposability - 임시 컨테이너 활용

> 빠른 시작 및 단계적 종료로 견고성을 극대화한다.

- **응용 프로그램의 일회용 기능을 사용하면 빠르게 시작하거나 중지할 수 있다.**

- 안정적인 상태가 되어 정상적으로 종료되는 데 오랜 시간이 걸리면 애플리케이션을 빠르게 확장, 배포 또는 복구할 수 없다. 애플리케이션의 로드가 증가하고 해당 로드를 처리하기 위해 더 많은 인스턴스를 가져와야 하는 경우 시작 지연은 애플리케이션이 시작되는 동안 요청 거부를 의미할 수 있다.

- Spring Boot 애플리케이션은 일회용으로 만들기 위해 컨테이너 내부에서 실행되어야 한다. 컨테이너는 임시적이며 언제든지 시작하거나 중지할 수 있다.

- 따라서 시작 시간을 최소화하고 컨테이너가 중지될 때 애플리케이션이 정상적으로 종료되도록 하는 것이 중요한다. 종속 리소스의 지연 초기화와 [최적화된 컨테이너 이미지](https://reflectoring.io/spring-boot-docker/) 를 구축하여 시작 시간을 최소화 한다.



#### 10) Dev/Prod Parity - 한 번 빌드 - 어디든지 실행

> 개발, 준비 및 프로덕션을 가능한 한 유사하게 유지한다.

- **dev/prod Parity의 목적은 애플리케이션이 변경 없이 이상적으로 모든 환경에서 작동하도록 하는 것이다.**

- 환경 간 코드 이동은 전통적으로 개발 속도를 늦추는 주요 요인이며 개발 및 생산에 사용되는 인프라의 차이에서 발생한다.

- 컨테이너를 사용하면 한 번 빌드하고 여러 대상 환경으로 이동할수 있으며 OS를 포함한 모든 종속성을 패키징할 수 있다.

- Spring Boot 애플리케이션은 Docker 컨테이너에 패키징되어 Docker 레지스트리에 푸쉬되며  Docker 파일을 사용하여 Docker 이미지를 생성하는 것 외에도 Spring Boot는 Cloud-Native 빌드팩을 사용하여 소스에서 OCI 이미지를 빌드 하기 위한 플러그인을 제공한다.



#### 11) Logs - 이벤트 스트림으로 로그 게시

> 로그를 이벤트 스트림으로 취급한다.

- **애플리케이션은 일련의 이벤트로만 로그를 생성해야 한다.** 
- 클라우드 환경에서는 애플리케이션을 실행하는 인스턴스에 대한 지식이 제한적이며 탄력적 확장 중에 인스턴스를 만들고 종료할 수도 있다.
- 호스트 인스턴스의 파일 시스템에 저장된 로그를 기반으로 하는 애플리케이션 진단 프로세스는 지루하고 오류가 발생하기 쉽다.
- 따라서 추가 분석을 위해 로그를 저장, 집계 및 다른 시스템으로 전달하는 책임은 기본 클라우드 플랫폼에서 사용할 수 있는 특수 목적 소프트웨어 또는 관측 가능성 서비스에 위임되어야 한다.
- 또한 애플리케이션의 로그 출력 프로세스를 단순화하면 코드베이스를 줄이고 애플리케이션의 핵심 비즈니스 가치에 더 집중할 수 있다.
- Spring Boot는 기본적으로 콘솔에만 기록하고 로그 파일을 작성하지 않으며 기본 Logger 구현으로 Logback으로 사전 구성된다.
- Logback은 로그 appender, filter, shipper로 구성된 풍부한 생태계를 가지고 있으므로 많은 모니터링 및 시각화 도구를 지원한다. 이 모든 것은 [Spring boot에서 로깅을 구성](https://reflectoring.io/springboot-logging/) 하는 데 자세히 설명되어 있다.



#### 12) Admin Processes - API로 구축되고 애플리케이션과 함께 패키징됨

> 관리/관리 작업을 일회성 프로세스로 실행한다.

- **대부분의 응용 프로그램은 관리 및 관리를 위해 일회성 작업을 실행해야 한다.** 
  - 일반적으로 python 및 C와 같은 언어에 더 적합한 REPL(Programmatic Interactive Shell) 사용을 권장지만 클라우드네이티브 환경에서는 변화가 필요하다.
- 관리 작업의 예로는 데이터베이스를 초기화하기 위한 데이터베이스 스크립트 또는 잘못된 레코드를 수정하기 위한 스크립트가 있다.
-  Twelve-Factor App의 원래 목표인 최대 이식성 빌드에 따라 이 코드는 애플리케이션과 함께 패키지화되어 함께 릴리스되어야 하며 동일한 환경에서도 실행되어야 한다.
- Spring Boot 애플리케이션에서 관리 기능을 일회성 프로세스로 호출되는 별도의 Endpoint로 노출하는 형태 또는 Spring  Batch를 사용 하여 청크단위로 일회성 프로세스를 실행할 수 있다.
- 이 기능을 추가하는 것도 동일하게 빌드, 테스트 및 릴리스 주기를 거쳐야 한다.



#### 1.4.5 결론

| Factor           | 적용방법                                                     |
| ---------------- | ------------------------------------------------------------ |
| 코드베이스       | 모든 환경에 대해 하나의 코드베이스를 사용한다.               |
| 종속성           | `pom.xml`또는 의 모든 종속성을 선언합니다 `build.gradle`.    |
| 구성             | 환경 변수를 사용하여 구성을 외부화 한다.                     |
| 지원 서비스      | JPA와 같은 추상화를 사용하여 플러그형 서비스를 구축한다.     |
| 빌드/릴리스/실행 | Docker 이미지를 빌드하고 게시한다.                           |
| 프로세스         | 상태 비저장 서비스를 구축하고 모든 상태 정보를 애플리케이션 외부(예: 데이터베이스) 외부에 저장한다. |
| 포트 바인딩      | `server.port`환경 변수 로 포트를 구성 한다.                  |
| 동시성           | 더 작은 상태 비저장 애플리케이션(마이크로서비스)을 구축한다. |
| 일회용           | 컨테이너 이미지에 애플리케이션을 패키징한다.                 |
| 개발/제품 패리티 | 컨테이너 이미지를 빌드하고 여러 환경에 제공한다.             |
| 로그             | 중앙 로그 수집기에 로그를 게시한다.                          |
| 관리 프로세스    | API 엔드포인트/실행인수로 일회성 프로세스를 구축한다.        |



### 1.4.5 15 Factors

- 2016년에는 클라우드 플랫폼 회사 피보탈(Pivotal)의 엔지니어인 케빈 호프만(Kevin Hoffman)이 최신 트렌드에 맞는 사용자의 요구 사항을 반영하여 헤로쿠의 12 Factors 에 3가지의 요소를 추가하였다15). 새롭게 추가된 내용은 아래와 같다.

  **13) API 우선(API First): API 설계를 우선하여, 코드를 작성하기 이전에 설계하고자 하는 서비스의 의도와 기능을 명확하게 할 수 있음. API 설계로 Web이나 모바일 뿐만 아니라 API를 이용하려는 다른 서비스간에도 커뮤니케이션 가능**

  **14) 관측(Telemetry): 애플리케이션 성능 모니터링, 애플리케이션이 처리하는 초당 HTTP 요청의 평균 개수 등과 같이 비즈니스에 의미 있는 예측 분석을 위해 이벤트 및 데이터 수집**

  **15) 인증과 권한(Authentication and Authorization): 애플리케이션의 리소스에 대한 모든 요청에 대해 누가 요청을하고 있는지, 해당 사용자가 적절한 역할을 가지고 작업을 수행할 권한을 부여할지 여부를 결정**

- 케빈 호프만은 3가지의 새로운 내용을 추가하면서 기존 12 Factors의 우선순위를 다음과 같이 변경하는 것을 제안하였다.

  1) 코드 베이스(One Codebase, One Application)

  2) API 우선(API First)

  3) 종속성(Dependency Management)

  4) 빌드, 릴리스, 실행(Design, Build, Release, Run)

  5) 설정(Configuration, Credentials)

  6) 로그(Logs)

  7) 폐기 가능(Disposability)

  8) 벡엔드 서비스(Backing Services)

  9) 개발, 프로덕션 환경 일치(Environment Parity)

  10) 관리 프로세스(Administrative Processes)

  11) 포트 바인딩(Port Binding)

  12) 무상태 프로세스(Stateless pProcesses)

  13) 동시성(Concurrency)

  14) 관측(Telemetry)

  15) 인증과 권한(Authentication and Authorization)

 

## 1.5 모놀리스와 클라우드 네이티브 애플리케이션의 차이점

 <img src="./assets/image-20220810135438142.png" alt="image-20220810135438142" style="zoom:150%;" />

모놀리스와 마이크로서비스 아키텍처의 차이

  

### 1.5.1  모놀리스 아키텍처

- 모놀리스 아키텍처에 의해 개발되는 애플리케이션의 대부분은 장기간에 걸쳐 순차적 으로 진행되는 폭포수(waterfall) 개발 방식으로 구축된다. 애플리케이션 자체가 하나의 구성으로 이뤄져 있는 경우가 대부분이며 일반적으로 다음과 같이 3개의 주요 부분으로 구성되었다. 

  ◾ **클라이언트 사이드 UI(Front-end)**: HTML 페이지와 사용자 단말기의 브라우저 에서 실행되는 자바스크립트와 같은 프로그래밍 언어

  ◾  **데이터베이스(Database)**: 애플리케이션에서 사용되는 데이터가 저장되는 저장소, 일반적으로 관계형 데이터베이스를 사용하며, 사용자의 요구사항에 의해 도출된 도메인에 의해 여러 개의 테이블로 구성

  ◾  **서버 사이드 애플리케이션(Server side application, Back-end)**: 클라이언트의 요청에 따라, 비즈니스 로직을 실행하며 데이터베이스와의 연동 작업을 통해, 사용자의 요청 UI에게 결과 값이나 뷰(View) 페이지를 전달(예, 사용자가 웹 브라우저를 이용하는 경우에 HTML 페이지를 위한 뷰 생성)

- 위에서 언급한 3개의 주요 부분을 **하나의 애플리케이션에 구현한 것을 모놀리스 애플리케이션**이라 한다.

- 구현된 애플리케이션을 배포하기 위해서는 먼저, 개발자의 컴퓨터에서 단위 테스트를 실행하고, 테스트 환경에서 사용자 테스트를 수행한 다음, 최종 프로덕션 환경에 배포하게 된다. 이러한 배포 과정은 배포 파이프라인(Deploy Pipeline)을 통해 자동화 시킬 수 있으며, 여러 인스턴스들 앞에 로드 밸런서(Load Balancer)를 두어 사용자의 요청을 분산 처리하여 실행할 수도 있다.

- **모놀리스 애플리케이션은 시스템 또는 서비스 간에 긴밀하게 결합(coupling)**되어 개발 되었다. 사용자 인터페이스 및 다양한 애플리케이션 서비스, 데이터 액세스 코드 및 기타 구성 요소들이 기술 환경에 상관없이 결합되어, 대규모의 다목적 애플리케이션 형태로 구축되었다.

- 모놀리스 아키텍처로 구현된 **단일 애플리케이션은 시스템을 구축하기 쉽다는 장점**을 가지고 있지만, **애플리케이션의 작은 부분을 변경할 경우라도 전체 애플리케이션을 다시 빌드**해야 한다. 

- 애플리케이션을 운영하는 시간이 길어질수록 단순화된 모듈 구조를 유지하기 어려워지며, **특정한 모듈의 변경하려고 해도, 관련이 없는 전체 애플리케이션을 다시 배포** 해야 한다. 

- 모놀리스 애플리케이션의 인프라는 애플리케이션에 필요한 최대 용량을 예측하여 사전에 사용할 수 있는 리소스가 미리 결정되어 준비되기 때문에, 애플리케이션이 운영되고 있는 시스템의 성능을 높이기 위한 스케일링(Scaling) 작업에서도, 필요한 부분만큼의 자원을 늘리는 것이 아니라, **수직적 확장(Scale up)을 통해 서버의 하드웨어 용량을 높이는 확장**이 이루어져야 하는 단점을 가지고 있었다.

 

### 1.5.2  마이크로서비스 아키텍처

- 마이크로서비스 아키텍처는 소프트웨어 애플리케이션을 독립적으로 배치 가능하도록 서비스를 조합하고 설계하는 개발 방법을 말한다. 마이크로서비스의 창시자인 제임스 루이스(James Lewis)와 마틴 파울러(Martin Fowler)는 마이크로 서비스에 대해 다음과 같이 정의하였다.

> “간단히 말해서 마이크로 서비스 아키텍처 스타일은 단일 애플리케이션을 작은 서비스들의 모음으로 개발하려는 접근 방식으로, 각각의 서비스는 자신만의 프로세스로 실행되고 HTTP 리소스 API와 같은 경량 메커니즘을 사용하여 통신한다. 이러한 서비스는 비즈니스 기능을 중심으로 구축되며 완전히 자동화된 배포 시스템을 통해 독립적으로 배포할 수 있다. 이러한 서비스들은 중앙 집중식 관리를 최소로 하고 있으며, 다양한 프로그래밍 언어로 개발되고 다른 데이터 저장 기술을 사용한다.”

위에서 언급된 내용 중 핵심적인 사항을 살펴보면, 다음과 같이 정의 내릴 수 있다.

​	◾  적절하게 나뉜 작은 서비스

​	◾  독립적인 프로세스로 운영

​	◾  비즈니스 중심으로 구축되고 독립적인 배포가 가능

​	◾  중앙 집중 관리의 최소화

​	◾  다른 언어와 다른 데이터 저장 기술로 작성

- **마이크로서비스 아키텍처 스타일은 하나의 애플리케이션을 작은 서비스 군의 조합으로 구축하는 방법을 말하며, 개별 서비스는 독립적인 프로세스로 실행되며, HTTP 프로토콜을 이용하는 리소스(Resource) API 등을 통해 통신**하게 된다.
-  **서비스는 비즈니스 수행 능력에 맞게 구분되며(DDD), 자동화된 매커니즘을 통해 관리된다. 최소의 중앙 통제적인 관리를 받으며, 각각의 서비스는 서로 다른 프로그래밍 언어와 다른 데이터 저장 기술을 통해 개발**될 수도 있다.



# 2. 네이티브 클라우드 기술스택

## 2.1.  클라우드 네이티브 아키텍처

### 2.1.1  클라우드 네이티브 아키텍처와 기술

- **클라우드 컴퓨팅 환경에서 확장 가능한 애플리케이션을 개발하고 운영하기 위한 기술을 통틀어 클라우드 네이티브 기술**이라 하며, 클라우드 네이티브 기술을 이용하여 구현되는 애플리케이션 및 서비스를 위한 설계나 계획을 클라우드 네이티브 아키텍처라 한다.

- 클라우드 네이티브 기술의 대표적인 예로 **컨테이너, 서비스 메쉬(Service Mesh), 마이크로 서비스(MicroService), 불변의 인프라스트럭쳐(Immutable Infrastructure), 선언적 API (Declarative API)** 등이 있으며, 클라우드 네이티브 기술들을 이용해 서비스 하고자 하는 애플리케이션에 대해 **적은 리소스의 사용, 회복성, 관리능력 및 느슨하게 연결된 모듈 등의 효과를 제공**할 수 있을 뿐만 아니라, 자**동화된 인프라의 구성으로 시스템의 변경 및 개선 사항을 최소한의 노력으로 더 자주 배포**할 수 있다.

- CNCF에서는 클라우드 네이티브 아키텍처가 다음과 같은 속성을 갖도록 구성되어야 한다고 정의 하였다.

  ◾  애플리케이션 또는 프로세스는 컨테이너 가상화 기술에 의해 분리된 단위로 실행

  ◾  애플리케이션을 구성하는 프로세스는 리소스 사용을 개선하고 유지보수 비용을 줄이기 위해 중앙 오케스트레이션 프로세스에 의해 동적으로 관리

  ◾  애플리케이션 또는 서비스(마이크로서비스)는 명시적으로 기술된 종속적인 각 항목들과 느슨하게 결합

 

### 2.1.2 클라우드 네이티브 아키텍처의 기술 스택

- 클라우드 네이티브 아키텍처를 구성하는 각각의 기술 스택들은 **애플리케이션을 보다 빠르게 개발하고, 관리하기 쉽도록 모니터링 기술을 지원하며, 클라우드 상에 배포되는 시간을 단축하여, 더 자주 배포하는 것을 목표**로 한다. 
- CNCF의 TOC(Technical Oversight Committee) 대표인 Ken Owens는 이러한 클라우드 네이티브 관련 기술 스택들 간의 호환성과 표준화를 위해 다음과 같은 클라우드 네이티브 참조 아키텍처를 제시하였다.

 ![img](./assets/clip_image115.jpg)

 클라우드 네이티브 참조 아키텍처



1) **Application Definition/Development**: 컨테이너 네이티브 애플리케이션을 구현하는데 필요한 메타데이터, 설정, 도구, 컨테이너 이미지 관리 도구 등

2) **Orchestration & Management**: 컨테이너 오케스트레이션(Kubernetes, Docker Swarm 등) 도구를 활용한 컨테이너 배포, Logging & Monitoring, Service Discovery 등

3) **Runtime**: 컨테이너 실행 표준(OCI), 컨테이너 네트워킹(Container Networking Interface Project), Storage(Volume Driver) 등

4) **Provisioning**: 컨테이너 환경을 고려한 DevOps의 배포 도구와 프로비저닝 등

5) **Infrastructure**: Bare Metal, Public Cloud 환경에서의 호환성을 유지

위에서 설명한 클라우드 네이티브 참조 아키텍처에서는 제일 먼저 비즈니스 도메인에 맞는 실행 환경과 애플리케이션을 설계 및 개발한 다음, 컨테이너 가상화 기술에 의해 배포하고 관리 도구를 사용해 애플리케이션의 상태와 개선 사항을 주기적으로 확인하도록 하고 있다.

> 애플리케이션 설계 → 개발 → 컨테이너에 배포 → 관리



#### 2.1.2.1  Cloud Native Landscape

https://landscape.cncf.io/

- CNCF에서는 클라우드 네이티브 참조 아키텍처를 바탕으로 클라우드 네이티브화를 실현하기 위한 Open Source Service(이하 OSS)나 서비스 기술 목록인 Cloud Native Landscape와 단계별 클라우드 네이티브 구축을 위한 Cloud Native TrailMap를 공개하였다.

- Cloud Native Landscape 프로젝트를 통해 공개된 클라우드 네이티브 아키텍처를 위한 기술 스택은 다음과 같다.

  ◾  Application Definition and Development

  ​	\- Database

  ​	\- Streaming & Messaging

  ​	\- Application Definition & Image Build

  ​	\- Continuous Integration & Delivery

  ◾  Orchestration & Management

  ​	\- Scheduling & Orchestration

  ​	\- Coordination & Service Discovery

  ​	\- Remote Procedure Call

  ​	\- Service Proxy

  ​	\- API Gateway

  ​	\- Service Mesh

  ◾  Runtime

  ​	\- Cloud Native Storage

  ​	\- Container Runtime

  ​	\- Cloud Native Network

  ◾  Provisioning

  ​	\- Automation & Configuration

  ​	\- Container Registry

  ​	\- Security & Compliance

- Key Management

  ◾  Platform

  ​	\- CloudFoundry

  ​	\- OpenShift

  ​	\- RANCHER

  ◾  Observability and Analysis

  ​	\- Monitoring: Prometheus

  ​	\- Logging: Fluentd

  ​	\- Tracing: JAEGER

  ​	\- Chaos Engineering: Gremlin

<img src="./assets/image-20220810140046458.png" alt="image-20220810140046458" style="zoom:150%;" />



Cloud Native Landscape

 

#### 2.1.2.2  Cloud Native Trail Map

- Cloud Native TrailMap에서는 Cloud Native Landscape 프로젝트의 수많은 기술 스택 중에 **클라우드 네이티브 애플리케이션 구축에 필요한 기술 및 개발, 운영에 권장되는 프로세스**를 소개하고 있다.

![Cloud Native Trail Map infographic](./assets/CNCF_TrailMap_latest-1.png)

Cloud Native TrailMap

 

1) **Containerization**

​	\- 일반적으로 Docker 컨테이너로 수행

​	\- 다양한 크기의 애플리케이션과 종속성에 관련된 내용을 컨테이너화

​	\- 애플리케이션을 단계별로 분할에 적합한 부분부터 분할하면서 Microservice로 전환

2) **CI/CD**

​	\- CI/CD(Continuous Integration/Continuous Delivery)를 설정하여 소스 코드를 변경하면 새 컨테이너가 자동으로 빌드, 테스트 및 스테이징 환경에 배포되어 최종적으로 프로덕션에 배포되도록 구성

​	\- 롤아웃, 롤백 및 테스트에 대한 자동화 설정

3) **Orchestration & Application Definition**

​	\- Docker 컨테이너의 표준화 오케스트레이션 도구인 Kubernetes 사용

​	\- Kubernetes를 이용하여 배포할 호스팅 플랫폼 또는 설치 프로그램을 선택

​	\- Kubernetes에서는 복잡한 애플리케이션의 정의, 설치 및 업그레이드를 위한 도구 (Helm Chart 등) 사용 가능

4) **Observability & Analysis**

​	\- 모니터링, 로깅 및 추적을 위한 솔루션

​	\- CNCF 프로젝트에서 Prometheus(모니터링), Fluentd(로깅) 및 Jaeger(추적) 제공

5) **Service Proxy, Discovery & Mesh**

​	\- 서비스 검색과 상태 확인, 라우팅 및 로드 밸런싱

​	\- 애플리케이션의 구성 요소 간 데이터통신을 위한 아키텍처를 지원

6) **Networking, Policy & Security**

​	\- 보다 유연한 네트워크 구성을 위해 Calico, Flannel 또는 Weave Net과 같은 CNI(Container Network Interface) 호환 네트워크 프로젝트 사용

​	\- CNCF 프로젝트 중 권한 부여 및 승인 제어에서 데이터 필터링에 이르기까지 다양한 용도로 사용되는 범용 정책엔진을 위해 OPA(Open Policy Agent)나 클라우드 네이티브의 이상 탐지를 위한 Falco 서비스 사용 가능

7) **Distributed Database & Storage**

​	\- 단일 데이터베이스 뿐만 아니라, 보다 탄력성 있고 확장성이 필요한 대규모의 데이터베이스 서비스 사용 고려 

\- Kubernetes에서는 스토리지 오케스트레이터로 Rook과 같은 스토리지 솔루션 세트 사용

8) **Stream & Messaging**

​	\- JSON-REST 방식 보다 더 높은 호환성이나 성능이 필요한 경우 범용 RPC 프레임워크인 gRPC 또는 NATS를 사용

​	\- CNCF 프로젝트의 NATS는 요청/응답, 게시/구독 및 부하 분산 대기열을 포함하는 다중 모달 메시징 시스템을 제공

9) **Container Registry & Runtime**

​	\- 컨테이너 생성을 위한 이미지 정보가 저장되어 있는 레포지토리의 모음

​	\- CNCF 프로젝트에서 OCI 스펙을 따르는 containerd 및 CRI-O 사용 가능

10) **Software Distribution**

​	\- 안전한 소프트웨어 배포

​	\- CNCF 프로젝트의 업데이트 프레임워크인 Notary 사용 가능

 

#### 2.1.2.3  Cloud Native TrailMap의 적용

- 클라우드 네이티브 애플리케이션을 위해 반드시 Cloud Native TrailMap을 따라야 하는 것은 아니다. 
- 어디까지나 참조사항으로, 각 단계에 필요한 서비스들은 벤더들의 제품을 선택하거나 직접 구현할 수 있다. 특히, **Cloud Native TrailMap의 3단계 이후부터는 기업의 상황에 따라 선택**해야 한다. 애플리케이션과 회사의 규모에 따라 달라져야 하며, 작고 간단한 애플리케이션에 Observability나 Service Mesh와 같은 기능은 필요하지 않을 수 있다.
- 기업에 적합한 클라우드 네이티브 애플리케이션 구축을 위해서 Cloud Native TrailMap 자체는 매우 훌륭한 지침이 될 수 있지만, 여기에는 “어떤 한 가지 기술이나 솔루션을 포함한 클라우드 네이티브”이라는 의미가 아니라, “**자신에게 맞는 것을 지속적으로 구현해 나가는 것**”이라는 의미로 해석해야 한다.





# 3. 클라우드 네이티브 애플리케이션

 CNCF가 제시한 클라우드 네이티브 참조 아키텍처를 바탕으로 애플리케이션 아키텍처에 대한 구체적인 내용에 대해 설명한다.

## 3.1  마이크로서비스의 특징

- 일반적으로 하나의 **클라우드 네이티브 애플리케이션은 다수의 마이크로서비스로 구성**된다.

-  **마이크로서비스 아키텍처는 기본적으로 마이크로서비스마다 고유한 프로그래밍 언어, 데이터베이스 및 스토리지**를 가지고 있다. 

- 각 마이크로서비스가 가지는 서비스의 특성에 따라 프로그래밍 언어가 선택되고, 다른 마이크로서비스가 관리하는 데이터 베이스와 스토리지에 직접 액세스할 수 없도록 설계하기 때문에, **서비스간의 통신과 데이터베이스에 엑세스하기 위해서는 직접 엑세스하는 방식이 아닌 공개 API를 이용 하여 통신**하는 것을 권장한다. 이러한 마이크로서비스의 특징을 정리하면 다음과 같다.

  ◾  분리된 프로세스: 개별 마이크로서비스는 별도의 프로세스에 의해 실행되어, 서비스간의 의존성을 작게 할 수 있다.

  ◾  API 통신: 마이크로서비스 구축을 위해 서로 다른 프로그래밍 언어를 이용하여 개발될 수 있으며, 각 마이크로서비스 간의 통신은 API를 통해 이뤄지게 된다.

  ◾  독립적인 배포: 각 서비스마다 별도의 개발 및 유지 관리 계획을 세울 수 있으며, 서비스의 규모를 작게 하여 프로그램의 복잡성을 줄여 개발 유지 보수에 필요한 비용을 절감할 수 있다.

- 애플리케이션의 신규 개발에 있어서, 반드시 마이크로서비스 아키텍처로 시작해야 한다는 것은 아니다. 전통적인 방식의 **모놀리스 아키텍처 스타일로 애플리케이션을 개발하는 것이 효율적**일 수도 있고, **서비스를 세분화 하여 마이크로서비스 아키텍처 스타일로 개발하는 것이 효율적**일 수 있다. 또는, 초기 애플리케이션을 **모놀리식 애플리케이션 방식으로 모듈화하고, 거기에 따른 서비스에 대한 문제 및 개선점이 요구될 때 해당 모듈을 마이크로서비스로 분할하는 방식**으로 전환하는 등 사용자의 요구사항 및 도메인 모델에 따라, 설계 방식을 달리해야 한다.

- 마이크로서비스 아키텍처를 선택하기 전에 이러한 문제를 충분히 인식한 다음, 사용자 요구사항에 따른 도메인 설계와 서비스 경계를 구분해야하고, 그에 따른 시스템 구성을 해야 한다. 마이크로서비스에 대한 이러한 단점이나 복잡성에도 불구하고, **마이크로서비스 아키텍처는 기존의 단일 애플리케이션 개발 방식의 문제점 해결이나 고객의 새로운 요구사항, 애플리케이션의 개선 및 이슈 등에 따르게 대응할 수 있다는 장점으로 새로운 개발 아키텍처로써 빠르게 전파**되고 있다.

 

## 3.2  클라우드 네이티브 애플리케이션 구축 시 고려 사항

- 마이크로서비스 아키텍처를 이용하여 애플리케이션을 구축할 경우에 고려해야 할 가장 중요한 점은 **사용자의 요구사항에 따른 기능을 어떻게 분할하고 어떤 마이크로서비스 에 할당**하느냐에 대한 것이다. 사용자의 요구사항에 따른 각 **기능을 너무 세밀하게 분할하면 시스템의 오버헤드가 커지고, 반대로 마이크로 서비스를 너무 크게 분할하면 마이크로서비스의 장점을 충분히 사용할 수 없게 되며, 각 서비스에 대해 감시/모니터링 해야 할 대상이 늘어남에 따라 애플리케이션 운영에 대한 복잡성이 늘어나게 된다.**

- 클라우드 네이티브 애플리케이션 구현을 위한 과정은 기업이나 조직에 따라 달라져야 한다. 애자일 개발 방식이나 IT 자동화를 지원하는 툴을 도입한다고 해서 클라우드 네이티브화되고, 서비스 접근 방식의 속도가 빨라지는 것이 아니다. 필요한 클라우드 네이티브의 기술과 특징을 살펴보고, 기업에 맞는 최선의 선택을 해야 한다. **클라우드 네이티브 애플리케이션을 구축하기 위해서는 다음과 같은 5가지 요소를 고려**해 봐야 한다.

  1) **애플리케이션 설계**: 구축하려는 서비스들의 사용자 요구사항에 대한 경계 설정과 마이크로 서비스로의 전환에 따른 설계

  2) **API 설계**: 표준화된 방법을 통한 내부 및 외부 리소스에 대한 액세스 방식에 대한 설계

  3) **운영 관리**: 애플리케이션 관리를 위한 로그 및 모니터링 정보에 대한 관리

  4) **DevOps**: 개발에서부터 운영까지의 애플리케이션 라이프 사이클에 대한 자동화 빌드와 배포

  5) **테스트**: 품질 보증을 위한 테스트

 

### 3.2.1  애플리케이션 설계

- 클라우드 네이티브 애플리케이션뿐만 아니라, 모든 애플리케이션의 가장 큰 요구 사항 중 하나는 속도에 대한 부분이다. 사용자(또는 고객)의 요구사항에 맞는 **애플리케이션 기능을 빠르게 제공하고 고객의 에러 및 이슈에 대해 수정해야하고, 이를 다시 시스템 에 반영하는 과정을 지속적으로 반복**해야 한다.

-  마이크로서비스는 애플리케이션을 구성 하는 **서비스의 구조와 경계를 변경하여 개발 뿐만 아니라, 통합 및 테스트를 수행하는 부담을 줄이고, 실행 가능한 배포 모델의 단위를 작게** 하였다. 
- 전통적인 방식에서의 커다란 단일 실행 파일 대신 클라우드 네이티브에서의 애플리케이션은 **마이크로서비스 단위로 애플리케이션을 구성하고, 해당 마이크로 서비스가 단일 애플리케이션과 같이 개별적으로 실행될 수 있도록, 기능적 구성 요소를 세분화하여 개발하고, 배포**할 수 있도록 하였다. 
- 이러한 마이크로서비스 아키텍처를 통해 애플리케이션의 다른 부분에는 영향을 주지 않고 **개별적으로 나뉜 각 기능 구성 요소를 업데이트하고 배포함으로써, 기존의 모놀리식 아키텍처가 가지고 있던 많은 문제를 줄일 수 있게** 되었다.

- 모든 마이크로서비스의 실행 파일은 **개별적으로 작동하기 때문에 각 마이크로 서비스는 포함된 기능을 적합한 스케줄에 따라 독립적으로 업데이트**될 수 있다. 
  - 예를 들어 하나의 마이크로서비스가 비즈니스 요구사항이 자주 변경되는 기능(예: 전자 상거래 에서 사용자 프로모션 제공 등)을 제공하는 경우, 마이크로 서비스는 자주 변경되지 않는 애플리케이션의 다른 부분에는 영향을 주지 않는 상태로 필요한 서비스에 대해 변경하고 독립적으로 배포할 수 있다. 또한, 마이크로서비스 방식의 개발 방식에서는 전체적인 오버 헤드가 줄어들기 때문에, 각 서비스에 대한 배포 시간을 단축시킬 수 있다.
  -  마이크로서비스 아키텍처로 개발하게 되면 특정 기능과 관련된 서비스만 변경하기 때문에, 변경에 따른 시간과 리소스 낭비를 줄일 수 있게 된다. 
- 검증에 관해서도 전체 애플리케이션의 기능을 검증해야 하는 것이 아니라, **특정 마이크로 서비스와 관련된 기능만 검증하면 되기 때문에, 서비스에 대한 테스트가 간소화되어, 더 자주 테스트하고, 더 자주 개선되고, 더 자주 배포할 수 있는 환경을 구축**할 수 있게 된다.

- **세분화된 마이크로서비스는 빠른 기능 반복 및 통합에 필요한 노력을 감소하게 하는 것이 가능**하지만, **애플리케이션에 대한 모니터링과 같은 관리의 복잡성**을 가져오기도 한다. 
- 반대로, **단순화된 마이크로 서비스는 애플리케이션 모니터링 및 관리를 단순화**할 수는 있지만, **집계나 상태 확인을 위해 여러 서비스간에 통합이 빈번하게 발생**하여, 마이크로서비스의 장점을 제대로 살리지 못하는 경우도 있을 수 있다.

- 애플리케이션의 기능을 분할하기 위한 또 한 가지 방법으로 **기본적인 서비스만을 위한 독립적인 마이크로서비스를 만드는 것을 고려**해 볼 수 있다. 
  - 예를 들어 사용자 인증 및 권한에 관련된 기능은 일반적으로 다른 애플리케이션과 독립적이지만, 여러 애플리케이션에 걸쳐 자주 사용되기 때문에, 자체 마이크로서비스로 구축하는 것이 좋다.

 

### 3.2.2  API

- 마이크로서비스 아키텍처에서 서비스 경계로 구분된 각각의 **서비스간의 데이터 교환 방법은 아키텍처 설계 시 가장 중요하게 고려**해야 할 내용 중 한가지이다.
- 서비스를 요청하는 클라이언트는 또 다른 마이크로서비스나 브라우저, 스마트 디바이스와 같은 장치일 수 있으며, 애플리케이션은 이러한 다양한 사용자들의 요청에 대한 적절한 응답을 해야 한다. 
- 가장 대표적으로 사용되는 데이터 포맷으로는 XML과 JSON이 있으며, 이러한 포맷을 사용하는 **RESTful API는 서비스간의 통신을 위해 가장 일반적인 사용되는 통신 방식**이다.

- 개념적으로 API는 매우 간단하지만 실제로 **API를 사용하여 실행 가능한 연결 메커니즘으로 만들기 위해서는 다음의 요소가 필수적으로 포함** 되어 있어야 한다.

  ◾  API 버전 관리

  ◾  서비스 제한

  ◾  Circuit Breaker

  ◾  데이터 캐싱

 

### 3.2.3  운영 설계

- 모놀리스 시스템 운영에서의 가장 큰 문제 중 하나는 **새로운 코드 릴리스를 실제 운영 환경(프로덕션)으로 옮길 때 발생하는 오버 헤드**이다. 
- 마이크로 서비스를 이용하게 되면 **개발, 테스트, 운영 등으로 실행환경이 분할**되어 있을 뿐만 아니라, **새로운 코드의 변경 사항도 서비스 단위로 분리**되어 개발되고, 업데이트 되기 때문에, 변경 사항을 위한 빌드를 위해 **전체 애플리케이션을 재배포 하지 않아도 된다.** 
- 또한 **코드 변경을 이전 상태로 복귀하는 프로세스도 쉽게 구현**할 수 있다.

- 대부분의 **마이크로서비스 환경에는 각 마이크로서비스마다 기능에 대한 중복성**이 있을 수 있다. 
  - 이것은 기존의 기능을 완전하게 종료하지 않더라도, 다른 마이크로서비스가  대체하여 실행할 수 있음을 의미한다. 새 코드를 실행한 다음, 새로운 기능을 점차적으로 테스트하기 위해, 일부 마이크로서비스만을 종료할 수 있다. 전체 마이크로서비스가 정상적으로 계속 작동하는 상태에서 부분적으로 각 서비스에 대한 업데이트를 수행할 수 있게 된다.

- 새로운 애플리케이션의 아키텍처에는 IT 조직이 마이크로서비스 기반의 애플리 케이션을 처리할 수 있는 **새로운 모니터링 및 관리 시스템을 준비**해야 한다. 
  - 마이크로 서비스로 구성된 전체 애플리케이션은 이전보다 더 많은 실행 파일이 실행될 수 있으며, 이에 따라 모니터링 및 관리 시스템은 더 많은 데이터 소스를 통합하고 운영 담당자가 이해할 수 있고 유용하게 사용할 수 있도록 관리 모니터링 도구가 준비되어 야 한다.

 

### 3.2.4  데브옵스(DevOps)

- 오늘날의 IT 시스템은 개발, 애플리케이션 구축, QA, 운영 등을 포함하여 애플리케이션 각 수명주기를 책임지는 조직이나 팀 등에 의해 개발 및 운영되고 있다.대부분의 IT 조직에서는 각 팀들 간에 내부 최적화에 중점을 둔 고유 한 프로세스를 가지고 있을 수 있다. 
- 한 팀에서 다른 팀으로 프로젝트의 결과물이 전달되면, 각 팀은 새로운 실행 환경에 따른 완전히 새로운 애플리케이션의 실행 파일(결과물)을 만들어 버리는 경우도 있고, 작업의 결과물을 전달 받은 조직에서 기존에 추가된 작업에 대해 수정작업을 해야 하는 경우도 있다. 
- 이러한 IT 구조는 빠른 배포 및 빈번한 업데이트가 필요한 IT 서비스의 생태계에서 매우 긴 배포 시간을 유발하고 결과적으로 사용자 요구사항의 반영이나 시스템의 개선을 더디게 하는 요인이 될 수 있다.

- **DevOps는 이러한 IT 팀 간의 장벽을 없애려는 시도이며, 수동 프로세스를 자동화로 대체하여 업무 개선 및 운영에 효율성을 가져오기 위한 방법론**이다. **DevOps에서의 목표는 개발자가 코드를 작성 또는 수정하는 시점과 코드를 프로덕션에 배치하는 시점 사이의 시간을 최대한 줄이는 것**이다.
- DevOps는 애플리케이션의 전체 수명주기에 걸쳐 각 작업의 소요 시간을 식별하여 프로세스를 적용하는 방법과 특정한 작업이나 그룹에서 작업 소요 시간이 오래 걸리는 부분을 파악하여 프로세스를 개선하는 방법으로 시작할 수 있다.

 

### 2.2.5  테스트

- 대부분의 IT 조직에서의 검증과 테스트 작업은 담당하는 QA 그룹은 직원 수가 적거나 리소스가 부족한 경우가 많기 때문에, 애플리케이션 기능이 올바르게 작동하는지에 대한 테스트를 위한 작업도 부분적이고 수동적인 기능 테스트 밖에 할 수 없는 경우가 많다. 
- IT조직은 배포 직전까지 QA를 수행하는데, 이러한 문제점으로 인해 최종 애플리케이션을 재작업 하거나, 만족스럽지 못한 코드를 배포하는 경우도 종종 발생 한다. 이러한 방식은 비즈니스를 기능을 지원하는 부가적인 애플리케이션에는 수용될 수 있지만 완전한 비즈니스 애플리케이션을 위해서는 허락 될 수 없다.

-  QA 테스트는 개발 프로세스의 핵심 부분이어야 하며 프로세스가 초기에 수행되어 애플리케이션에서 발생하는 문제를 애플리케이션의 패닉 상태나 애플리케이션 중단을 유발하기 전에 식별하여 해결해야만 한다. 이를 위해서 애플리케이션 개발의 수명주기 초기에 테스트를 수행하면서 개발하는 **TDD(Test Driven Development, 테스트 주도 개발)를 도입**하기도 한다.

- **애플리케이션의 각 기능들의 테스트 코드에 대한 개발 책임은 새로운 기능을 작성하는 개발자가 처리해야 하며, 새 코드가 개발 완료 되는 즉시 테스트 코드가 호출될 수 있는 자동화된 테스트 실행 환경을 구축**해야 한다. 
- **개발자가 코드를 버전 컨트롤 시스템에 체크인 할 때, 코드 저장소에는 개발자가 작업한 코드 부분과 관련된 모든 기능 테스트를 자동으로 시작하는 시스템이 준비**되어 있어야 한다.

- 기능 테스트가 개발자 중심으로 전환됨으로 인해 QA 그룹은 다음과 같은 중요한 세 가지 테스트에 집중할 수 있다.

  ◾  **통합 테스트(Integration Test)**: 애플리케이션의 종단 간 테스트를 처리하며, **애플리케이션의 모든 부분을 테스트**한다. 통합 테스트는 새로운 기능이 구현 될 때 새로운 코드가 실수로 기존 기능을 손상시키지 않는지 검증해 주며, 초기 코드 체크인시 이 테스트를 자동화하여 프로덕션에서 예기치 않은 오류를 방지할 수 있다. **통합 테스트 환경을 구현하려면 자동화된 테스트 기능, 전용 테스트 리소스 및 테스트 코드에 대한 개발** 투자가 필요하다.

  ◾  **사용자 테스트(User Accepted Test)**: 애플리케이션은 해당 애플리케이션이 가장 많이 사용되는 **사용자의 환경을 중심으로 테스트**되어야 한다. 예를 들어 모바일 애플리케이션의 경우 가장 일반적이고 널리 사용되는 모든 모바일 디바이스에서 애플리케이션을 테스트하는 것이 중요하다. 많은 IT 조직은 테스트 목적으로 가능한 한 충분한 디바이스에서 테스트를 하려 하지만, 새로운 디바이스에 대한 모든 테스트를 하기에는 자원이 부족하기 때문에, 포괄적이고 많은 테스트를 지원하고, 충분한 리소스를 포함하는 테스트 전용 프레임워크를 사용한다.

  ◾  **성능/부하 테스트(Stress Test)**: 기본적으로 **클라우드 네이티브 애플리케이션은 불규칙적인 트래픽에 대해 리소스를 탄력적으로 제공**해야 한다. 일부 기능은 많은 트래픽을 처리할 수 없거나 애플리케이션이 탄력적인 리소스를 사용하는 데에 적합하지 않게 설계되었기 때문에, 많은 애플리케이션에서 장애가 발생하거나 클라우드 환경에서는 성능이 저하될 수도 있다. 이러한 트래픽에 대한 문제는 **자동스케일링(Auto Scaling) 기능으로 리소스의 확장 및 축소에 대한 동적인 대응이 가능해야하고, 탄력적인 리소스 제공에 대한 성능 및 부하(스트레스) 테스트를 거쳐, 애플리케이션의 장애 또는 성능 저하를 방지**해야 한다.



## 2.3 애플리케이션 아키텍처

- 기존 모노리스 환경에서 많이 적용하는 레이어드 아키텍처(Layered Architecture )에 대해 설명하고 최근의 마이크로서비스 설계자들이 마이크로서비스 내부구조를 유연하게 가져가기 위해 적용하고 있는 헥사고널 아키텍처(Hexagonal Architecture )와 클린 아키텍처(Clean Architecture)가 있다

### 2.3.1 레이어드 아키텍처

- 레이어드 아키텍처(계층 형 아키텍처:Layered Architecture)를 구성하는 레이어는 많은 사람들이 혼동하는 물리적인 티어(Tier)의 개념과 달리 논리적인 개념이다. 티어는 물리적인 장비, 서버 컴퓨터 등의 물리 층을 의미하고 레이어는 티어 내부의 논리적인 분할을 의미한다. 
- 아래 그림과 같이 물리적인 서버 티어의 레이어(이하:계층)를 **프레젠테이션(Presentation) , 비지니스 로직(Business Logic), 데이터 액세스(Data Access)** 3개의 논리적인 계층으로 구분할 수 있다.

![티어와 레이어](./assets/MSA_3.2.png)

- 계층은 설계자들이 복잡한 시스템을 분리할 때 흔히 사용하는 패턴 중 하나로 어플리케이션이 내부에서 처리하는 관심사를 논리적으로 구분한다. 
- 다음은 **마틴 파울러가 그의 책 ‘엔터프라이즈 애플리케이션 아키텍처 패턴(Enterprise Application Architecture Pattern)’ 에서 구분한 레이어드 아키텍처 패턴 전형적인 유형**이다. 아키텍트가 의도하는 방향에 따라 여러가지로 구분 가능하나 일반적으로 **프레젠테이션, 비즈니스 로직, 데이터 액세스**의 3계층으로 구분하는 경향이 일반적이다.

![전통적인3계층 아키텍처](./assets/MSA_3.3.png)

- 프레젠테이션 층의 관심사는 화면 표현 및 전환 처리이고 비즈니스 로직층의 관심사는 비즈니스 개념 및 규칙, 흐름 제어이며 데이터 액세스 층의 관심사는 데이터 처리이다.

- 레이어드 아키텍처는 레이어 간 응집성을 높이고 의존도를 낮추기 위해 몇 가지의 규칙들을 가지고 있는데 다음과 같다.
  - 상위 계층이 하위 계층을 호출하는 단 방향성을 유지한다.
  - 상위 계층은 하위의 여러 계층을 모두 알 필요 없이 바로 밑의 근접 계층만 활용한다.
  - 상위 계층이 하위 계층에 영향을 받지 않게 구성해야 한다.
- 하위 계층은 자신을 사용하는 상위 계층을 알지 못하게 구성해야 한다.
- 계층 간의 호출은 인터페이스를 통해 호출하는 것이 바람직하다. (구현 클래스에 직접 의존하지 않음으로써 약한 결합을 유지해야 한다.)

![레이어드 아키텍처 규칙](./assets/MSA_3.4.png)

- 특히 인터페이스를 통한 의존성 분리는 인터페이스를 구현하는 구현체를 다양하게 해주는 다형성을 추구함으로써 제어 흐름을 간접적으로 전환하게 해준다. 아래 그림을 보면 상위 계층은 직접적으로 하위 계층을 호출하지 않고 추상적인 인터페이스를 의존한다. 
- 이럴 경우 하위레이어는 추상적 인터페이스를 만족하는 다양한 방식의 구현체를 선택적으로 적용할 수 있다.

![인터페이스 호출을 통한 다형성 추구](./assets/MSA_3.5.png)

- 이러한 방식은 로버트 C 마틴이 정의한 객체지향의 원칙의 **의존성 역전 원칙(Dependency Inversion Principle)** 을 만족하는 것처럼 보인다. 의존성 역전의 원칙은 ‘유연성이 극대화된 시스템’이란 소스 코드 의존성이 추상에 의존하며 구체에는 의존하지 않아야 한다’라고 말하기 때문이다.

- 그렇지만 **개방 폐쇄의 원칙(OCP: Open-Closed Principle)** 까지 살펴본다면 문제가 있다. OCP는 소프트웨어 개체는 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다는 원칙이다. 이는 **개체의 행위는 확장할 수 있어야 하지만 이때 개체를 변경해서는 안된다는 말**이다.

- 그러나 계층 방식은 인터페이스를 통해 의존성을 낮춘다 해도, 일반적으로 추상적인 인터페이스가 각 계층의 제일 상위에 위치하는 구조로 제어의 흐름(Flow of Control)이 상위에서 하위로 흐르게 되고 이에 따른 소스코드의 의존성은 제어의 흐름을 따르게 된다. 따라서 **하위 계층의 유형이 추가되어 확장될 때 닫혀 있어야 할 상위계층이 의존을 받을 수 밖에 없다.**

- 프레젠테이션, 비지니스로직, 데이터 액세스 의 3계층으로 살펴보면 제일 마지막에 있는 **데이터 액세스 계층이 변경되었을 때 비지니스로직 계층이 변경되면 안되는데 위의 그림을 보면 비지니스로직 계층의 클래스가 데이터 액세스 계층에 존재하는 인터페이스를 의존하기 때문에 데이터 계층의 영향을 받게 된다.**

- 문제는 데이터 엑세스 인터페이스 위치이다. 데이터 엑세스 인터페이스는 데이터 엑세스 계층에 존재한다. 일면 당연해 보이지만 그런 방식은 항상 하위 계층에 의존해야 한다. 그렇지만 어플리케이션에서는 비지니스 로직이 핵심이라고 하였다. 즉 문제 중심 영역이다. 그렇기 때문에 비지니스 로직을 보통 고수준 영역이라고 하고 프레젠테이션 계층 및 데이터 액세스 계층을 저수준 영역이라고 한다. 고수준 영역은 문제 중심 영역이므로 보호를 받아야 하고 따라서 저수준 영역의 변경, 확장에 영향을 받지 않아야 한다. 그러나 위에서처럼 **일반적인 레이어드 아키텍처의 규칙만을 따르면 고수준 영역이 저수준영역에 의존하게 되고 영향을 받게 된다.**

- 여기서 의존성의 역전 원칙(DIP)적용의 필요성이 생긴다. DIP는 데이터 액세스 계층에서 정의한 인터페이스의 위치를 경계 넘어 비지니스로직 계층으로 이동시킨다. 그러면 데이터 액세스 계층의 구현체는 비지니스 로직의 계층의 인터페이스를 바라볼 수 밖에 없다.

- 즉 데이터 액세스 계층이 구현해야 할 인터페이스를 아래 그림과 같이 보다 **고수준의 비지니스 로직 계층에서 정의하게 함으로써 기존에 위에서 아래로 흘렀던 의존관계를 역전시키고 고수준이 저수준의 변경에 영향을 받지 않도록 해 주는 것**이다.

![의존관계 역전의 적용](https://engineering-skcc.github.io/assets/images/msa/MSA_3.6.png)

### 2.3.3 헥사고날 아키텍처

- 레이어드 아키텍처에 DIP를 적용해도 한계가 존재한다. 프레젠테이션 계층 와 데이터 액세스 계층을 보통 저수준 계층으로 정의한다고 했는데 **현대 어플리케이션의 활용은 이러한 2가지 계층 말고도 다양한 인터페이스를 필요**로 한다. 즉 어플리케이션을 호출하는 시스템의 유형과 어플리케이션과 상호작용하는 다양한 저장소가 존재한다. **헥사고날 아키텍처(육각형, Hexagonal Architecture)** 는 이러한 문제점을 해결할 수 있다.

- 헥사고날 아키텍처는 엘리아스 쿡번(Alistair Cockburn )이 제시한 아키텍처로 **‘ 포트 엔 어댑터 아키텍처(ports and adapters architecture)’** 라고도 부른다. 아래 그림을 통해 간단히 살펴보면 고수준의 비지니스 로직을 표현하는 내부 영역과 인터페이스 처리를 담당하는 저수준의 외부 영역으로 나눈다.

- **내부 영역** 은 순수한 **비지니스로직을 표현하는 기술 독립적인 영역며 외부영역과 연계되는 포트**를 가지고 있다.

- **외부 영역** 은 외부에서 들어오는 요청을 처리하는 **인 바운드 어댑터(Inbound Adapter)와 비지니스 로직에 의해 호출되어 외부와 연계되는 아웃바운드(Outbound Adapter) 어댑터로 구성**된다.

- 헥사고널의 가장 큰 특징은 **고수준의 내부 영역이 이런 어댑터에 전혀 의존하지 않게 한다는 것**이다. 그것을 가능하게 하는 것이 내부 영역에 구성되는 **포트**이다. **포트는 인 바운드 / 아웃 바운드 포트로 구분되는데, 인 바운드 포트는 내부 영역 사용을 위해 표출된 API**이며, 외부 영역의 인 바운드 어댑터가 호출한다. **아웃바운드 포트는 내부 영역이 외부를 호출하는 방법을 정의**한다. 여기서 **DIP 원칙과 같이 아웃바운드 포트가 외부의 아웃바운드 어댑터를 호출하여 외부 시스템과 연계하는 것이 아니라 아웃바운드 어댑터가 아웃바운드 포트에 의존**하여 구현된다.

- 외부영역에 존재하는 **어댑터** 의 종류를 살펴보면 **인 바운드 어댑터는 REST API를 발행하는 컨트롤러, 웹 페이지를 구성하는 스프링 MVC 컨트롤러, 커맨드 핸들러, 이벤트 메시지 구독 핸들러** 등이 될 수 있고, **아웃바운드 어댑터는 데이터 액세스 처리를 담당하는 DAO , 이벤트 메시지를 발행하는 클래스, 외부 서비스를 호출하는 프록시** 등이 될 수 있다.

![헥사고날 아키텍처의 포트 와 어답터](https://engineering-skcc.github.io/assets/images/msa/MSA_3.7.png)

### 2.3.4 클린 아키텍처

- 클린 아키텍처(Clean Architecture)는 **로버트 C 마틴이 제안한 아키텍처로 헥사고널 아키텍처의 아이디어와 매우 유사**하다. 앞서 언급한 것처럼 로버트는 소프트웨어는 행위적/구조적 두 종류의 가치를 가지며 구조적 가치가 더 중요하다고 말한다. 왜냐하면 소프트웨어를 부드럽게 만드는 것이 구조적 가치이기 때문이다. 그렇다면 소프트웨어를 부드럽게 유지하는 방법은 무엇일까? 즉 구조 중에 선택할 수 있는 것을 가능한 오랫동안 열어두는 것이다. 특히 열어둬야 할 선택사항은 바로 중요치 않은 세부사항이다.

- 마틴은 아래 그림같이 **클린 아키텍처를 여러 겹의 둘러싸인 영역으로 표현하며 엔티티, 유스케이스, 그 외 세부사항으로 구분**한다.

- 제일 중앙에는 **엔티티** 가 있다. 업무 규칙은 **사업적으로 수익을 얻거나 비용을 줄일 수 있는 규칙 또는 절차**를 말한다. 이런 업무 규칙은 수동으로 처리할 수 있지만 시스템으로도 자동화 할 수 있다. 예를 들면 쇼핑몰의 물건을 사고 파는 규칙, 은행의 이자 계산 규칙 ,도서대여 시스템의 대여/반납 규칙 등 모든 시스템에는 해당 **도메인의 업무를 규정하는 핵심 업무 규칙들이 존재**한다. 그리고 핵심업무규칙은 보통 데이터를 요구한다. 따라서 **핵심 규칙과 데이터는 본질적으로 결합되어 있기 때문에 객체로 쉽게 만들 수 있다. 이런 유형을 ‘엔티티’ 객체** 라 한다.

- 그 다음 엔티티를 감싸는 객체는 **유스케이스**이다. 유스케이스는 **자동화된 시스템을 사용하는 처리 절차**를 기술한다. 유스케이스는 **애플리케이션에 특화된 업무 규칙을 표현하며 엔티티 내부의 핵심 업무 규칙을 호출하며 시스템을 사용하는 흐름**을 담는다. 이때 엔티티 같은 고수준은 저수준의 유스케이스를 알게 하면 안된다.
  엔티티는 간단한 객체 여야 하며 프레임워크 데이터베이스 또는 여타 복잡한 것에 의존되어서는 안되고 유스케이스 객체을 통해서만 엔티티를 조작해야 한다.

- 그리고 그 다음 유스케이스를 감싸고 있는 모든 영역들은 **세부사항** 이다. **세부사항은 입출력 장치, 저장소, 웹 시스템, 서버, 프레임워크, 통신 프로토콜이 될 수 있으며, 세부사항과 유스케이스 관계를 의존관계 역전의 법칙을 이용하여 플러그인처럼 유연하게 처리**해야 한다. 이런 명확한 결합의 분리는 테스트 성 및 개발 독립성, 배포 독립성 강화할 수 있다.

![클린 아키텍처](https://engineering-skcc.github.io/assets/images/msa/MSA_3.8.png)



 

# 4. Spring 

## 4.1. 스프링(Spring)이란?

### 4.1.1 스프링의 개념

![image](./assets/spring_logo.png)

- Spring은 무엇일까요? 스프링은 **자바 기반의 웹 어플리케이션을 만들 수 있는 프레임워크**이다. spring.io 사이트에서 확인하면 **스프링 프레임워크는 현대 자바 기반의 엔터프라이즈 어플리케이션을 위한 프로그래밍 및 Configuration Model 제공한다**라고 언급하고 있다.

- Python을 이용한 Django, Ruby를 이용한 Ruby on Rails, Javascript를 이용한 Node.js 기반의 웹 서버 개발과 같이 Java 개발자들은 Spring을 사용하여 웹 서비스를 만들 수 있다.
- Spring 은 수많은 국내 기업과 해외 기업에서 매우 많은 서비스를 만들 때 사용되고 있다. 자바 백엔드 개발자는 웹 애플리케이션을 개발할 때, 대부분 스프링을 사용한다고 있다.
- 스프링의 구조는 아래와 같은 구조로 이루어져있다.

![](./assets/spring_architect.png)





### 4.1.2 스프링의 특징

- Spring은 자바 플랫폼을 위한 오픈소스 애플리케이션 프레임워크로서 엔터프라이즈급 애플리케이션을 개발하기 위한 모든 기능을 종합적으로 제공하는 **경량화된 솔루션**이다.

- Spring은 경량 컨테이너로 자바 객체를 직접 Spring 안에서 관리한다.

- 객체의 생성 및 소멸과 같은 생명 주기(Life cycle)을 관리하며, Spring 컨테이너에서 필요한 객체를 가져와 사용한다.

- Spring의 가장 큰 특징인 IOC와 DI의 개념은 아래와 같다.

  - ```plaintext
  제어의 역전 (IOC, Inversion Of Control)
    ```

    - 일반적으로 처음에 배우는 자바 프로그램에서는 **각 객체들이 프로그램의 흐름을 결정하고 각 객체를 직접 생성하고 조작하는 작업(객체를 직접 생성하여 메소드 호출)을 한다**. 즉, 모든 작업을 사용자가 제어하는 구조이다. 예를 들어 A 객체에서 B 객체에 있는 메소드를 사용하고 싶으면, B 객체를 직접 A 객체 내에서 생성하고 메소드를 호출한다.
  - 하지만 **IOC가 적용된 경우, 객체의 생성을 특별한 관리 위임 주체에게 맡긴다.** 이 경우 **사용자는 객체를 직접 생성하지 않고, 객체의 생명주기를 컨트롤하는 주체는 다른 주체**가 된다. 즉, 사용자의 제어권을 다른 주체에게 넘기는 것을 IOC(제어의 역전) 라고 한다.
    
  - 요약하면 Spring의 Ioc란 `클래스 내부의 객체 생성 -> 의존성 객체의 메소드 호출`이 아닌, `스프링에게 제어를 위임하여 스프링이 만든 객체를 주입 -> 의존성 객체의 메소드 호출` 구조이다. 스프링에서는 모든 의존성 객체를 스프링이 실행될때 만들어주고 필요한 곳에 주입해준다.
    
  - ```plaintext
  의존성 주입 (DI, Dependency Injection)
    ```
  
    - 어떤 객체(B)를 사용하는 주체(A)가 객체(B)를 직접 생성하는게 아니라 **객체를 외부(Spring)에서 생성해서 사용하려는 주체 객체(A)에 주입시켜주는 방식**이다. 사용하는 주체(A)가 사용하려는 객체(B)를 직접 생성하는 경우 의존성(변경사항이 있는 경우 서로에게 영향을 많이 준다)이 높아진다. 하지만, 외부(Spring)에서 직접 생성하여 관리하는 경우에는 A와 B의 의존성이 줄어든다.



## 4.2. Spring Boot란?

### 4.2.1 개요

![image](./assets/spring_boot_logo.png)

- Spring Boot를 는 **스프링(Spring)을 더 쉽게 이용하기 위한 도구**라고 볼 수 있다.
- Spring Boot를 사용하면 실행할 수 있는 실행 가능한 형태의 Spring 기반 응용 프로그램을 만들 수 있다. 
- Spring Boot는 매우 간단하게 프로젝트를 설정할 수 있게 하여, Spring 개발을 조금 더 쉽게 만들어 주는 역할을 하고 있다.

![image](./assets/spring_boot2.png)

> Spring Boot는 실행환경이나 의존성 관리 등의 인프라 영역에 대한 자동화를 제공하고 결국  **비즈니스를 만들기 위한 프로그래밍**에 집중할 수 있는 환경을 제공해 준다.



### 4.2.2 시스템 요구 사항

- 스프링 부트 2.7.3에는 Java 8이 필요하며 [Java](https://www.java.com/) 18까지 호환된다.
  - [Spring framework 5.3.22](https://docs.spring.io/spring-framework/docs/5.3.22/reference/html/) 이상 버전을 사용한다.

- 아래 빌드 도구를 지원한다.

| 빌드 도구 | 버전                |
| :-------- | :------------------ |
| Maven     | 3.5+                |
| Gradle    | 6.8.x, 6.9.x 및 7.x |

### 4.2.3  서블릿 컨테이너

- Spring Boot는 다음과 같은 임베디드 서블릿 컨테이너를 지원한다.

| 이름         | 서블릿 버전 |
| :----------- | :---------- |
| Tomcat 9.0   | 4.0         |
| Jetty 9.4    | 3.1         |
| Jetty 10.0   | 4.0         |
| Undertow 2.0 | 4.0         |



### 4.2.4 PSA(Portable Service Abstraction)란?

- **Spring은 Spring Triangle이라고 부르는 핵심 3대요소를 제공해준다. 이는 각각 IoC , AOP , PSA를 일컫는다.**

![](https://blog.kakaocdn.net/dn/lWkuv/btq9MEmLHyN/q6A6PnOdfE6L5AwdXjaOl0/img.png)



- PSA란 **환경의 변화와 관계없이 일관된 방식의 기술로의 접근 환경을 제공하는 추상화 구조**를 말한다**.**

- 이는 POJO 원칙을 철저히 따른 Spring의 기능으로 Spring에서 동작할 수 있는Library들은 POJO원칙을 지키게끔 PSA형태의 추상화가 되어있음을 의미한다.


> #### "잘 만든 인터페이스 하나가 열 클래스 부럽지 않다"
>

- PSA가 적용된 코드라면 나의 코드가 바뀌지 않고, 다른 기술로 간편하게 바꿀 수 있도록 확장성이 좋고, 기술에 특화되어 있지 않는 코드를 의미한다.

- Spring은 **Spring Web MVC, Spring Transaction, Spring Cache 등의 다양한 PSA를 제공**하고 있다.
  

#### 4.2.1.1 Spring Web MVC

- **일반적인 서블릿의 형태**

> Servlet을 사용하려면 HttpServlet을 상속받고 doGet(), doPost() 등 오버라이딩하여 사용해야 한다.

```java
public class CocoServlet extends HttpServlet {
 
	// GET
	@Override
	protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
		super.doGet(req, resp);
	}
	
	// POST
	@Override
	protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
		super.doPost(req, resp);
	}
}
```

- **Spring Web MVC의 형태**

```java
@Controller
class OwnerController {
 
 do something..
 
@GetMapping("/owners/new")
@LogExecutionTime
public String initCreationForm(Map<String, Object> model) {
	Owner owner = new Owner();
	model.put("owner", owner);
	return VIEWS_OWNER_CREATE_OR_UPDATE_FORM;
}
 
@PostMapping("/owners/new")
@LogExecutionTime
public String processCreationForm(@Valid Owner owner, BindingResult result) {
	if (result.hasErrors()) {
		return VIEWS_OWNER_CREATE_OR_UPDATE_FORM;
	}
	else {
		this.owners.save(owner);
		return "redirect:/owners/" + owner.getId();
	}
}
 
do something..
 
} // end OwnerController
```

- 일반 클래스에 **@Controller** 어노테이션을 사용하면 **요청을 매핑할 수 있는 컨트롤러 역할을 수행하는 클래스**가 된다.

- 그 클래스에서는 **@GetMapping**과 **@PostMapping** 어노테이션을 사용해서 요청을 매핑할 수 있다.
  - 서블릿을 Low level 로 개발하지 않고도, Spring Web MVC를 사용하면 이렇게 서블릿을 간편하게 개발할 수 있다.
  - 즉, HttpServlet을 상속받고 **doGet(), doPost()**를 구현하는 등의 작업을 하지 않아도 된다.

- **Service Abstraction(서비스 추상화)의 목적 중 하나가 이러한 편의성을 제공하는 것이다.**
  - 또한, Spring Web MVC는 코드를 거의 그대로 둔 상태에서 톰캣이 아닌 다른 서버로 실행하는 것도 가능하다.
    - 프로젝트의 spring-boot-starter-web 의존성 대신 spring-boot-starter-webflux 의존성을 받도록 바꿔주기만 하면 **Tomcat이 아닌 netty 기반으로 실행하게 할 수 있다.**

- 이렇게 Spring Web MVC는 @Controller, @RequestMapping 과 같은 어노테이션과 뒷단의 여러가지 복잡한 인터페이스들 그리고 기술들을 기반으로 하여 사용자가 **기존 코드를 거의 변경하지 않고**, 웹 기술 스택을 간편하게 바꿀 수 있도록 해준다.



#### 4.2.1.2  Spring Transaction

- Low level로 트랜잭션 처리를 하는 간단한 예제 코드이다.

```java
 try (Connection conn = DriverManager.getConnection(
             "jdbc:coco://127.0.0.1:5432/test", "coco", "password");
             Statement statement = conn.createStatement();
             ) {
             
             //start transaction block
             conn.setAutoCommit(false); //default true
             
             String SQL = "INSERT INTO Employees " +
             			  "VALUES (101, 20, 'Rita', 'Tez')";
             stmt.executeUpdate(SQL);
             
             String SQL = "INSERTED INT Employees " +
             			  "VALUES (107, 22, 'Kita', 'Tez')";
             stmt.executeUpdate(SQL);
             
             // end transaction block, commit changes
             conn.commit();
             
             // good practice to set it back to default true
             conn.setAutoCommit(true);
             
             } catch(SQLException e) {
             	
                System.out.println(e.getMessage());
                conn.rollback();
             }
```

- conn.setAutoCommit(false);을 하여 자동커밋을 막아주고, 오류 없이 진행된다면 conn.commit();으로 커밋 된다.

- 하지만, 2번째 SQL문에 INSERTED INT 의 오타로 인해 커밋 되지 않고 catch문으로 가게되어 conn.rollback();으로 롤백 하는 코드이다.

- 위의 코드와 같이 Low level로 트랜잭션 처리를 하려면 명시적으로 setAutoCommit()과 **commit(), rollback()**을 호출해야 한다.

- 하지만 Spring이 제공하는 **@Transactional** 어노테이션을 사용하면 단순하게 메소드에 어노테이션을 붙여줌으로써트랜잭션 처리가 간단하게 이루어진다.

```java
@Transactional(readOnly = true)
Employees findById(Integer id);
```

- 이 또한 PSA로써 다양한 기술 스택으로 구현체를 바꿀 수 있다.

- 예를들어, JDBC를 사용하는 DatasourceTransactionManager, JPA를 사용하는 JpaTransactionManager, Hibernate를 사용하는 HibernateTransactionManager를 유연하게 바꿔서 사용할 수 있다. 

- 즉, **기존 코드는 변경하지 않은 채로 트랜잭션을 실제로 처리하는 구현체를 사용 기술에 따라 바꿀 수 있는 것**이다.



#### 4.2.1.3 Spring Cache

- Cache도 마찬가지로 JCacheManager, ConcurrentMapCacheManager, EhCacheCacheManager와 같은 여러가지 구현체를 사용할 수 있다.

```java
@Transactional
@Cacheable("users")
List<User> findAllUser();
```

- 사용자는 **@Cacheable** 어노테이션을 붙여줌으로써 구현체를 크게 신경쓰지 않아도 필요에 따라 바꿔 쓸 수 있다..

- Spring은 이렇게 **특정 기술에 직접적 영향을 받지 않게끔 객체를 POJO 기반으로 한번씩 더 추상화한 Layer를 갖고 있으며,** **이를통해 일관성있는 Service Abstraction(서비스 추상화)를 만들어 낸다.**

- 덕분에 코드는 더 견고해지고 기술이 바뀌어도 유연하게 대처할 수 있게 된다.



### 4.2.5 Spring Boot Auto Configuration 

[using-boot-disabling-specific-auto-configuration](https://docs.spring.io/spring-boot/docs/current/reference/html/using-boot-auto-configuration.html#using-boot-disabling-specific-auto-configuration)

- Spring Boot는 Spring과 마찬가지로 component-scan을 통해 component들을 찾고 bean 생성을 진행한다.
- 그 과정에서 우리가 설정한 bean들이 생성된다.
- 예를들면, @Controller, @RestController, @Service, @Repository 그리고 @Configuration에 등록한 @Bean 과 같은 설정 이고 그 과정에서 Spring Boot에서 미리 작성해둔 auto configuration에 의해 추가적인 bean들도 함께 생성된다.

- Spring에서는 ThreadPoolTaskExecutor를 사용하기 위해서는 우리가 해당 bean을 등록해야했지만 Spring Boot에서는 등록하지 않아도 해당 bean이 자동으로 생성되기 때문에 사용할 수 있게된다.

  

#### 4.2.5.1 @SpringBootApplication

- @SpringBootApplication는 @ComponentScan과 @EnableAutoConfiguration을 포함하고 있다.

- 아래의 Application.java는 @SpringBootApplication 설정만 했지만 component scan과 auto configuration이 이루어진다.

```
Application.java
package com.dveamer.sample

@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

- 즉, 우리는 프로젝트의 최상단에 Application.java를 위치시키고 @SpringBootApplication 설정해두면 앞으로 프로젝트에 추가할 configuration 관련 정보들이 모두 유효하도록 설정이 된다.

  

#### 4.2.5.2 @EnableAutoConfiguration

- @EnableAutoConfiguration은 auto configuration 기능을 사용하겠다는 설정이다. 
- @EnableAutoConfiguration을 설정하지 않는다면 auto configuration 을 사용하지 못하게 된다. 일반적으로 아래와 같이 @ComponentScan과 함께 사용된다.

```
package com.dveamer.sample

@SpringBootConfiguration
@ComponentScan("com.dveamer.sample")
@EnableAutoConfiguration
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

- @ComponentScan에 입력된 com.dveamer.sample 값은 component scan를 시작할 패키지 위치이다.
- com.dveamer.sample 하위 모든 패키지를 component scan 범위로 잡겠다는 설정이다.
- package 위치를 입력하지 않는다면 com.dveamer.sample.Application이 놓여진 패키지(com.dveamer.sample)가 기본 값으로 사용된다. 여러 패키지 위치를 scan 대상으로 설정하는 것도 가능하다.
-  component scan을 통해서 모은 component들의 정보와 Spring Boot가 spring.factories 파일에 사전에 정의한 AutoConfiguration 내용에 의해 bean 생성이 진행된다.



#### 4.2.5.3 Auto Configuration Filters & Conditions

- Spring Boot가 미리 정의해둔 AutoConfiguration 정보는 `spring-boot-autoconfigure/META-INF/spring.factories`에서 혹은 [spring.factories](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories)에서 확인 가능하다.

`org.springframework.boot.autoconfigure.EnableAutoConfiguration`에 상당히 많은 AutoConfigruation이 등록되어있는 것을 확인할 수 있다.

```
...

# Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\
org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\
org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\
org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\
org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\
org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\
org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\
org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\
org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\
org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\
...
```

- 각 AutoConfigruation들은 필요한 상황에만 자신이 실행될 수 있도록 @Conditional, @Condition과 같은 annotation들로 설정이 되어있다. 그 annotation 을 기반으로 필터링이 먼저 이뤄지고 필터링되지 않은 AutoConfigruation을 가지고 작업이 진행된다.

- @Condition, @Conditional 은 Sprig 4.0부터 추가된 annotation이고 Spring Boot auto configuration 과정에서 사용되는 또 다른 annotation들도 [autoconfigure-condition](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/)에서 확인 가능하다.

- 또한 [@Profile](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Profile.html), [@Lazy](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Lazy.html)와 같은 Spring에서 제공하는 다른 annotation들도 Spring Boot auto configuration에 활용된다.



#### 4.2.5.4 Auto Configuration Import Filters

- Spring Boot는 [spring.factories](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories) 정보를 가지고 auto configruation을 진행한다.

- 그리고 그 내용 중에 AutoConfigurationImportFilter 관련 설정이 있으며 아래와 같은 3개의 필터가 적용 된 것을 확인할 수 있다.

```properties
spring.factories
...
# Auto Configuration Import Filters
org.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\
org.springframework.boot.autoconfigure.condition.OnBeanCondition,\
org.springframework.boot.autoconfigure.condition.OnClassCondition,\
org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition

...
```

- 해당 필터들은 각 AutoConfiguration이 가진 @Conditional을 가지고 조건 만족여부를 체크 한다. 그리고 조건이 맞지 않을 경우 해당 AutoConfiguration이 동작하지 않도록 제외 시키는 역할을 수행한다.
  - [org.springframework.boot.autoconfigure.condition.OnBeanCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnBeanCondition.java)

    특정 bean들의 존재유무에 대해서 다루는 필터이다.

    대상 : @ConditionalOnBean, @ConditionalOnMissingBean, @ConditionalOnSingleCandidate

  - [org.springframework.boot.autoconfigure.condition.OnClassCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnClassCondition.java)

    특정 class들의 존재유무에 대해서 다루는 필터이다.

    대상 : @ConditionalOnClass, @ConditionalOnMissingClass

  - org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnWebApplicationCondition.java)

    WebApplicationContext의 존재유무에 대해서 다루는 필터이다.

    대상 : @ConditionalOnWebApplication, @ConditionalOnNotWebApplication

  

#### 4.2.5.5 @ConditionalOnMissingBean

- **[@ConditionalOnMissingBean](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnMissingBean.html)은 특정 bean이 사전에 생성되지 않은 경우 조건이 만족된다.** 
- @Bean과 함께 사용된다면 이미 생성된 bean이 없을 때 해당 bean을 생성한다는 의미이다.
- 특정 bean을 생성하도록 설정해놨다면, 일반적으로 AutoConfiguration의 bean생성 순서가 마지막에 오도록 AutoConfiguration이 잘 짜여져있기 때문에 우리가 설정한 bean이 먼저 생성되고 해당 AutoConfiguration은 필터링 되어 중복생성되는 상황을 막는다. 우리가 해당 bean을 설정하지 않았다면 AutoConfiguration에서는 해당 bean을 자동 생성하게 된다.
- ThreadPoolTaskExecutor bean을 생성하는 [TaskExecutionAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/task/TaskExecutionAutoConfiguration.java)를 예로 들어보자.

```java
TaskExecutionAutoConfiguration.java
...
@Configuration(proxyBeanMethods = false)
public class TaskExecutionAutoConfiguration {

    /**
     * Bean name of the application {@link TaskExecutor}.
     */
    public static final String APPLICATION_TASK_EXECUTOR_BEAN_NAME = "applicationTaskExecutor";

    ...

    @Lazy
    @Bean(name = { APPLICATION_TASK_EXECUTOR_BEAN_NAME,
        AsyncAnnotationBeanPostProcessor.DEFAULT_TASK_EXECUTOR_BEAN_NAME })
    @ConditionalOnMissingBean(Executor.class)
    public ThreadPoolTaskExecutor applicationTaskExecutor(TaskExecutorBuilder builder) {
        return builder.build();
    }

}
```

- @Lazy가 걸려있기 때문에 Spring Boot 기동시에 생성되지 않고 ThreadPoolTaskExecutor가 필요한 상황에서 bean이 생성이 요청된다.
-  Executor.class와 같은 class type인 bean이 이미 생성되지 않은 경우에 @ConditionalOnMissingBean 조건이 만족되고 bean생성이 진행된다. 
- 즉, 우리가 아래와 같은 Executor bean을 생성하는 설정을 해뒀다면 우리가 설정한 bean이 생성되고 TaskExecutionAutoConfiguration 에 의해서는 bean생성이 이뤄지지 않는다. 반대로 우리가 Executor bean 등록을 설정하지 않았더라도 필요한 상황이되면 해당 bean이 생성되게 된다.

```java
CustomizedAsyncConfig.java
...

@Configuration
public class CustomizedAsyncConfig {

    @Bean(name = "threadPoolTaskExecutor")
    public Executor threadPoolTaskExecutor() {
        ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
        taskExecutor.setCorePoolSize(3);
        taskExecutor.setMaxPoolSize(30);
        taskExecutor.setQueueCapacity(10);
        taskExecutor.setThreadNamePrefix("Executor-");
        taskExecutor.initialize();
        return taskExecutor;
    }
}
```



#### 4.2.5.6 @ConditionalOnBean

- **[@ConditionalOnBean](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnBean.html)은 특정 bean이 이미 생성되어있는 경우에만 조건이 만족된다.** 
- 작업을 위해 필수적으로 필요한 bean이 미리 생성되어있는지 체크할 때 사용할 수 있다.

- 예를들어, JdbcTemplate를 생성하기 위해서는 DataSource가 필요한 경우  아래의 JdbcTemplate bean 생성 설정은 @ConditionalOnBean이 함께 사용되어 dataSource라고 정의된 bean이 존재할 때만 JdbcTemplate bean을 생성한다.
-  만약에 dataSource가 존재하지 않는다면 JdbcTemplate을 만들 수도 없을 뿐더러 만들 필요가 없기 때문에 auto configuration 과정에서 JdbcTemplate을 bean 생성을 진행하지 않는다.

```java
    @Bean 
    @ConditionalOnBean(name={"dataSource"}) 
    public JdbcTemplate jdbcTemplate(DataSource dataSource) {
        return new JdbcTemplate(dataSource); 
    }
```

- 참고로, 실제 [JdbcTemplateAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/JdbcTemplateAutoConfiguration.java)은 @ConditionalOnBean을 사용하지는 않는다.



#### 4.2.5.7 @ConditionalOnClass

- **[@ConditionalOnClass](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnClass.html)은 classpath에 특정 class가 존재할 때만 조건이 만족된다.**
- 작업을 위해 필수적으로 필요한 의존성이 등록되어 있는지 체크할 때 사용할 수 있다.

- [H2ConsoleAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/h2/H2ConsoleAutoConfiguration.java)을 예로들어 좀 더 자세히 살펴보면 브라우저에서 접근 가능한 H2 DB 콘솔 화면을 자동으로 구성하는 내용이다.

```java
H2ConsoleAutoConfiguration.java
package org.springframework.boot.autoconfigure.h2;

...

@Configuration(proxyBeanMethods = false)
@ConditionalOnWebApplication(type = Type.SERVLET)
@ConditionalOnClass(WebServlet.class)
@ConditionalOnProperty(prefix = "spring.h2.console", name = "enabled", havingValue = "true", matchIfMissing = false)
@AutoConfigureAfter(DataSourceAutoConfiguration.class)
@EnableConfigurationProperties(H2ConsoleProperties.class)
public class H2ConsoleAutoConfiguration {

    private static final Log logger = LogFactory.getLog(H2ConsoleAutoConfiguration.class);

    @Bean
    public ServletRegistrationBean<WebServlet> h2Console(H2ConsoleProperties properties, ObjectProvider<DataSource> dataSource) {

        ...

        String path = properties.getPath();
        String urlMapping = path + (path.endsWith("/") ? "*" : "/*");
        ServletRegistrationBean<WebServlet> registration = new ServletRegistrationBean<>(new WebServlet(), urlMapping);

        ...

        return registration;
    }

}
```

- WebServlet.java 파일이 classpath에 존재해야지만 @ConditionalOnClass의 조건이 만족된다. 결국 WebServlet.java를 가진 spring-boot-stater-web 과 같은 의존성이 추가되어있는 상황에서만 H2ConsoleAutoConfiguration은 동작하게 된다.

- 그 외 다른 조건들의 의미는 다음과 같다.
  - @ConditionalOnWebApplication : servlet 타입의 web application 일 경우
  - @ConditionalOnProperty : 프로퍼티에 spring.h2.console.enabled=true가 있는 경우
  - @AutoConfigureAfter : DataSourceAutoConfiguration 이 먼저 진행 된 후에 처리 된다.
  - @EnableConfigurationProperties : [H2ConsoleProperties](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/h2/H2ConsoleProperties.java)를 이용해서 관련 프로퍼티 정보를 읽어온다.

- 위의 조건들 모두가 만족된다면 ServletRegistrationBean bean이 생성되고 브라우저로 /h2-console 에 접근하면 console을 사용할 수 있게 되고 이 모든 과정은 auto configuration에 의해서 진행되고 아래와 같은 H2에 대한 의존성 주입과 프로퍼티 설정만으로도 H2 web console을 사용할 수 있게 된다.

```
pom.xml
    ...
    <dependency>
        <groupId>com.h2database</groupId>
        <artifactId>h2</artifactId>
    </dependency>
    ...
application.properties
...
spring.h2.console.enabled=true
```



#### 4.2.5.8 Disabling Specific Auto-configuration Classes

- 만약 **특정 AutoConfiguration을 사용하지 않으려고 한다면 아래와 같이 exclude 설정**을 하면 된다.

```
import org.springframework.boot.autoconfigure.*;
import org.springframework.boot.autoconfigure.jdbc.*;
import org.springframework.context.annotation.*;

@Configuration
@EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class})
public class MyConfiguration {
    ...
}
```





### 4.2.6 Spring Initializr

#### https://start.spring.io/

- **Spring Boot 프로젝트를 쉽게 생성할 수 있는 도구를 제공한다.** 
- 빌드 시스템 및 패키징, 언어, 패키징, 플랫폼 버전 및 프로젝트에 추가할 종속성에 대한 설정을 제공한다.

[![img](./assets/image-20220627130205043.png)](https://github.com/kirobo77/scg/blob/main/assets/image-20220627130205043.png)

- Spring Initializr은 다양한 **IDE 환경 및 API/CLI 형태로도 제공**한다.



## 4.3 Spring Boot를 활용한 아키텍처 구성

### 4.3.1 포트와 어댑터 

- **포트는 바로 인터페이스**이다. 예를 들면 클래스의 메서드 시그니처나 Java의 인터페이스가 바로 포트라고 할 수 있다. 
- **어댑터는 클라이언트에 제공해야 할 인터페이스를 따르면서도 내부 구현은 서버의 인터페이스로 위임**하는 것이다.
- 아래 코드는 책이나 DVD 같은 대여물의 대여와 반납을 관리하는 애플리케이션의 이다.

```java
@Service
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    @Autowired
    public TotalRentalServiceImpl(CustomerRepository customerRepository,
                                  RentalRepository rentalRepository,
                                  InventoryService inventoryService,
                                  RentalHistoryRepository rentalHistoryRepository) {
        this.customerRepository = customerRepository;
        this.rentalRepository = rentalRepository;
        this.inventoryService = inventoryService;
        this.rentalHistoryRepository = rentalHistoryRepository;
    }
 
    @Override
    public RentalHistory rent(RentalTarget target) {
        Customer borrower = customerRepository.find(target.customerId())
                                              .orElseThrow(() -> new NotFoundException(target.customerId()));
        Rental rental = rentalRepository.find(target.rentalId())
                                        .orElseThrow(() -> new NotFoundException(target.rentalId()));
        Item rentedItem = inventoryService.rent(rental, borrower)
                                          .orElseThrow(AlreadyRentedException::new);
        RentalHistory history = RentalHistory.of(UUID.randomUUID().toString(),
                                                 RentalSpec.of(borrower, rental),
                                                 rentedItem);
        rentalHistoryRepository.save(history);
        return history;
    }
}
```

- 이 서비스는 `TotalRentalService`를 구현하여 `RentalHistory rent(RentalTarget)`라는 인터페이스를 제공하고 있다.
-  만약 MVC 패턴을 채택했다면 이 서비스의 `rent()`를 사용하는 것은 컨트롤러이다. 
- 컨트롤러는 다시 HTTP를 통한 인터페이스를 클라이언트에게 제공하여 클라이언트가 `TotalRentalService`를 이용할 수 있도록 중간 역할을 한다. 이를 그림으로 나타내면 다음과 같다.

![img](./assets/1657785410947.png)클라이언트와 애플리케이션의 통신 간 컨트롤러의 위치와 역할

- 이때 `TotalRentalService`는 인터페이스를 제공하므로 포트이며, 위 코드에선 `rent()`가 포트가 된다. 컨트롤러는 클라이언트의 HTTP API 요청을 받아 `rent()`라는 인터페이스를 연결해주고 있으므로 어댑터이다. 
- 이렇게 **외부에서 요청해야 동작하는 포트와 어댑터를 주요소(primary)라고 하며, 포트와 어댑터에 따라 주포트 혹은 주어댑터**라고도 부른다.

- `TotalRentalService`의 구현체는 내부적으로 `CustomerRepository`나 `RentalRepository`, `InventoryService` 인터페이스를 사용한다. 만약 `Repository`가 데이터의 영속을 위해 Redis를 사용한다면 아래 그림과 같이 표현할 수 있다.

![img](./assets/1657785452997.png)그림] 애플리케이션과 기반 요소의 통신 간 Repository의 위치와 역할

- `Repository`나 `Service`는 `TotalRentalService`가 사용할 인터페이스를 제공하고 있기 때문에 포트이다. 위 코드의 `rentalRepository.find()`나 `inventoryService.rent()`를 예로 들 수 있다.
- Repository가 Redis와 프로토콜을 이용해 통신하고 있다면 `RedisRepository`와 같은 구현체가 있으며 이 구현체는 Repository라는 인터페이스를 따르면서 내부적으로 Redis 프로토콜과 연결해 주므로 어댑터이다.
- **애플리케이션이 호출하면 동작하는 포트와 어댑터를 부요소(secondary)라고 한다. 역시 부포트 또는 부어댑터**라고 부를 수 있다.

- 아래는 포트와 어댑터 아키텍처를 따른 소프트웨어와 인터페이스, 기반 요소와의 관계를 표현한 그림이다. 

![img](./assets/1657785510912.png)포트와 어댑터의 추상적인 개념

- 앞서 설명드렸던 요소들이 모두 담겨 있는 위 그림을 통해 서로 간의 의존 관계를 파악할 수 있다. 
- 포트
  - 어댑터가 애플리케이션과는 겹치지 않고 포트와 겹쳐 있는 모습으로 미루어 보아 **어댑터가 애플리케이션을 직접 참조하지 않고 포트에 의존**하고 있다는 것을 알 수 있으며 포트는 변경이 잦은 어댑터와 애플리케이션의 결합도를 낮추는 역할을 한다. 
  - **애플리케이션은 핵심 로직에 가까우므로 결합도를 낮추는 것**이 매우 중요하다. 
  - 또한 애플리케이션은 도메인에 의존하지만 도메인은 애플리케이션과 어댑터에 전혀 의존하지 않는다. 따라서 애플리케이션이나 어댑터가 변경되어도 핵심 로직인 도메인은 아무런 영향을 받지 않는다.
- 어댑터
  - 주요소 쪽의 HTTP와 RPC는 각각의 어댑터를 통해 애플리케이션을 이용한다. 
  - 그러나 각각의 **어댑터는 결국 하나의 포트**를 사용한다. 
  - 만약 웹소켓이 필요하다면 웹소켓 어댑터를 새로 만들어서 추가하면 된다. 
  - 새로운 **어댑터를 추가하는 동안 포트가 애플리케이션과 도메인을 보호**하며 부요소 쪽에는 애플리케이션이 이용하는 기반 요소들이 있다. 
  - 위 그림에서는 저장소로 MySQL을 사용하고 있는 것을 확인할 수 있다.
  - 앞서 주요소 쪽에서 본 것과 다르게 기반 요소의 포트와 어댑터는 일반적으로 1:1 관계이며 이것은 하나의 포트에 여러 어댑터가 있다거나 새로 추가될 일은 거의 없다는 의미이다. 
- 기존에 사용하던 어댑터가 교체될 가능성은 충분이 있으며 빠른 속도가 필요하다면 MySQL을 Redis로 교체할 필요성이 있을 경우 Redis의 어댑터를 포트의 인터페이스에 준해서 만들고, 교체하면 된다. 이때도 역시 포트가 애플리케이션과 도메인을 보호한다.
- **Spring**
  -  Spring Data JPA를 쓸 때 보통 인터페이스는 만들지만 구현체는 만들지 않는다. 
  - Spring Data JPA가 구현체 즉 어댑터를 만들어 준다.
  - 만약 Spring Data Redis를 도입하더라도 먼저 만들어 둔 Repository들은 인터페이스, 즉 포트이므로 수정사항이 없다.
  - Spring Data Redis가 Redis와 통신하는 어댑터를 만들어준다. 



### 4.3.2 포트와 어댑터 아키텍처 구성

- 애플리케이션의 코드를 구조화 하기 위해 패키지나 네임스페이스 등을 활용하며 포트와 어뎁터 아키턱처를 위한 패키지 구조는 다음과 같다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        // ...
        return history;
    }
}
```



```markup
└── com
    └── portandadpater
        └── rentalapp
            ├── application
            │   ├── AlreadyRentedException.java
            │   ├── NotFoundException.java
            │   ├── RentalTarget.java
            │   ├── TotalRentalService.java
            │   └── TotalRentalServiceImpl.java
            ├── domain
            │   ├── model
            │   │   ├── customer
            │   │   │   ├── Customer.java
            │   │   │   └── CustomerRepository.java
            │   │   ├── history
            │   │   │   ├── RentalHistory.java
            │   │   │   └── RentalHistoryRepository.java
            │   │   └── rental
            │   │       ├── Item.java
            │   │       ├── Rental.java
            │   │       └── RentalRepository.java
            │   └── service
            │       └── rental
            │           └── InventoryService.java
            │
            ├── infrastructure
            └── interfaces
```

- 이 구조는 **포트와 어댑터 아키텍처에 반드시 필수 형태는 아니며 아키텍처 원칙에 맞다면 프로젝트 성격에 따라 달라질 수 있다.**
-  위 패키지 구조에서 `domain`엔 주로 업무 로직을 포함하는 클래스들이 들어선다. 
- application`은 주로 유스케이스(usecases)가 작성된 클래스를 포함한다. 이 계층엔 업무 로직이 거의 없고, `domain`의 여러 업무 로직을 조합하는 역할을 한다. 
- interfaces`는 클라이언트와 약속한 통신 방식의 어댑터를 포함한다. 이곳에 포함되는 어댑터는 주어댑터이며, 주로 MVC의 컨트롤러나 RPC 서비스 등이다.`
- infrastructure`는 기반 요소, 즉 다른 서비스를 사용하는 어댑터를 포함한다. 이곳에 포함되는 어댑터는 부어댑터이다. 예를 들면 Kafka나 Redis, MySQL 또는 다른 서비스의 API를 사용하는 구현체가 포함되는 패키지이다.
- 일반적인 레이어드 구조의 패키지를 포트앤아답터 구조의 패키지로 변환하는 예이다.

```markup
└── com
    └── layered
        └── sally
            ├── controller
            │   ├── MembershipController.java
            │   └── StoreController.java
            ├── dto
            │   ├── RegisterRequest.java
            │   ├── RegisterResponse.java
            │   ├── StoreRequest.java
            │   ├── StoredItemDto.java
            │   └── UserDto.java
            ├── entity
            │   ├── User.java
            │   ├── Item.java
            ├── persistence
            │   ├── ItemRepository.java
            │   └── UserRepository.java
            └── service
                ├── InventoryService.java
                ├── MembershipService.java
                ├── TotalRentalService.java
                └── TotalRentalServiceImpl.java
```

- `controller`의 `MembershipController`와 `StoreController`는 서로 전혀 참조하지 않을 것 같지만 같은 패키지에 들어 있다. 
- `persistence`의 `ItemRepository`와 `UserRepository`도 서로 참조하지 않는다. 
- 패키지는 서로 연관이 있는 클래스를 한 데 모으고 응집도를 높이는 역할을 해야 한다. 
- 패키지 조직만 잘해도 응집도가 높은 패키지 구조([참고](https://en.wikipedia.org/wiki/Package_principles))를 작성할 수 있다.
- 이 패키지 구조를 포트와 어댑터 아키텍처를 따른 패키지 구조로 리팩터링한다면 다음과 같다.

```markup
└── com
    └── linecorp
        └── sally
            ├── application
            │   ├── impl
            │   │   └── TotalRentalServiceImpl.java
            │   ├── InventoryService.java
            │   └── TotalRentalService.java
            ├── domain
            │   ├── item
            │   │   ├── Item.java
            │   │   └── ItemRepository.java
            │   └── member
            │       ├── MembershipService.java
            │       ├── User.java
            │       └── UserRepository.java
            └── interfaces
                ├── common
                │   ├── StoredItemDto.java
                │   └── UserDto.java
                ├── member
                │   ├── MembershipController.java
                │   ├── RegisterRequest.java
                │   └── RegisterResponse.java
                └── store
                    ├── StoreController.java
                    └── StoreRequest.java
```

- `RegisterRequest`와 `RegisterResponse`는 아마도 `MembershipController`외에는 사용할 것 같지 않으므로 같은 패키지에 넣어둔다.
- 이렇게 하면 `RegisterRequest`와 `RegisterResponse`의 접근 제어자를 패키지 수준으로 제한할 수 있다.
- **접근 제어자를 제한해 놓으면 두 클래스는 다른 패키지에서 전혀 관심 가질 필요가 없다는 의도를 명확히 표현**할 수 있다.
- 또 클래스가 격리되므로 불필요한 의존성을 막거나 불특정 다수에게 참조될 위험성을 미연에 방지할 수 있다.
- 패키지 구조를 바꿈으로써 우리는 응집도를 높이고 모듈화라는 패키지 본연의 기능을 극대화할 수 있다.



### 4.3.3 포트와 어댑터 아키텍처 적용 사례

- 애플리케이션에 속하는 이 서비스는 `rent()` 메서드를 실행하기 위해 `RentalTarget` 객체를 요구하고 있다. 
- 이는 인터페이스, 즉 이 메서드를 호출하는 클라이언트와의 약속이다. 

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        // ...
        return history;
    }
}
```

- 종종 어댑터인 컨트롤러의 매개변수가 그대로 애플리케이션이나 도메인 쪽으로 넘어오는 사례가 있다. 컨트롤러가 아래와 같이 호출하는 경우이다.

```java
public class RentalController {
     
    private final TotalRentalService totalRentalService;
 
    // ...
    public Response<RentalHistoryView> rent(@RequestBody RentParam param) {
        // ...
        totalRentalService.rent(param); // 애플리케이션이 어댑터를 알게 되는 상황
        // ...
    }
}
```

- `totalRentalService.rent()`에 `param`을 넣는 것을 보니 `rent()`의 시그니처는 `RentalHistory rent(RentParam param)`이다. 
- 클라이언트와 컨트롤러 사이의 인터페이스가 컨트롤러와 애플리케이션 간의 인터페이스로 사용되었다.
- 이런 상황은 포트와 어댑터가 구분되어 있다고 할 수 없으며  클라이언트의 인터페이스가 애플리케이션까지 변경할 수 있으므로 결합도가 높은 상황이다.
-  여기에 RPC 서비스를 새로 붙여서 애플리케이션에 연동할 경우 아래와 같은 상황이 발생한다.
  -  RPC 서비스는 주로 [IDL](https://ko.wikipedia.org/wiki/인터페이스_정의_언어)을 사용하고 [DTO](https://ko.wikipedia.org/wiki/데이터_전송_객체)를 별도로 생성한다. 
  - 아마 `RentParam`을 사용하지 않을 테지만, 애플리케이션을 사용하기 위해 RPC 서비스에선 굳이 `RentParam`을 생성하여 매개변수로 사용해야 한다.
  -  이때 HTTP 어댑터인 컨트롤러에서 요구 사항이 변경되어 `RentParam`을 변경해야 한다면, 애플리케이션뿐만 아니라 RPC 서비스까지 변경해야 한다.
- 포트앤어댑터 아키텍처에선 어댑터가 애플리케이션을 일방적으로 알고 있기 때문에 어댑터가 애플리케이션에 맞춰야 한다. 
- 아래는 `RentParam`을 `RentalTarget`으로 변경하여 메서드를 호출하는 예제이다.

```java
public class RentalController {
     
    private final TotalRentalService totalRentalService;
    // ...
 
    public Response<RentalHistoryView> rent(@RequestBody RentParam param) {
        // ...
        totalRentalService.rent(param.toRentTarget());
        // ...
    }
}
```

- 부포트와 어댑터 역시 크게 다르지 않다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        //...
 
        Item rentedItem = inventoryService.rent(rental, borrower).orElseThrow(AlreadyRentedException::new);
        // ...
        return history;
    }
}
```

- `inventoryService`에 `HttpInventoryService`라는 어댑터를 주입했다고 가정할 경우 일반적으로 네트워크를 통해 하나의 서비스에서 다른 서비스를 호출하며 이때 주로 HTTP 인터페이스를 사용하게 된다. 
- 그런데 처음 서비스를 연동할 때에는 API가 추가되거나 변경된다고만 생각할 뿐, 연동하는 서비스 자체가 바뀔 거라는 생각은 잘 하지 않기 때문에 연동한 서비스의 DTO를 바로 반환하는 방법이 일반적이다.

```java
public class HttpInventoryService implements InventoryService {
    // ...
 
    @Override
    public Optional<StoredItem> rent(Rental rental, Customer borrower) {
        // ... HTTP 통신
        // ... JSON 역직렬화
        return Optional.of(storedItem);    
    }
}
```

- `HttpInventoryService`는 HTTP를 이용해 받아 온 JSON을 역직렬화하여 `StoredItem` 객체를 만든다. 
- 예제와 같이 애플리케이션 계층에서 사용하는 `Item`이 아니라 외부 `InventoryService`에서 얻어 온 StoredItem을 반환하는 경우가 많으며InventoryService`를 고도화하여 향상된 `InventoryService`가 출시되었고, 모든 클라이언트에게 API를 변경해야 하는 상황이 발생 하게 된다.
  - 만약 포트와 어댑터 아키텍처대로 설계했다면, 어댑터를 하나 더 생성하여 `HttpInventoryService`를 대체하면 되나 새로 생성한 어댑터에서는 더 이상 `StoredItem`을 사용할 수 없게 되었다.
  - 향상된 `InventoryService`에서 제공하는 JSON의 구조가 아래와 같이 변경되었기 때문이다.
  - 이렇게 되면 DTO를 변경해야 하고, 결국 애플리케이션 영역에 있는 `TotalRentalService`에도 영향을 준다. 

```json
// 기존 JSON
{ "itemId": "ID", "itemStatus": "AVAILABLE", "rentalId": "RID", rentalName": "NAME" }
// 향상된 JSON
{ "item": { "id": "ID", "status": "AVAILABLE" }, "rental": { "id": "RID", "name": "NAME" } }
```

- 이를 방지하기 위해서는 **주어댑터와 마찬가지로 부어댑터가 부포트를 준수**하면 된다.

```java
public class HttpInventoryService implements InventoryService {
    // ...
 
    @Override
    public Optional<Item> rent(Rental rental, Customer borrower) {
        // ... HTTP 통신
        // ... JSON 역직렬화
        return Optional.of(storedItem.toItem());
    }
}
```

- 포트와 어댑터 아키텍처를 따랐다면 향상된 `InventoryService`가 JSON 구조를 바꿨다고 해도 걱정할 필요 없으며. 담고 있는 요소가 변경되지 않는 이상, 새로운 어댑터를 추가하는 것만으로도 기반 요소 변경에 쉽게 대응할 수 있다. 

- 새로 추가된 어댑터는 여전히 JSON을 역직렬화하여 `Item` 객체를 만들 수 있고, 데이터를 애플리케이션에 제공할 수 있다.

  > **어플리케이션 개발 시 주고받는 데이터 형태에만 신경 써선 안된다. 예를들어 MyBatis를 쓰고 있다고 해서 Repository의 인터페이스를 `queryList()`와 같이 작성하면 이 인터페이스는 애플리케이션이 아니라 MyBatis에 의존하게 된다.** 

  > **저장소를 Redis로 바꾸게 되면 `queryList()`는 어색한 인터페이스로 남으며 이 메서드를 `commandList()`로 바꿔야 할 것 같지만 그러기 위해선 애플리케이션이나 도메인 영역을 함께 변경해야하므로 인터페이스 자체를 어느 한쪽에 치우치게 설계하지 말고 도메인 관점에서 도메인이 필요로 하는 인터페이스를 설계해야 한다.**




### 4.3.4 테스트

- 포트와 어댑터 아키텍처로 만든 애플리케이션은 테스트하기가 매우 쉽다. 
- **업무 로직을 포트가 감싸고 있기 때문에 모의 어댑터를 붙여 애플리케이션을 쉽게 구동해 볼 수 있어서 단순하게 테스트**할 수 있다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    public TotalRentalServiceImpl(CustomerRepository customerRepository,
                                  RentalRepository rentalRepository,
                                  InventoryService inventoryService,
                                  RentalHistoryRepository rentalHistoryRepository) {
        this.customerRepository = customerRepository;
        this.rentalRepository = rentalRepository;
        this.inventoryService = inventoryService;
        this.rentalHistoryRepository = rentalHistoryRepository;
    }
 
    @Override
    public RentalHistory rent(RentalTarget target) {
        Customer borrower = customerRepository.find(target.customerId())
                                              .orElseThrow(() -> new NotFoundException(target.customerId()));
        Rental rental = rentalRepository.find(target.rentalId())
                                        .orElseThrow(() -> new NotFoundException(target.rentalId()));
        Item rentedItem = inventoryService.rent(rental, borrower)
                                          .orElseThrow(AlreadyRentedException::new);
        RentalHistory history = RentalHistory.of(UUID.randomUUID().toString(),
                                                 RentalSpec.of(borrower, rental),
                                                 rentedItem);
        rentalHistoryRepository.save(history);
        return history;
    }
}
```

- 위 애플리케이션 서비스는 네 개의 포트를 이용하고 있다. 
- 세 개의 Repository와 하나의 Service는 내부가 어떻게 구성되어 있는지 모른다고 가정하고 저장소로 MySQL을 사용할 수도 있고 Redis를 사용할 수도 있으며 Service는 RPC를 이용할 수도, HTTP를 이용할 수도 있다.
- 포트앤아답터 아키텍처에서는 애플리케이션 서비스를 실행하는 데에는 아무런 문제가 발생하지 않는다.
- 아래는 Seudo 코드로 테스트 코드를 작성한 것이다.

```markup
@Test
fun `rent should return a history`() {
    val customer = Customer("CUSTOMER_ID")
    val rental = Rental("RENTAL_ID")
    val item = Item()
    var saved: RentalHistory
 
    // 모의 어댑터를 준비한다.
    val customerRepository = CustomerRepository {
        override fun find(id) = customer
    }
    val rentalRepository = RentalRepository {
        override fun find(id) = rental
    }
    val inventoryService = InventoryService {
        override fun rent(rental, customer) = item
    }
    val rentalHistoryRepository = RentalHistoryRepository {
        override fun save(history) {
            saved = history
        }
    }
 
    // 테스트할 객체를 준비하고
    val service: TotalRentalService = TotalRentalServiceImpl(customerRepository, rentalRepository, inventoryService, rentalHistoryRepository)
 
    // 테스트할 대상을 실행한다.
    val result = service.rent(RentalTarget("CUSTOMER_ID", "RENTAL_ID"))
 
    // 결과를 검증한다.
    assertNotNull(result)
    assertNotNull(saved)
    assertSame(result, saved)
    assertEquals(customer, result.borrower)
    assertEquals(rental, result.rental)
    assertEquals(item, result.rentedItem)
}
```

- 단위 테스트는 Whitebox 테스트이므로 각각의 모의 어댑터를 실행했을 때 어떻게 동작하고 어떤 값을 반환하는지 예상할 수 있다. 
- 그러므로 모의 어댑터에 기대하는 동작을 정의하고 실제 서비스를 실행한 다음, 기대했던 결과와 일치하는지 확인할 수 있다.

- 그런데 이때 애플리케이션의 저장소로 MySQL을 사용했고 Repository가 MySQL에 강하게 결합하고 있다면 같은 코드를 테스트하기 위해선 개발 장비에 MySQL을 설치하고 애플리케이션이 동작할 수 있는 스키마로 테이블을 생성한 뒤 모의 데이터까지 삽입하고 나서야 테스트를 실행할 수 있다.

- 모의 테스트 프레임워크를 사용하면 결합도 높은 클래스라도 쉽게 모의 객체를 만들어 주긴 하지만 클래스의 결합도가 높다면 단위 테스트를 할 때 'MySQL 쿼리에 오류가 있으면 어떡하지?'와 같은 고민을 하게 된다. 그런 일이 늘어나면 결국 단위 테스트는 통합 테스트가 되며  포트앤어댑터 아키텍처로 설계하면 이런 고민을 하지 않아도 된다.

  > **업무 로직은 포트만 알면 된다.**



## 4.4 Spring Cloud란?

### 4.4.1 개요

https://spring.io/projects/spring-cloud

- **마이크로 서비스의개발, 배포, 운영에 필요한 아키텍처를 쉽게 구성할 수 있도록 지원하는 Spring Boot기반의 프레임워크이다.**

- Spring Cloud는 개발자가 분산 시스템에서 일부 공통 패턴(예: 구성 관리, 서비스 검색, 회로 차단기, 지능형 라우팅, 마이크로 프록시, 제어 버스, 일회성 토큰, 글로벌 잠금, 리더십 선출, 분산 세션, 클러스터 상태)을 구현하는 서비스와 애플리케이션을 신속하게 구축할 수 있다.

- 개발자 자신의 랩톱, 베어메탈 데이터 센터 및 Cloud Foundry와 같은 관리 플랫폼을 포함한 모든 분산 환경에서 잘 작동한다.

- [Spring Cloud 와 Kubernetes의 비교](https://bryceyangs.github.io/study/2021/07/28/MSA-SpringCloud-vs-Kubernetes/)

  

### 4.4.2 특징

Spring Cloud는 일반적인 사용 사례에 대한 우수한 즉시 사용 가능한 경험과 다른 사용자를 포괄하는 확장성 메커니즘을 제공한다.

- 분산/버전 구성
- 서비스 등록 및 검색
- 라우팅
- 서비스 간 호출
- 부하 분산
- 회로 차단기
- 전역 잠금
- 리더십 선거 및 클러스터 상태
- 분산 메시징



### 4.4.3 Spring Cloud / Spring Boot 의존관계

- 기존 Spring Boot 앱인 경우 해당 앱에 Spring Cloud를 추가하려는 경우 첫 번째 단계는 사용해야 하는 Spring Cloud 버전을 지정해야 한다.

- 어플리케이션에서 사용하는 버전은 사용 중인 Spring Boot 버전에 따라 다르다.

| Release Train                                                | Boot Version                          |
| :----------------------------------------------------------- | :------------------------------------ |
| [2021.0.x](https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2021.0-Release-Notes) aka Jubilee | 2.6.x, 2.7.x (Starting with 2021.0.3) |
| [2020.0.x](https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes) aka Ilford | 2.4.x, 2.5.x (Starting with 2020.0.3) |
| [Hoxton](https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-Hoxton-Release-Notes) | 2.2.x, 2.3.x (Starting with SR5)      |
| [Greenwich](https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Greenwich-Release-Notes) | 2.1.x                                 |
| [Finchley](https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Finchley-Release-Notes) | 2.0.x                                 |
| [Edgware](https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Edgware-Release-Notes) | 1.5.x                                 |
| [Dalston](https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Dalston-Release-Notes) | 1.5.x                                 |



### 4.4.4 dependency 설정 

- pom.xml

  ```yaml
  <dependencyManagement>
      <dependencies>
          <dependency>
              <groupId>org.springframework.cloud</groupId>
              <artifactId>spring-cloud-dependencies</artifactId>
              <version>2021.0.1</version>
              <type>pom</type>
              <scope>import</scope>
          </dependency>
      </dependencies>
  </dependencyManagement>
  ```

  - spring-cloud-dependencies 는 취약점 보완 때문에 **2021.0.1** 으로 해야 한다.

  - spring cloud 를 사용하기 위해서는 spring-cloud-dependencies dependencyManagement 를 추가해 주어야 한다.

  - 현재 spring boot 버전은 2.6.6 버전에서 dependency 가 호환 된다.

    

## 4.5 Spring Cloud Gateway

https://github.com/kirobo77/scg/blob/main/APIGateway.md

### 4.5.1 개요

- **Spring Cloud Gateway는 Spring 및 Java 위에 API 게이트웨이를 빌드하기 위한 라이브러리를 제공한다. 여러 기준에 따라 요청을 라우팅하는 유연한 방법을 제공할 뿐만 아니라 보안, 탄력성 및 모니터링과 같은 교차 문제에 중점**둔다.

> API Gateway로써 쉽게 Endpoint의 요청을 받고 API Service에게 라우팅 해주는 서버다.

- Spring Cloud Gateway는 Spring Reactive 생태계 위에 구현된 API Gateway이다. 게이트웨이 핸들러 매핑을 사용하여 들어오는 요청을 적절한 대상으로 라우팅하는 간단하고 효과적인 방법을 제공하며 `Netty`를 사용하여 non-blocking 요청 처리를 제공한다.

### 4.5.2 핵심 요소

- **라우트(Route)** : 라우트는 목적지 URI, 조건자 목록과 필터의 목록을 식별하기 위한 고유 ID로 구성된다. 라우트는 모든 조건자가 충족됐을 때만 매칭된다

  > 대상 URI, 조건부 집합(Predicates), 각종 필터들로 이루어진 요청을 라우팅할 대상들이라고 생각하자.

- **조건자(Predicates)** : 각 요청을 처리하기 전에 실행되는 로직, 헤더와 입력된 값 등 다양한 HTTP 요청이 정의된 기준에 맞는지를 찾는다.

  > Java 8의 Function Predicate로, 라우팅에 필요한 조건이다. 예로 path = /abc 같은 조건이나, request header의 특정 키-값도 조건으로 사용할 수 있다.

- **필터(Filters)** : HTTP 요청 또는 나가는 HTTP 응답을 수정할 수 있게한다. 다운스트림 요청을 보내기전이나 후에 수정할 수 있다. 라우트 필터는 특정 라우트에 한정된다.

  > Spring Framework의 WebFilter 인스턴스이다. Filter에서는 요청 전후로 요청/응답을 추가/수정 할 수 있다.

### 4.5.3 동작 원리

![img](https://velog.velcdn.com/images%2Fjeb1225%2Fpost%2Fb4a8b2a9-30b4-49bf-adb6-8166a8075acd%2Fspring_cloud_gateway_diagram.png)

1. 클라이언트는 Spring Cloud Gateway에 요청한다.
2. 게이트웨이 핸들러 매핑이 요청이 경로와 일치한다고 결정하면 게이트웨이 웹 핸들러로 전송된다.
3. 이 핸들러는 요청과 관련된 필터 체인을 통해 요청을 실행한다. 필터가 점선으로 구분되는 이유는 필터가 프록시 요청을 보내기 전후에 로직을 실행할 수 있기 때문이다.
4. 모든 pre 필터 로직 실행된다. 
5. 프록시 요청 실행된다.
6. post 필터 로직가 실행된다.





## 4.6 Spring Cloud Config

### 4.6.1 개요

- **Spring Cloud Config는 분산 시스템에서 외부화된 설정 정보를 서버 및 클라이언트에게 제공하는 시스템이다. 설정 서버는(Config Server)는 외부에서 모든 환경에 대한 정보들을 관리해주는 중앙 서버이다**. 
- 설정 정보 저장을 위해 git을 사용하도록 되어있어서 손쉽게 외부 도구들로 접근 가능하고, 버전 관리도 가능하다.
- Spring Cloud Config Server(설정 서버): 버전 관리 레포지토리로 백업된 중앙 집중식 구성 노출을 지원한다.
- Spring Cloud Config Client(설정 클라이언트) : 애플리케이션이 설정 서버에 연결하도록 지원한다.



![img](https://blog.kakaocdn.net/dn/QC4Xs/btrCS0QoktP/JTWsRVzvK4EBGTUbqlbu5K/img.png)



### 4.6.2 Spring Cloud Config의 장점과 단점

- Spring Cloud Config 는 여러 서비스 들의 설정 파일을 외부로 분리해 하나의 중앙 설정 저장소 처럼 관리 할 수 있도록 해주며 특정 설정 값이 변경시 각각의 서비스를 재기동 할 필요없이 적용이 가능하도록 도와준다.
  - 여러 서버의 설정 파일을 중앙 서버에서 관리할 수 있다. 
  - 서버를 재배포 하지 않고 설정 파일의 변경사항을 반영할 수 있다.

- 하지만 이것이 모든 문제를 해결해주지는 않는다. Spring Cloud Config를 이용하면 다음의 문제들을 겪을 수 있으므로 주의해야 한다.
  - Git 서버 또는 설정 서버에 의한 장애가 전파될 수 있다.
  - 우선 순위에 의해 설정 정보가 덮어씌워질 수 있다.

- 이미 서비스가 실행중이라면 메모리에서 설정 정보를 관리해 문제가 없지만, 서비스가 시작될 때 만약 GIT 서버나 설정 서버에 문제가 있다면 서비스들까지 문제가 전파될 수 있다. 또한 설정 서버에 의해 장애 지점이 될 수 있으므로 설정 정보를 관리하기 위한 별도의 서비스 운영이 필요할 수도 있다. 또한 설정 파일이 여러 곳에 있을 수 있어 우선 순위에 주의해야 한다.



### 4.6.3 Spring Cloud Config 설정 파일 우선 순위 

- 설정 파일은 크게 다음의 위치에 존재할 수 있으며 다음의 순서대로 읽어진다. 나중에 읽어지는 것이 우선순위가 높다.
  - 프로젝트의 application.yaml
  - 설정 저장소의 application.yaml
  - 프로젝트의 application-{profile}.yaml
  - 설정 저장소의 {application name}/{application name}-{profile}

- 만약 읽어지는 순서대로 읽다가 동일한 값을 지니는 설정 정보가 있다면 덮어 씌워지므로 주의해야 한다. 

- 예를 들어 'hello'이라는 이름의 애플리케이션에 local 프로파일인 환경변수가 로컬의 appliation.yaml, application-local.yaml에 있고, 설정 저장소의 application.yaml, hello/hello-local.yaml에도 있다면 다음의 순서대로 읽어진다.
  - 프로젝트의 application.yaml
  - 설정 저장소의 application.yaml
  - 프로젝트 application-local.yaml
  - 설정 저장소의 hello/hello-local.yaml

- 최종적으로 읽혀 적용되는 환경변수 값은 설정 저장소의 hello/hello-local.yaml 의 값이다. 만약 설정 정보가 산개되어 있다면 오히려 관리가 복잡해질 수 있으며, 동작 과정을 모른다면 장애가 될 수 있으므로 주의해야 한다.

  

### 4.6.5 **ConfigurationProperties**

- *.properties , *.yml 파일에 있는 property를 자바 클래스에 값을 가져와서(바인딩) 사용할 수 있게 해주는 어노테이션

- Spring boot 에서는 운영에 필요한 설정(DB 정보, LOG설정 등등 )들을 *.properties , *.yml 에 써두고 관리한다.
- 이 설정은 KEY - VALUE 의 형태로 저장되어 관리하고 있으며 @Value 을 사용하여 바인딩을 할 수 있다.
- 아래와 같은 properties 파일이 있다고 가정할 때 @Value 를 사용하여 바인딩을 하면 다음과 같은 자바 코드가 나온다.

```properties
site-url.naver=https://www.naver.com
site-url.google=https:/google.com
```

```java
@Value("${site-url.naver}")
private String naver;

@Value("${site-url.google}")
private String google;
```

@Value를 사용하여 바인딩을 하는 방법은 문자열을 사용하기에 오타가 날 수도 있다. 그래서 클래스 파일로 관리하는 방법도 제공한다.

**1. properties에서 오토컴플릿을 지원하도록 하기 위한 dependency를 추가**

```
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-configuration-processor</artifactId>
	<optional>true</optional>
</dependency>
```

**2. 클래스 파일 생성**

@ConfigurationProperties 이 좋은 이유 여러 표기법에 대해서 오토로 바인딩해 준다. ( 아래 참고 )

| acme.my-project.person.first-name | properties 와 .yml에 **권장**되는 표기 방법                  |
| --------------------------------- | ------------------------------------------------------------ |
| acme.myProject.person.firstName   | 표준 카멜 케이스 문법.                                       |
| acme.my_project.person.first_name | .properties와 .yml 에서 사용가능한 방법 ( - 표기법이 더 표준 ) |
| ACME_MYPROJECT_PERSON_FIRSTNAME   | 시스템 환경 변수를 사용할 때 권장                            |

 @Component로 bean을 등록해야 한다.

@ConfigurationProperties에 prifix를 설정한다.

 properties 파일에 있는 site-url.* 에 대하여 바인딩한다.

```
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

import lombok.Data;

@Component
@ConfigurationProperties(prefix = "site-url")
@Data
public class siteUrlProperties {
	private String naver;
	private String google;
	
}
```

 **3. 확인**

```
@Controller
@RequestMapping("/")
@Slf4j
public class MainController {
	
	@Autowired
	siteUrlProperties siteUrlProperties;
	
	@GetMapping("")
	@ResponseBody
	public String test(Model model) {
		return siteUrlProperties.getNaver();
	}
	
}
```

@ConfiguConfigurationProperties 어노테이션을 사용하여 property 값을 사용하면 매핑을 유연하게 할 수 있다는 장점이 있지만 SpEL를 사용할 수 없다.

SpEL를 사용할 때에는 @Value를 사용해야 한다.

 그 외에는 @ConfiguConfigurationProperties를 사용하는게 코드가 깔끔해진다.



## 4.7 Spring Cloud Stream

### 4.7.1 개요

- **Spring Cloud Stream은 공유 메시징 시스템과 연결된 확장성이 뛰어난 이벤트 기반 마이크로서비스를 구축하기 위한 프레임워크이다**.
- Spring Cloud Stream Application과 Message Middleware System 직접 붙지는 않는다.
- 중간에 Spring Cloud Stream이 제공하는 Binder 구현체를 중간에 두고 통신을 하기 때문에 Application에서는 미들웨어 독립적으로 추상화된 방식으로 개발 진행이 가능하다.
- 그리고 Application과 Binder 는 아래 그림과 같이 inputs, outputs 채널과 통신을 하게 된다.

### 4.7.2 Spring Cloud Stream와 연동 가능한 다양한 바인더 구현

- RabbitMQ

- Apache Kafka

- Kafka Streams

- Amazon Kinesis

- Google PubSub *(partner maintained)*

- Solace PubSub+ *(partner maintained)*

- Azure Event Hubs *(partner maintained)*

- AWS SQS *(partner maintained)*

- AWS SNS *(partner maintained)*

- Apache RocketMQ *(partner maintained)*

  

### 4.7.3 Spring Cloud Stream 의 core building blocks 

- Destination Binders: 외부 메시징 시스템과의 통합을 제공하는 구성 요소
- Destination Bindings: 외부 메시징 시스템과 최종 사용자가 제공하는 애플리케이션 코드(생산자/소비자) 간의 브리지
- Message: 생산자와 소비자가 대상 바인더(및 외부 메시징 시스템을 통한 다른 응용 프로그램)와 통신하는 데 사용하는 표준 데이터 구조



### 4.7.4 dependency 설정 

- pom.xml

  ```yaml
  <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-stream-binder-kafka</artifactId>
     <exclusions>
         <exclusion>
             <groupId>org.springframework.cloud</groupId>
             <artifactId>spring-cloud-function-core</artifactId>
         </exclusion>
         <exclusion>
             <groupId>org.springframework.cloud</groupId>
             <artifactId>spring-cloud-function-context</artifactId>
         </exclusion>
         <exclusion>
             <groupId>org.springframework.cloud</groupId>
             <artifactId>spring-cloud-function-web</artifactId>
         </exclusion>
     </exclusions>
  </dependency>
  <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-function-core</artifactId>
     <version>3.2.3</version>
  </dependency>
  <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-function-context</artifactId>
     <version>3.2.3</version>
  </dependency>
  <dependency>
     <groupId>org.springframework.cloud</groupId>
     <artifactId>spring-cloud-function-web</artifactId>
     <version>3.2.3</version>
  </dependency>
   ...
   
  <dependencyManagement>
      <dependencies>
          <dependency>
              <groupId>org.springframework.cloud</groupId>
              <artifactId>spring-cloud-dependencies</artifactId>
              <version>2021.0.1</version>
              <type>pom</type>
              <scope>import</scope>
          </dependency>
      </dependencies>
  </dependencyManagement>
  ```

  - spring-cloud-dependencies 는 취약점 보완 때문에 **2021.0.1** 으로 해야 한다.
  - spring-cloud-function 은 취약점 보완 때문에 **3.2.3** 으로 해야 한다.
  - spring cloud stream 을 사용하기 위해서 spring-cloud-stream-binder-kafka dependency 만 추가해 주면 된다.
  - spring cloud 를 사용하기 위해서는 spring-cloud-dependencies dependencyManagement 를 추가해 주어야 한다.
  - 현재 spring boot 버전은 2.6.6 버전에서 dependency 가 호환 된다.



### 4.7.5 kafka 메시지 Event 전송 (Producer)

#### 4.7.5.1 producer 프로젝트 설정

- application.xml

```yaml
  spring:
      cloud:
          stream:
            kafka:
              binder:
                brokers:
                - sa-cluster-kafka-route-bootstrap-kafka-system.apps.cluster01.cz-dev.icis.co.kr:443
                configuration:
                  security:
                    protocol: SASL_SSL
                  sasl:
                    mechanism: SCRAM-SHA-512
                    jaas:
                      config: org.apache.kafka.common.security.scram.ScramLoginModule required username="order" password="WpxJedx0IIWj";
                  ssl:
                    truststore.location: classpath:/truststore.jks
                    truststore.type: JKS
                    truststore.password: new1234 
            bindings:
              boardCreate-out-0:
                destination: order-board-create
              boardUpdate-out-0:
                destination: order-board-update   
              boardDelete-out-0:
                destination: order-board--delete
```

- bindings : 연결할 Topic을 설정 한다. 

  - boardCreate-out-0 : 이벤트를 전송할 대상이며 producer 인 경우는 보통 "out" 으로 하며 consumer는 "in" 을 사용한다.
  
  - -out-0 : 0은 접속할 brokers의 첫번째 kafka-cluster 주소이다.

  - destination: 연동할 Topic를 등록한다.
  
  - kafka.binder.brokers: kaka-cluster를 연동할 주소들이다. 
    - kafka-cluster가 2개 이상일경우 ","로 구분하여 등록 가능하다.
    - security :  SASL 기반의 TLS로  SASL_SSL 를 등록한다.
    - sasl.mechanism :  SCRAM-SHA-512
    - sasl.jaas : kafka-user의 유저명과 패스워드를 입력 한다. (주의: 끝에 ";" 꼭 추가해야 한다 ) 
  - ssl: kafka-cluster 외부에서 접속하기 위해서 okd의 kafka router는 https로 할당되기 때문에 SSL로 접속 해야 한다. 
  
- 프로젝트에 resource 폴더 하위에 truststore.jks 파일을 위치 시키며 jks 생성시 입력한 password 를 입력해 준다. 
  
- truststore.jks를 resources 하위에 위치 시킨다.
  
    ```
    resources
    ├── config
    │   ├── application-dev.yml
    │   ├── application-local.yml
    │   └── application.yml
    └── truststore.jks
    ```
  
    

#### 4.7.5.2 Events 객체 생성

- BoardCreateEvent.java

  ```java
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardCreateEvent {
      private String eventName;
      private int num;
      private String title;
      private String contents;
      private String writeId;
      private String writeName;
      private LocalDateTime writeDate;
  }
  ```

- BoardUpdateEvent.java

  ```
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardUpdateEvent {
      private String eventName;
      private int num;
      private String title;
      private String contents;
      private String modifyId;
      private String modifyName;      
      private LocalDateTime  modifyDate;
  }
  ```

- BoardDeleteEvent.java

  ```java
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardDeleteEvent {
      private String eventName;
      private int num;
   
  }
  ```

- ResultMessage.java

  ```java
  
  @Getter
  @Setter
  public class ResultMessage {
   
      private String successYn;
      private String statusCode;
      private String code;    
      private String message;
      private String devMessage;
       
       
      public ResultMessage() {       
      }
   
      public ResultMessage(String successYn) {
          this.successYn = successYn;
          this.statusCode = null;
          this.message = null;
          this.devMessage = null;
      }
      public ResultMessage(String successYn, String message) {
          this.successYn = successYn;
          this.statusCode = null;
          this.message = message;
          this.devMessage = null;
      }
       
      public ResultMessage(String successYn,String statusCode, String message, String devMessage) {
          this.successYn = successYn;
          this.statusCode = null;
          this.message = message;
          this.devMessage = null;
      }
   
  }
  
  ```

  

#### 4.7.5.3 kafka 메시지 전송

- BoardEventService.java

  ```java
  @Service
  @AllArgsConstructor
  @Slf4j
  public class BoardEventService {
   
      private final StreamBridge streamBridge;
      private static String SUCCESS = "Y";
   
      public ResultMessage boardCreate(BoardCreateEvent event) {
   
          boolean result = streamBridge.send("boardCreate-out-0", event);
          log.info("====[Producer]====== boardCreate send to kafka Topic  BoardCreateEvent: {} , result :{}", event,
                  result);
          return getReturnResultMessage(result);
   
      }
   
      public ResultMessage boardUpdate(BoardUpdateEvent event) {
   
          boolean result = streamBridge.send("boardUpdate-out-0", event);
          log.info("====[Producer]====== boardCreate send to kafka Topic  BoardUpdateEvent: {} , result :{}", event,
                  result);
          return getReturnResultMessage(result);
   
      }
   
      public ResultMessage boardDelete(BoardDeleteEvent event) {
   
          boolean result = streamBridge.send("boardDelete-out-0", event);
          log.info("====[Producer]======boardDelete send to kafka Topic  BoardDeleteEvent: {} , result :{}", event,
                  result);
          return getReturnResultMessage(result);
   
      }
   
      private ResultMessage getReturnResultMessage(boolean result) {
          ResultMessage resultMsg = new ResultMessage("N", "실패");
          if (result) {
              resultMsg.setSuccessYn(SUCCESS);
              resultMsg.setMessage("성공");
              return resultMsg;
          }
          return resultMsg;
   
      }
   
  }
  ```

  

- StreamBridge: kafka에 메시지를 전송하기 위해서 Spring cloud stream에서 제공하는 StreamBridge 클래스를 활용한다.

- 전송할 메시지를 이벤트 객체에 담아서 전송한다. "boardCreate-out-0" 는 application.yaml에 등록된 destination 키에 해당한다.

  ```java
  boolean result = streamBridge.send("boardCreate-out-0", event);
  ```

- BoardController.java

  ```java
  @RestController
  @Slf4j
  @RequiredArgsConstructor
  public class BoardController {
   
      private final BoardEventService boardEventService;
   
      @PostMapping("/create")
      public ResultMessage createBoard(@RequestBody BoardCreateEvent event ) {
      
          return   boardEventService.boardCreate(event);
      }
   
      @PostMapping("/update")
      public ResultMessage updateBoard(@RequestBody BoardUpdateEvent event ) {  
          return   boardEventService.boardUpdate(event);
      }
   
      @PostMapping("/delete")
      public ResultMessage deleteBoard(@RequestBody BoardDeleteEvent event ) {  
          return   boardEventService.boardDelete(event);
      }
   
  }
  ```

  

### 4.7.6 kafka 메시지 Event 수신 (Consumer)

#### 4.7.6.1 consumer 프로젝트 설정 

- application.yml

```yaml
spring:
  cloud:
    stream:
      function:  ## 반드시 있어야 함
        definition: boardCreate;boardUpdate;boardDelete
      kafka:
        default:
           consumer:
             ack-mode: MANUAL_IMMEDIATE        
        binder:
          brokers:
          - sa-cluster-kafka-route-bootstrap-kafka-system.apps.cluster01.cz-dev.icis.co.kr:443
 
          configuration:
            security:
              protocol: SASL_SSL
            sasl:
              mechanism: SCRAM-SHA-512
              jaas:                
                config: org.apache.kafka.common.security.scram.ScramLoginModule required username="order" password="WpxJedx0IIWj";
            ssl:
              truststore.location: classpath:/truststore.jks
              truststore.type: JKS
              truststore.password: new1234
 
      bindings:      
        boardCreate-in-0:         
          destination: order-board-create
          group: order-board-group
        boardUpdate-in-0:
          destination: order-board-update
          group: order-board-group
        boardDelete-in-0:
          destination: order-board-delete
          group: order-board-group
```

- spring cloud stream consumer 는 spring cloud function 을 사용해야 한다. 따라서 function 빈을 등록해 줘야 한다. 

  - function 빈 등록 

    ```yaml
    function:  
       definition: boardCreate;boardUpdate;boardDelete
    ```

    - kafka.binder.brokers: kaka-cluster를 연동할 주소들이다. 
      - kafka-cluster가 2개 이상일경우 ","로 구분하여 등록 가능하다. 
      - security :  SASL 기반의 TLS로  SASL_SSL 를 등록한다.
      - sasl.mechanism :  SCRAM-SHA-512 
      - sasl.jaas : kafka-user의 유저명과 패스워드를 입력 한다. (주의: 끝에 ";" 꼭 추가해야 한다.) 
      - ssl: kafka-cluster 외부에서 접속하기 위해서 okd의 kafka router는 https로 할당뒤기 때문에 SSL로 접속 해야 한다. 
        - 프로젝트에 resource 폴더 하위에 truststore.jks 파일을 위치 시키며 jks 생성시 입력한 password 를 입력해 준다. 

- yaml설정은 producer 설정과 동일하다. 

- truststore.jks를 resources 하위에 위치 시킨다.

  ```
  resources
  ├── config
  │   ├── application-dev.yml
  │   ├── application-local.yml
  │   └── application.yml
  └── truststore.jks
  ```

  

#### 4.7.6.2 이벤트 객체 생성

- BoardCreateEvent.java

  ```java
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardCreateEvent {
      private String eventName;
      private int num;
      private String title;
      private String contents;
      private String writeId;
      private String writeName;
      private LocalDateTime writeDate;
   
  }
  ```

- BoardUpdateEvent.java

  ```java
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardUpdateEvent {
      private String eventName;
      private int num;
      private String title;
      private String contents;
      private String modifyId;
      private String modifyName;      
      private LocalDateTime  modifyDate;
       
   
  }
  ```

- BoardDeleteEvent.java

  ```java
  @AllArgsConstructor
  @NoArgsConstructor
  @Getter
  @Builder
  @ToString
  public class BoardDeleteEvent {
      private String eventName;
      private int num;
   
  }
  ```

  

#### 4.7.6.3 kafka 메시지 수신

- BoardEventFunction.java

  ```java
  @Configuration
  @Slf4j
  @RequiredArgsConstructor
  public class BoardEventFunction {
        
      private Jackson2JsonObjectMapper mapper = new Jackson2JsonObjectMapper();
   
      @Bean
      public Consumer<Message<String>> boardCreate(){
          return ((msg) -> {
              log.info("boardCreate 이벤트 수신: {}",msg); 
              try {
                  BoardCreateEvent event = mapper.fromJson(msg.getPayload(),BoardCreateEvent.class );
                  log.info("==============[Consumer]============BoardCreateEvent: {}", event.toString());
                  //repositoryBoardCreate(event); 
                  Acknowledgment acknowledgment = msg.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);           
                  if(acknowledgment != null){
                      log.info("==============[Consumer]===Acknowledgment provided");            
                      acknowledgment.acknowledge();
                  }             
              } catch (Exception e) {             
                  e.printStackTrace();
              }
          });
      }
   
      @Bean
      public Consumer<Message<String>> boardUpdate(){
          return ((msg) -> {
              log.info("boardUpdate 이벤트 수신: {}",msg); 
              try {
                  BoardUpdateEvent event = mapper.fromJson(msg.getPayload(),BoardUpdateEvent.class );
                  log.info("=============[Consumer]===================BoardUpdateEvent: {}", event.toString());
                  //repositoryBoardUpdate(event);
                   
              } catch (Exception e) {             
                  e.printStackTrace();
              }
   
          });
      }
      @Bean
      public Consumer<Message<String>> boardDelete(){
          return ((msg) -> {
              log.info("boardDelete 이벤트 수신: {}",msg); 
              try {
                  BoardDeleteEvent event = mapper.fromJson(msg.getPayload(),BoardDeleteEvent.class );
                  log.info("==============[Consumer]==================BoardDeleteEvent: {}", event.toString());
                  //repositoryBoardDelete(event);
              } catch (Exception e) {             
                  e.printStackTrace();
              }
          });
   
      }
   
      private void repositoryBoardCreate(BoardCreateEvent event) {   
          
          log.info("======== BoardCreateEvent : {}", event.toString());
      }
   
      private void repositoryBoardUpdate(BoardUpdateEvent event){
          log.info("======== BoardUpdateEvent : {}", event.toString());
           
      }
      private void repositoryBoardDelete(BoardDeleteEvent event) {
          log.info("======== BoardDeleteEvent : {}", event.toString());
      }
  }
  ```

- topic의 consumer는 spring cloud function bean으로 등록 해야 한다. 

- 각 빈의 메소드명을 바탕으로 kafka topic destination 키와 매핑된다. 

  -  예를 들어 @Bean public Consumer<String> boardCreate() 의 **boardCreate**는 아래와 같이 매핑된다.

    ```yaml
    bindings:      
       boardCreate-in-0: 
         destination: sa-app-order-board-create
    ```
    
    

### 4.7.6 Consumer 수동 커밋 방법 

- spring kafka binder는 기본 커밋 설정으로 되어 있다. 따라서 consumer에서 poll 하면 offset이 커밋 된다. (특정 주기 마다 자동으로 commit)

- 일반적으로 중요도가 낮은 로그성 데이터가 이에 해당된다. 하지만 Consumer 가 읽어온 데이터 처리 실패시 보상 로직이나 재처리가 필요한 AP라면, 자동커밋이 아닌 수동커밋으로 설정 후 로직 성공에 의해 커밋되도록 수정해야 한다.



#### 4.7.6.1 수동커밋설정

- Consumer의 autoCommitOffset= true로 되어 있다. 하지만 spring cloude stream kafka binder 3.1버전 부터 이 속성은 더 이상 사용되지 않는다. (Deprecated) 

- autoCommit을 false로 설정하기 위해서는 ackMode를 사용하며 MANUAL 또는 MANUAL_IMMEDIATE로 설정 하면 된다.

- application.yaml 에 다음과 같이 설정한다.

  ```yaml
  spring:
    cloud:
      stream:
        kafka:
          default:
             consumer:
               ack-mode: MANUAL_IMMEDIATE
  ```

- MANUAL 보다는MANUAL_IMMEDIATE로 설정하여 acknowledgment 통보하면 즉시 커밋 되도록 한다. 

- kafka의 default로 선언하면 각 채널에 중복으로 설정을 피할 수 있고 모든 채널에 공통으로 설정된다. 



#### 4.7.6.2 Consumer에서 acknowledgment 사용 

- consumer.ackMode로 전환 되면 consumer 메서드가 수신하는 메시지에 kafka_acknowledgment 라는 헤더가 있다. 이를 이용하여 acknowledge를 통보할수 있다. 

  ```java
  @Bean
  public Consumer<Message<String>> boardCreate(){
      return ((msg) -> {
          log.info("boardCreate 이벤트 수신: {}",msg); 
          try {
           
              BoardCreateEvent event = mapper.fromJson(msg.getPayload(),BoardCreateEvent.class );
              log.info("==============[Consumer]============BoardCreateEvent: {}", event.toString());
               
              // 메세지 DB 처리작업 예
              repositoryBoardCreate(event);
               
              Acknowledgment acknowledgment = msg.getHeaders().get(KafkaHeaders.ACKNOWLEDGMENT, Acknowledgment.class);           
              if(acknowledgment != null){
                  log.info("==============[Consumer]===Acknowledgment provided");            
                  acknowledgment.acknowledge();
              }
                           
          } catch (Exception e) {             
              e.printStackTrace();
          }
      });
  }
  ```
  
  

## 4.8 Spring Cloud Eureka

### 4.8.1 개요

- **클라우드가 아닌 환경에서 서비스의 발견은 로드 밸런서가 서비스에 대한 프록시 역할을 하므로 서비스에 매핑된 정보가 있어야 하는데 이 매핑 규칙을 수동으로 정의해야 하기 때문에 인프라스트럭처의 복잡성이 높아진다**. (새로운 서비스를 인스턴스 시작 시점이 아닌 수동으로 등록)

- MSA로 설계된 환경에서 중앙 집중식 인프라 스트럭처는 확장성에 제한이 있다. 예를 들어 많은 수의 마이크로 서비스가 있다면 서버와 인스턴스의 갯수를 동적으로 조절할 상황이 발생할 수 있는데 이 경우 예측을 통해 서버의 URL을 정적으로 지정하는 것은 부적합하다.

- **마이크로서비스가 자신의 서비스를 동적으로 등록하여 스스로 라이프 사이클을 관리할 수 있게 하고, 서비스가 등록되면 서비스 탐색 대상에 포함되어 발견되게 함으로써 최대한 수동 작업을 피하고 자동화하**는 것이 좋다.

- 이러한 부분을 지원하기 위해 MSA 환경에서는 **서비스 디스커버리 메커니즘**을 사용한다

  - Kubernetes 환경에서는 Etcd가 서비스 디스커버리 역할을 하므로 해당 환경 사용시에는 Eureka가 필요하지 않다.

  


### 4.8.2 Eureka Server

서비스 레지스트리를 위해 Eureka Server 를 구현하는 것은 다음과 같다.

1. 종속성 에 *[spring-cloud-starter-netflix-eureka-server](https://search.maven.org/search?q=spring-cloud-starter-netflix-eureka-server)* 추가
2. [*@EnableEurekaServer*](https://www.baeldung.com/spring-boot-application-configuration) 로 주석을 달아 *@SpringBootApplication* 에서 Eureka 서버 활성화
3. 종속성 구성

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-parent</artifactId>
            <version>Greenwich.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

4. Bootstrap 클래스를 생성한다.

```java
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class, args);
    }
}
```

5. *application.yml* 생성한다.

```plaintext
server:
  port: 8761
eureka:
  client:
    registerWithEureka: false
    fetchRegistry: false
```

- **애플리케이션 포트를 구성하고 있다. \*Eureka\* 서버 의 기본값 은 \*8761\* 이다.** 



- 브라우저를 [http://localhost:8761](http://localhost:8761/) 로 지정하여 *Eureka* 대시보드를 보고 나중에 등록된 인스턴스를 확인한다.
  - 현재 Status 및 Health 지표와 같은 기본 지표를 볼 수 있다.

[![스크린샷_20160819_073151](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_073151.png)](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_073151.png)

### 4.8.3 Eureka Client

1. @SpringBootApplication 이 검색을 인식하려면 클래스 경로에 *Spring* *Discovery Client*를 포함해야 한다.
   - @EnableDiscoveryClient  *@Configuration* 에 주석을 *달아야  한다.* 

2. 종속성 구성.

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

3. Bootstrap 클래스를 생성한다.

```java
@SpringBootApplication
@EnableDiscoveryClient
@RestController
public class EurekaClientApplication implements GreetingController {

    @Autowired
    @Lazy
    private EurekaClient eurekaClient;

    @Value("${spring.application.name}")
    private String appName;

    public static void main(String[] args) {
        SpringApplication.run(EurekaClientApplication.class, args);
    }

    @Override
    public String greeting() {
        return String.format(
          "Hello from '%s'!", eurekaClient.getApplication(appName).getName());
    }
}
```

4. *application.yml* 생성한다.

```plaintext
spring:
  application:
    name: spring-cloud-eureka-client
server:
  port: 0
eureka:
  client:
    serviceUrl:
      defaultZone: ${EUREKA_URI:http://localhost:8761/eureka}
  instance:
    preferIpAddress: true
```

- Eureka 클라이언트를 설정할 경우 서비스는 나중에 쉽게 확장할 수 있다.

- 클라이언트를 실행하고 브라우저를 다시 [*http://localhost:8761*](https://localhost:8761/) 로 지정하여 Eureka 대시보드에서 등록 상태를 확인할 수 있다.

![스크린샷_20160819_101810](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_101810.png)



## 4.6 Spring Cloud OpenFeign

### 4.6.1 개요

- **[OpenFeign](https://www.baeldung.com/intro-to-feign) 은 Feign 주석 및 JAX-RS 주석을 포함하는 플러그형 주석 지원으로 웹 서비스 클라이언트 작성을 더 쉽게 만든다.**

- [Spring Cloud 는 ](https://www.baeldung.com/spring-cloud-series)[Spring MVC 주석](https://www.baeldung.com/spring-mvc-annotations) 에 대한 지원을 추가 하고 Spring Web에서 사용되는 것과 동일한 [*HttpMessageConverters 를 사용한다.*](https://www.baeldung.com/spring-httpmessageconverter-rest)

- Feign 사용의 한 가지 좋은 점은 **인터페이스 정의 외에 서비스를 호출하기 위한 코드를 작성할 필요가 없다**.

### **4.6.2 종속성 구성**

먼저 Spring Boot 웹 프로젝트를 만들고 *pom.xml* 파일 에 *spring-cloud-starter-openfeign* 종속성을 추가한다.

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

https://search.maven.org/search?q=g:org.springframework.cloud AND a:spring-cloud-dependencies)

### 4.6.3 Bootstrap 클래스

다음으로 메인 클래스 에 *@EnableFeignClients 를 추가해야 한다.*

```java
@SpringBootApplication
@EnableFeignClients
public class ExampleApplication {

    public static void main(String[] args) {
        SpringApplication.run(ExampleApplication.class, args);
    }
}
```

이 주석을 사용하여 Feign 클라이언트임을 선언하는 인터페이스에 대한 구성 요소 스캔을 활성화 한다.

그런 다음 ***@FeignClient\*** **주석** 을 사용하여 Feign 클라이언트를 선언한다.

```java
@FeignClient(value = "jplaceholder", url = "https://jsonplaceholder.typicode.com/")
public interface JSONPlaceHolderClient {

    @RequestMapping(method = RequestMethod.GET, value = "/posts")
    List<Post> getPosts();

    @RequestMapping(method = RequestMethod.GET, value = "/posts/{postId}", produces = "application/json")
    Post getPostById(@PathVariable("postId") Long postId);
}
```

- 이 예에서는 클라이언트가 [JSONPlaceholder API](https://jsonplaceholder.typicode.com/) 에서 읽도록 구성하였다.

- *@FeignClient* 주석에 전달 된 *값* 인수 는 필수 임의 클라이언트 이름이며 *url* 인수를 사용하여 API 기본 URL을 지정한다.

- 또한 이 인터페이스는 Feign 클라이언트이므로 Spring 웹 주석을 사용하여 도달하려는 API를 선언할 수 있다.

### 4.6.4 구성

- **각 Feign 클라이언트가 사용자 지정 가능한 구성 요소 집합으로 구성되어 있음을 이해하는 것이 매우 중요하다.**

- Spring Cloud 는 다음 섹션에서 설명하는 대로 사용자 정의할 수 있는 *FeignClientsConfiguration 클래스를 사용하여 각 명명된 클라이언트에 대해 요청 시 새로운 기본 세트를 생성한다.*

- 위의 클래스에는 다음 빈이 포함되어 있다.
  - Decoder – *ResponseEntityDecoder ,* *SpringDecoder* 를 래핑 하여 *Response* 를 디코딩하는 데 사용된다.
  - Encoder– *SpringEncoder 는* *RequestBody* 를 인코딩하는 데 사용된다.
  - Logger– *Slf4jLogger* 는 Feign에서 사용하는 기본 Logger이다.
  - Contract – 주석 처리를 제공하는 *SpringMvcContract*
  - Feign-Builder – *HystrixFeign.Builder* 는 구성 요소를 구성하는 데 사용된다.
  - Client– *LoadBalancerFeignClient* 또는 기본 Feign 클라이언트

### 4.6.5 사용자 정의 빈 구성

- bean 중 하나 이상을 사용자 정의하려면 @Configuration 클래스를 사용하여 이를 재정의할 수 있으며 *FeignClient* 주석에 추가한다.

```java
@FeignClient(value = "jplaceholder",
  url = "https://jsonplaceholder.typicode.com/",
  configuration = MyClientConfiguration.class)
@Configuration
public class MyClientConfiguration {

    @Bean
    public OkHttpClient client() {
        return new OkHttpClient();
    }
}
```

- 이 예에서 우리는 HTTP/2를 지원하기 위해 기본값 대신 OkHttpClient를 사용하도록 [*Feign 에 지시한다.*](https://www.baeldung.com/guide-to-okhttp)

- Feign은 요청과 함께 더 많은 헤더를 보내는 *ApacheHttpClient* 를 포함하여 다양한 사용 사례에 대해 여러 클라이언트를 지원한다.( 예: 일부 서버에서 예상하는 *Content-Length ).*

- *이러한 클라이언트를 사용하려면  pom.xml* 파일 에 필수 종속성을 추가가 필요하다.

```xml
<dependency>
    <groupId>io.github.openfeign</groupId>
    <artifactId>feign-okhttp</artifactId>
</dependency>

<dependency>
    <groupId>io.github.openfeign</groupId>
    <artifactId>feign-httpclient</artifactId>
</dependency>
```



### 4.6.6 속성을 사용한 구성

- *@Configuration* 클래스를 사용하는 대신 이 *application.yaml* 예제 와 같이 **애플리케이션 속성을 사용하여 Feign 클라이언트를 구성할 수 있다.**

```xml
feign:
  client:
    config:
      default:
        connectTimeout: 5000
        readTimeout: 5000
        loggerLevel: basic
```

- 이 구성을 사용 하여 애플리케이션에서 선언된 각 클라이언트에 대해 시간 제한을 5초로 설정하고 로거 수준을 *기본 으로 설정한다.*

- 마지막으로 모든 *@FeignClient* 개체 를 구성하기 위해 *기본 클라이언트 이름으로 구성을 만들거나 구성에 대해 가상 클라이언트 이름을 선언할 수 있다..*

```yaml
feign:
  client:
    config:
      jplaceholder:
```

- *@Configuration* 빈과 Configuration Properties 이 모두 있는 경우 Configuration Properties이 *@Configuration* 값을 재정의한다.



### 4.6.7 인터셉터

- **인터셉터를 추가하는 것은 Feign에서 제공하는 또 다른 유용한 기능이다.**

- 인터셉터는 모든 HTTP 요청/응답에 대해 인증에서 로깅에 이르기까지 다양한 암시적 작업을 수행할 수 있다.

- 이 섹션에서는 자체 인터셉터를 구현하고 즉시 사용 가능한 Spring Cloud OpenFeign에서 제공하는 인터셉터를 사용하면 된다. 
- 둘 다 **각 요청에 기본 인증 헤더를 추가한다.**

#### 4.6.7.1 *RequestInterceptor* 구현

- 사용자 지정 요청 인터셉터 구현.

```java
@Bean
public RequestInterceptor requestInterceptor() {
  return requestTemplate -> {
      requestTemplate.header("user", username);
      requestTemplate.header("password", password);
      requestTemplate.header("Accept", ContentType.APPLICATION_JSON.getMimeType());
  };
}
```

- 또한 요청 체인에 인터셉터를 추가하려면 이 빈을 *@Configuration* 클래스에 추가하거나 이전에 본 것처럼 속성 파일에서 선언하면 된다.

```xml
feign:
  client:
    config:
      default:
        requestInterceptors:
          com.baeldung.cloud.openfeign.JSONPlaceHolderInterceptor
```

#### 4.6.7.2 *BasicAuthRequestInterceptor* 사용

- Spring Cloud OpenFeign이 제공하는 *BasicAuthRequestInterceptor 클래스를 사용할 수 있다.*

```java
@Bean
public BasicAuthRequestInterceptor basicAuthRequestInterceptor() {
    return new BasicAuthRequestInterceptor("username", "password");
}
```



### 4.6.8 Circuit Breaker 지원

- Feign은 resilience4j 를 지원하므로 활성화했다면 Fallback 패턴을 구현할 수 있다.

- Fallback 패턴을 사용하면 원격 서비스 호출이 실패할 때 예외를 생성하는 대신 서비스 소비자가 대체 코드 경로를 실행하여 다른 수단을 통해 작업을 수행하려고 한다.

- 목표를 달성하려면 속성 파일에 *feign.circuitbreaker.enabled=true 를 추가하여 resilience4j를 활성화해야 한다*

- 이를 통해 서비스가 실패할 때 호출되는 Fallback 메서드를 구현할 수 있다.

```java
@Component
public class JSONPlaceHolderFallback implements JSONPlaceHolderClient {

    @Override
    public List<Post> getPosts() {
        return Collections.emptyList();
    }

    @Override
    public Post getPostById(Long postId) {
        return null;
    }
}
```

- *대체 방법이 제공되었음을 Feign에 알리려면 @FeignClient* 주석 에서 대체 클래스도 설정해야 한다.

```java
@FeignClient(value = "jplaceholder",
  url = "https://jsonplaceholder.typicode.com/",
  fallback = JSONPlaceHolderFallback.class)
public interface JSONPlaceHolderClient {
    // APIs
}
```

### 4.6.8 로깅

- 각 Feign 클라이언트에 대해 로거가 기본적으로 생성된다.

- 로깅을 활성화하려면 클라이언트 인터페이스의 패키지 이름을 사용하여 *application.propertie* 파일 에 선언해야 한다.

```xml
logging.level.com.baeldung.cloud.openfeign.client: DEBUG
```

- 또는 패키지의 특정 클라이언트에 대해서만 로깅을 활성화하려면 전체 클래스 이름을 사용할 수 있다.

```xml
logging.level.com.baeldung.cloud.openfeign.client.JSONPlaceHolderClient: DEBUG
```

- **Feign 로깅은 \*DEBUG\* 수준에만 응답한다.**

- 클라이언트별로 구성할 수 있는 *Logger.Level 을 통해 로깅의 정보를 설정할 수 있다.

```java
@Configuration
public class ClientConfiguration {
    
    @Bean
    Logger.Level feignLoggerLevel() {
        return Logger.Level.BASIC;
    }
}
```

- 다음 네 가지 로깅 수준 중에서 선택할 수 있다.
  - *NONE* – 기본값인 로깅 없음
  - *BASIC* – 요청 방법, URL 및 응답 상태만 기록
  - *HEADERS* – 요청 및 응답 헤더와 함께 기본 정보를 기록.
  - *FULL* - 요청 및 응답 모두에 대한 본문, 헤더 및 메타데이터를 기록.

### 4.6.9 오류 처리

- Feign의 기본 오류 핸들러인 *ErrorDecoder.default* 는 항상 *FeignException* 을 발생한다.

- **발생한 예외를 사용자 지정하려면 \*CustomErrorDecoder\*** 를 사용할 수 있다.

```java
public class CustomErrorDecoder implements ErrorDecoder {
    @Override
    public Exception decode(String methodKey, Response response) {

        switch (response.status()){
            case 400:
                return new BadRequestException();
            case 404:
                return new NotFoundException();
            default:
                return new Exception("Generic error");
        }
    }
}
```

- *@Configuration* 클래스 에 빈을 추가하여 기본 *ErrorDecoder 를 교체해야 한다.*

```java
@Configuration
public class ClientConfiguration {

    @Bean
    public ErrorDecoder errorDecoder() {
        return new CustomErrorDecoder();
    }
}
```



## 4.7  Spring Data JDBC

### 4.7.1 개요

- **MSA 환경의 DDD(도메인주도설계) 관점의 Aggregate의 일관성을 제공하는 필수 기능을 제공하는 프레임워크**이다.
- Spring Data JDBC는 Spring Data JPA만큼 복잡하지 않으며  JPA의 캐시, 지연 로딩, 세션 등 여러 기능을 제공하지 않는다. 
- 자체 ORM이 있으며 매핑된 엔터티, 저장소, 쿼리 주석 및 JdbcTemplate 과 같이 Spring Data JPA와 함께 사용되는 대부분의 기능을  제공한다.
- Spring Data JDBC는 스키마 생성을 제공하지 않므로 스키마를 사전에 생성하여야 한다.
- Spring Data JDBC는 Spring JDBC를 사용하는 것처럼 간단한 솔루션을 제공하며  Spring Data JPA의 대부분의 기능을 제공한다.
- Spring Data JDBC의 가장 큰 장점 중 하나는 Spring Data JPA에 비해 데이터베이스에 접근할 때 향상된 성능을 제공한다.
- Spring Data JDBC를 사용할 때 가장 큰 단점 중 하나는 데이터베이스 벤더에 의존하므로 데이터베이스를 MySQL에서 Oracle로 변경하기로 결정한 경우 다른 Dialect를 사용하여 데이터베이스에서 발생하는 문제를 처리해야 한다.

### 4.7.2 Spring Data JDBC 의존성 추가

- Spring Data JDBC는 JDBC 종속성 스타터가 있는 Spring Boot 애플리케이션에서 사용할 수 있다.
  - 이 의존성은 데이터베이스 드라이버를 가져오지 않는다.

```xml
<dependency> 
    <groupId>org.springframework.boot</groupId> 
    <artifactId>spring-boot-starter-data-jdbc</artifactId>
</dependency> 
```

- 이 예에서는 H2 데이터베이스를 사용하고 있다. 앞서 언급했듯이 Spring Data JDBC는 스키마 생성을 제공하지 않는다.
  -  이러한 경우 스키마 개체를 만들기 위한 SQL DDL 명령이 있는 사용자 지정 *schema.sql 파일을 만들 수 있다.
- 자동으로 Spring Boot는 이 파일을 선택하여 데이터베이스 객체를 생성하는 데 사용한다.

### 4.7.3 엔티티 추가

- 다른 Spring Data 프로젝트와 마찬가지로 주석을 사용하여 POJO를 데이터베이스 테이블과 매핑된다. 
- Spring Data JDBC 에서 엔티티는 **@Id** 가 있어야 합니다 . Spring Data JDBC는 *@Id* 주석을 사용하여 엔티티를 식별한다.

- Spring Data JPA와 유사하게 Spring Data JDBC는 기본적으로 Java 엔티티를 관계형 데이터베이스 테이블에 매핑하고 속성을 열 이름에 매핑하는 명명 전략을 사용한다. 
- 기본적으로 엔터티 및 속성의 Camel Case 이름은 테이블 및 열의 스네이크 케이스 이름에 각각 매핑된다.

- *@Table* 및 *@Column* 주석을 사용하여 엔티티 및 속성을 테이블 및 열과 명시적으로 매핑할 수 있다.

```java
public class Person {
    @Id
    private long id;
    private String firstName;
    private String lastName;
    // constructors, getters, setters
}
```

- *Person* 클래스 에서 *@Table* 또는 *@Column* 주석을 사용할 필요가 없습니다 . Spring Data JDBC의 기본 명명 전략은 엔터티와 테이블 간의 모든 매핑을 암시적으로 수행한다.

### 4.7.4 JDBC 저장소 선언

- Spring Data JDBC는 Spring Data JPA와 유사한 구문을 사용한다.
-  *Repository* , *CrudRepository 또는 PagingAndSortingRepository* 인터페이스 를 확장하여 Spring Data JDBC 저장소를 생성할 수 있다. 
- *CrudRepository* 를 구현함으로써 우리는 특히 *save* , *delete* , *findById* 와 같은 가장 일반적으로 사용되는 메소드의 구현을 상속한다.

-  JDBC 저장소를 예제는 다음과 같다.

```java
@Repository 
public interface PersonRepository extends CrudRepository<Person, Long> {
}
```

- JPA와 마찬가지로 페이징 및 정렬 기능이 필요한 경우 *PagingAndSortingRepository* 인터페이스를 사용할 수 있다.

### 4.7.5 JDBC 저장소 사용자 정의

- *CrudRepository* 의 내장 메소드 에도 불구하고 특정 경우에 대한 메소드를 생성해야 한다.

- 이제 수정하지 않는 쿼리와 수정하는 쿼리를 사용하여 *PersonRepository 에 대한 예제이다.*

```java
@Repository
public interface PersonRepository extends CrudRepository<Person, Long> {

    List<Person> findByFirstName(String firstName);

    @Modifying
    @Query("UPDATE person SET first_name = :name WHERE id = :id")
    boolean updateByFirstName(@Param("id") Long id, @Param("name") String name);
}
```

- 버전 2.0부터 Spring Data JDBC는 [쿼리 메소드](https://docs.spring.io/spring-data/jdbc/docs/current/reference/html/#jdbc.query-methods) 를 지원한다. 즉, 예를 들어 *findByFirstName과* 같은 키워드를 포함하는 쿼리 메서드의 이름을 지정하면 Spring Data JDBC는 쿼리 객체를 자동으로 생성한다.

- 수정 쿼리의 경우 *@Modifying* 주석을 사용하여 엔터티를 수정하는 쿼리 메서드에 주석을 추가한다. *또한 @Query* 주석 으로 장식합니다 .

- *@Query* 주석 내부에 SQL 명령을 추가한다. **Spring Data JDBC에서는 일반 SQL로 쿼리를 작성한다.** 
-  JPQL과 같은 고급 쿼리 언어를 사용하지 않는다. 결과적으로 응용 프로그램은 데이터베이스 공급업체와 긴밀하게 연결되며 다른 데이터베이스로 변경하는 것도 더 어려워집니다.

-  **Spring Data JDBC가 인덱스 번호가 있는 매개변수 참조를 지원하지 않는다는 것입니다** . **매개변수는 이름으로만 참조할 수** 있다.



## 4.8 Caching Data with Spring

### 4.8.1 개요

- **Spring에서 Caching 추상화를 사용하는 방법 과 일반적으로 시스템의 성능을 향상시키는 기능을 제공**한다.

### 4.8.2. 의존성 추가

- Spring Boot를 사용하는 경우 *[spring-boot-starter-cache](https://search.maven.org/search?q=g:org.springframework.boot a:spring-boot-starter-cache)* 스타터 패키지를 활용하여 캐싱 종속성을 쉽게 추가할 수 있다.

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
    <version>2.4.0</version>
</dependency>
```

### 4.8.3 캐싱 활성화

- 캐싱을 활성화하기 위해 Spring은 프레임워크에서 다른 구성 수준 기능을 활성화하는 것과 마찬가지로 어노테이션을 사용한다.

- *구성 클래스에 @EnableCaching* 주석을 추가하여 캐싱 기능을 활성화할 수 있다.

```java
@Configuration
@EnableCaching
public class CachingConfig {

    @Bean
    public CacheManager cacheManager() {
        return new ConcurrentMapCacheManager("addresses");
    }
}
```



### 4.8.4 주석과 함께 캐싱 사용

- 캐싱을 사용하기 위해 어노테이션을 사용하여 캐싱 동작을 메서드에 바인딩할 수 있다.

#### 4.8.4.1 @Cacheable

- 메소드에 대한 캐싱 동작을 활성화하는 가장 간단한 방법은 *@Cacheable* 로 구분 하고 결과가 저장될 캐시 이름으로 매개변수화한다.

```java
@Cacheable("addresses")
public String getAddress(Customer customer) {...}
```

*getAddress()* 호출 은 실제로 메서드를 호출한 다음 결과를 캐싱하기 전에 먼저 캐시 *주소 를 확인한다.*

대부분의 경우 하나의 캐시로 충분하지만 Spring 프레임워크는 매개변수로 전달할 여러 캐시도 지원한다..

```java
@Cacheable({"addresses", "directory"})
public String getAddress(Customer customer) {...}
```

이 경우 캐시에 필요한 결과가 포함된 경우 결과가 반환되고 메서드가 호출되지 않는다.

#### 4.8.4.2 @CacheEvict

- 자주 필요하지 않은 값으로 캐시를 채울 경우 캐시는 상당히 크고 빠르게 증가할 수 있으며 오래되거나 사용되지 않는 데이터를 많이 보유할 수 있다. 
- 이 경우 새로운 값을 캐시에 다시 로드할 수 있도록 @CacheEvict 주석을 사용하여 하나 이상의 모든 값을 제거 할수 가 있다.

```java
@CacheEvict(value="addresses", allEntries=true)
public String getAddress(Customer customer) {...}
```

- 여기서 비울 캐시와 함께 *allEntries 추가 매개변수를 사용한다.* 이렇게 하면 캐시 *주소* 의 모든 항목이 지워지고 새 데이터를 위해 준비됩니다.

#### 4.8.4.3 @CachePut

- *@CacheEvict* 가 오래되고 사용되지 않는 항목을 제거하여 대용량 캐시에서 항목을 조회하는 오버헤드를 줄이는 동안 캐시에서 너무 많은 데이터를 제거하는 것을 방지할 필요성이 있을 경우 *@CachePut* 주석을 사용 하면 메서드 실행을 방해하지 않고 캐시 내용을 업데이트할 수 있다.

```java
@CachePut(value="addresses")
public String getAddress(Customer customer) {...}
```

- *@Cacheable* 과 *@CachePut* 의 차이점은 @Cacheable은 *메서드* 실행 을 **건너뛰지** 만 *@CachePut* 은 **실제로 메서드** 를 실행한 다음 그 결과를 캐시에 저장한다는 것이다.

#### 4.8.4.4 @Caching

- 메서드를 캐싱하기 위해 동일한 유형의 여러 어노테이션을 사용할 경우 아래와 같이 사용하는 것은 허용하지 않는다.

```java
@CacheEvict("addresses")
@CacheEvict(value="directory", key=customer.name)
public String getAddress(Customer customer) {...}
```

- 그럴경우 아래와 같이 캐싱관련 어노테이션을 그룹화하는 @Caching을 사용해야 한다.

```java
@Caching(evict = { 
  @CacheEvict("addresses"), 
  @CacheEvict(value="directory", key="#customer.name") })
public String getAddress(Customer customer) {...}
```

#### 4.8.4.5 @CacheConfig

- *@CacheConfig* 주석을 사용하면 캐시 구성의 일부를 클래스 수준의 단일 위치로 간소화할 수 있으므로 **여러** 번 선언할 필요가 없다.

```java
@CacheConfig(cacheNames={"addresses"})
public class CustomerDataService {

    @Cacheable
    public String getAddress(Customer customer) {...}
```

#### 4.8.4.6  조건부 캐싱

- 경우에 따라 모든 상황에서 메서드에 대해 캐싱이 제대로 작동하지 않을 수 있으며 이 경우 조건부 캐싱을 활용하여 효과적인 캐쉬를 사용할 수 있다.

```java
@CachePut(value="addresses")
public String getAddress(Customer customer) {...}
```

- 조건 매개변수

주석이 활성화될 때 더 많은 제어를 원하면 SpEL 표현식을 사용하고 해당 표현식 평가를 기반으로 결과가 캐시되도록 하는 조건 매개 변수로 *@CachePut 을 매개변수화할 수 있다.*

```java
@CachePut(value="addresses", condition="#customer.name=='Tom'")
public String getAddress(Customer customer) {...}
```

- 매개변수가 아닌 경우

*if* 매개변수 를 통한 **입력이 아닌 메소드의 출력을 기반으로** 캐싱을 제어할 수 있다.

```java
@CachePut(value="addresses", unless="#result.length()<64")
public String getAddress(Customer customer) {...}
```

- 위의 주석은 주소가 64자 미만인 경우를 제외하고 주소를 캐시한다.

- 이러한 종류의 조건부 캐싱은 큰 결과를 관리하는 데 매우 효과적이며 모든 작업에 일반 동작을 적용하는 대신 입력 매개 변수를 기반으로 동작을 사용자 지정하는 데 유용하다.



## 4.9  Spring with kafka

### 4.9.1 개요

- [Apache Kafka](https://kafka.apache.org/) 는 분산 및 내결함성 스트림 처리 시스템이다.

- *Spring Kafka는 @KafkaListener* 어노테이션 을 통해 *KafkaTemplate* 및 **Message-driven POJO 가 있는 단순하고 일반적인 Spring 템플릿 프로그래밍 모델을 제공**한다.

### 4.9.2 설정

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### 4.9.3 구성

```java
@Configuration
public class KafkaProducerConfig {

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(
          ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, 
          bootstrapAddress);
        configProps.put(
          ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
          StringSerializer.class);
        configProps.put(
          ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
          StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```



```yaml
  kafka:
    consumer:
      bootstrap-servers: localhost:9092
      group-id: consumerGroupId
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      bootstrap-servers: localhost:9092
```

### 4.9.4 이벤트 전송

- *KafkaTemplate* 클래스 를 사용하여 메시지를 보낼 수 있다.

```java
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

public void sendMessage(String msg) {
    kafkaTemplate.send(topicName, msg);
}
```

- send API는 ListenableFuture 객체 를 반환한다. 보내는 스레드를 차단하고 보낸 메시지에 대한 결과를 얻으려면 *ListenableFuture* 객체 의 *get* API를 호출할 수 있다. 스레드는 결과를 기다리지만 Producer 속도가 느려진다.
  - Kafka는 빠른 스트림 처리 플랫폼이다. 따라서 후속 메시지가 이전 메시지의 결과를 기다리지 않도록 결과를 비동기적으로 처리하는 것이 좋다.

- 이 같은 경우 콜백을 통해 작업을 수행할 수 있다.

```java
public void sendMessage(String message) {
            
    ListenableFuture<SendResult<String, String>> future = 
      kafkaTemplate.send(topicName, message);
	
    future.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {

        @Override
        public void onSuccess(SendResult<String, String> result) {
            System.out.println("Sent message=[" + message + 
              "] with offset=[" + result.getRecordMetadata().offset() + "]");
        }
        @Override
        public void onFailure(Throwable ex) {
            System.out.println("Unable to send message=[" 
              + message + "] due to : " + ex.getMessage());
        }
    });
}
```

### 4.9.5 이벤트 수신

- @KafkaListener 어노테이션을 통해 원하는 topic에 대한 메시지를 수신 받을 수 있다.

```java
@KafkaListener(topics = "topicName", groupId = "foo")
public void listenGroupFoo(String message) {
    System.out.println("Received Message in group foo: " + message);
}
```

- Topic 에 대해 각각 다른 Group ID를 가진 여러 리스너를 구현할 수 있다. 또한 한 Consumer는 다양한 Topic 메시지를 수신 할 수 있다.

```java
@KafkaListener(topics = "topic1, topic2", groupId = "foo")
```

- Spring은 또한 리스너에서 @Header 주석을 사용하여 하나 이상의 메시지 헤더 검색을 지원한다.

```java
@KafkaListener(topics = "topicName")
public void listenWithHeaders(
  @Payload String message, 
  @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
      System.out.println(
        "Received Message: " + message"
        + "from partition: " + partition);
}
```

### 4.9.6 특정 파티션의 메시지 사용

- 여러 파티션이 있는 Topic의 경우 *@KafkaListener* 는 초기 Offset에 있는 Topic의 특정 Partition을 명시적으로 구독할 수 있다.

```java
@KafkaListener(
  topicPartitions = @TopicPartition(topic = "topicName",
  partitionOffsets = {
    @PartitionOffset(partition = "0", initialOffset = "0"), 
    @PartitionOffset(partition = "3", initialOffset = "0")}),
  containerFactory = "partitionsKafkaListenerContainerFactory")
public void listenToPartition(
  @Payload String message, 
  @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
      System.out.println(
        "Received Message: " + message"
        + "from partition: " + partition);
}
```

- 이 리스너 에서 *initialOffset* 이 0으로 설정되었으므로 이 리스너가 초기화될 때마다 파티션 0과 3에서 이전에 사용된 모든 메시지가 다시 사용된다.

- 오프셋을 설정할 필요가 없다면 *@TopicPartition 주석의* *partitions* 속성을 사용 하여 오프셋 없이 파티션만 설정할 수 있다.

```java
@KafkaListener(topicPartitions 
  = @TopicPartition(topic = "topicName", partitions = { "0", "1" }))
```

### 4.9.7 리스너에 대한 메시지 필터 추가

- 사용자 지정 필터를 추가하여 특정 메시지 콘텐츠를 사용하도록 수신기를 구성할 수 있다. 이것은 *[RecordFilterStrategy](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/adapter/RecordFilterStrategy.html)* 를 *KafkaListenerContainerFactory* 로 설정하여 수행할 수 있다 .

```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String>
  filterKafkaListenerContainerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, String> factory =
      new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setRecordFilterStrategy(
      record -> record.value().contains("World"));
    return factory;
}
```

- 이 컨테이너 팩토리를 사용하도록 리스너를 구성할 수 있다.

```java
@KafkaListener(
  topics = "topicName", 
  containerFactory = "filterKafkaListenerContainerFactory")
public void listenWithFilter(String message) {
    System.out.println("Received Message in filtered listener: " + message);
}
```

이 리스너에서 필터와 일치하는 모든 메시지는 삭제된다.

### 4.9.8  Custom Message Converter

- 사용자 정의 Java 객체를 보내고 받기 위해서 ProducerFactory 에서 적절한 Seriallizer Conveter를 구성 하고 *ConsumerFactory* 에서 역 직렬 변환기를 구성해야 한다.

- 메시지로 보낼 간단한 빈 클래스*를* 살펴보겠습니다 .

```java
public class Greeting {

    private String msg;
    private String name;

    // standard getters, setters and constructor
}
```

#### 4.9.8.1 Custom Message 생성

-  *[JsonSerializer](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/support/serializer/JsonSerializer.html)* 를 사용한 *ProducerFactory* 및 *KafkaTemplate* 의 코드의 예이다.

```java
@Bean
public ProducerFactory<String, Greeting> greetingProducerFactory() {
    // ...
    configProps.put(
      ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
      JsonSerializer.class);
    return new DefaultKafkaProducerFactory<>(configProps);
}

@Bean
public KafkaTemplate<String, Greeting> greetingKafkaTemplate() {
    return new KafkaTemplate<>(greetingProducerFactory());
}
```

- *KafkaTemplate 을 사용하여* *인사말* 메시지 를 보낼 수 있다.

```java
kafkaTemplate.send(topicName, new Greeting("Hello", "World"));
```

#### 4.9.8.2 Custom Message 사용

- 메시지를 올바르게 Deseriallize 하도록 *ConsumerFactory* 및 *KafkaListenerContainerFactory 를 수정해야 한다.*

```java
@Bean
public ConsumerFactory<String, Greeting> greetingConsumerFactory() {
    // ...
    return new DefaultKafkaConsumerFactory<>(
      props,
      new StringDeserializer(), 
      new JsonDeserializer<>(Greeting.class));
}

@Bean
public ConcurrentKafkaListenerContainerFactory<String, Greeting> 
  greetingKafkaListenerContainerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, Greeting> factory =
      new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(greetingConsumerFactory());
    return factory;
}
```

- spring-kafka JSON 직렬 변환기 및 역직렬 변환기는 spring-kafka 프로젝트에 대한 선택적 Maven 종속성이기도 한 Jackson 라이브러리를 사용한다.
  - *pom.xml* 

```java
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.9.7</version>
</dependency>
```

- Greeting 메시지 를 사용하는 리스너를 작성해야 한다.

```java
@KafkaListener(
  topics = "topicName", 
  containerFactory = "greetingKafkaListenerContainerFactory")
public void greetingListener(Greeting greeting) {
    // process greeting message
}
```



## 4.10  Spring Cloud Sleuth/Zipkin

### 4.10.1 개요

- 마이크로서비스로 큰 서비스를 잘게 쪼개어 개발하게 되면 자연스럽게 마이크로서비스간에 연결이 많아지고 복잡하게 된다.

- Sleuth는 분산된 마이크로서비스간에 트래픽의 흐름을 추적(Tracing)할 수 있도록 Trace기록을 로그에 자동 삽입해 준다.
- Sleuth와 Zipkin이 필요한 이유는 **분산된 마이크로서비스간의 트래픽을 추적하여 문제를 사전에 방지하거나 해결하기 위해**서이다.

### 4.10.2 동작원리

- Sleuth를 적용한 후 Log4j, Logback, SLF4J(Simple Logging Facade for Java)등을 사용하여 로깅하면,  자동으로 로그에 Service명, Trace ID, Span ID가 삽입됩니다.

- Sleuth에 의해 로그에 자동으로 Trace정보가 주입된 예제이다.

- service명이 hystrix-consumer이고 Trace ID가 7d84c8618a10307f이며 Span ID는 e25a40b90acb4e5b이다.

- Span ID는 각 트래픽의 고유 ID이다.

```
2021-02-02 11:58:58.969  INFO [hystrix-consumer,7d84c8618a10307f,e25a40b90acb4e5b,true] 1 --- [nio-8003-exec-7] com.springcloud.CafeController           : ### Received: /delay/pass

2021-02-02 11:58:58.990  INFO [hystrix-consumer,7d84c8618a10307f,e25a40b90acb4e5b,true] 1 --- [nio-8003-exec-7] com.springcloud.CafeController           : ### Sent: [Americano, Latte, Mocha]
```

- 위 주문 트랜잭션의 예를 든다면 아래와 같이 부여됩니다.

| 마이크로서비스 (consumer) | 마이크로서비스 (producer) | API                              | Trace ID | Span ID |
| ------------------------- | ------------------------- | -------------------------------- | -------- | ------- |
| 주문접수                  | 주문등록                  | /order/register/{order id}       | 1000     | 1000    |
| 주문등록                  | 고객체크                  | /customer/validate/{customer id} | 1000     | 1100    |
| 주문접수                  | 결제                      | /pay/{order id}                  | 1000     | 1200    |
| 주문접수                  | 조리요청                  | /restaurant/{order id}           | 1000     | 1300    |
| 조리요청                  | 배달요청                  | /deliver/{order id}              | 1000     | 1400    |

그림으로 표현하면 아래와 같다.

![img](./assets/trace.png)



- 또한, 이러한 Tracing정보에는 4가지 종류의 timestamp가 있어 소요된 시간까지 측정할 수 있다.
  - CS(Client Start) -> SR(Server Received) => SS(Server Sent) => CR(Client Received)

- 이러한 Trace정보를 Zipkin과 같은 분산 트랜잭션 추적 시스템으로 송부하면 그래픽하게 트래픽의 흐름을 볼 수 있다.

- Trace정보를 Zipkin에 송부하기 위해서는 Zipkin client를 적용해야 한다.



![img](./assets/img2.png)

 

### 4.10.3 Zipkin 설치

- Zipkin은 분산 트랜잭션 추적을 위한 오픈소스소프트웨어이며 트위터에서 개발하였고 비슷한 제품으로는 Jaeger가 있다.

- Zipkin 아키텍처는 아래와 같다.



![img](https://blog.kakaocdn.net/dn/o0y9z/btqXgoJFibK/qmSiVsKsNVvPtyr1daNZ21/img.png)



- Zipkin client library: 각 어플리케이션에 설치되어 Zipkin collector로 Trace정보를 송부함

- Collector: Trace정보 수집기

- Storge: In-memory(테스트 목적), 소규모는 MySQL, 운영환경에는 ElasticSearch나 Cassandra를 사용

- API(Query Service): Web UI의 요청을 받아 Storage를 검색하여 결과를 리턴

- Web UI: 대시보드 UI 제공

### 4.10.4 설정

- pom.xml

```xml
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-sleuth</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-sleuth-zipkin</artifactId>
		</dependency>		
```

### 4.10.5 구성

- application.yaml

```
spring:
  sleuth: 
    sampler:
      probability: 1.0
  zipkin:
    base-url: http://localhost:9411
```

- probability는 트래픽의 몇%를 zipkin으로 보낼것인지를 정의한다. 0.5면 50%만 보내는 설정이다.
- zipkin.base-url은 zipkin service의 서비스명과 포트이다. 



# 5. Piot Application

## 5.1  개요

- 네이티브 아키텍처의 기술 스택을 이용한 Pilot Application을 구현하려고 한다. Pilot Application은 카탈로그 서비스, 사용자 서비스, 주문 서비스라는 3개의 마이크로서비스로 구성되어 있는 간단한 E-commerce 애플리케이션이다.

- 구현의 간단함을 위해 각 마이크로서비스는 RESTful API를 제공하는 비즈니스 로직만 구현하였다. 제공하는 비즈니스 로직은 다음과 같다.

  ◾  카탈로그 서비스: 상품의 목록을 확인, 상품의 재고수량 업데이트

  ◾  사용자 서비스: 사용자 등록, 상품의 정보를 확인 후 상품 주문

  ◾  주문 서비스: 상품의 주문과 주문된 상품 확인

- 다음은 Pilot Application의 서비스 흐름을 나타낸 그림이다.

 

![image-20220817110036458](./assets/image-20220817110036458.png)

Pilot Application의 서비스 흐름



- Piot Application은 아래의 Git을 통해 다운로드 받을수 있다.

  ```shell
  git clone https://github.com/kirobo77/cloudnative.git
  ```

  

## 5.2  사전 준비 작업

### 5.2.1  기술 스택

- Piot Application은 Spirng Cloud 기반에서 동작하는 마이크로서비스이며 DDD 관점에 따라 3개의 마이크로 서비스로 구성되어 있다.

- CloudNative에서는 컨테이너가 핵심요소이지만 해당 실습에서는 Spring Boot를 활용한 어플리케이션 개발에 중점을 두며 해당 영역은 별도로 다루지 않는다.
  - 컨테이너 환경에서는 Spring Cloud의 기술요소를 대체할 수 있는 여러 훌륭한 솔루션이 존재한다.

| 기술 스택                  | 참고                                   |
| -------------------------- | -------------------------------------- |
| Spring Cloud Gateway       | istio Ingress Gateway, Kong, KrakenD.. |
| Spring MVC                 |                                        |
| Spring Cloud Config        | Consul, Valut                          |
| Spring Cloud Eureka        | Zookeeper, Etcd, Consul, Eureka        |
| Spring Cloud OpenFeign     |                                        |
| Spring Cloud Sleuth/Zipkin | istio, Jaeger/Kiali                    |
| Spring Data JDBC           |                                        |
| Spring Data Redis          |                                        |
| Spring with Kafka          |                                        |
| Spring Cloud Stream        |                                        |

 

## 5.2.2  마이크로서비스

- 마이크로서비스는 카탈로그 서비스, 사용자 서비스, 주문 서비스 3개로 구성되어 있으며, Java 17 언어를 이용한 Spring Boot(v2.7.2) + Spring Cloud(2021.0.3) API를 이용하여 개발되었다.

| 서비스 명       | URI                                                       | HTTP  Method | 설명           |
| --------------- | --------------------------------------------------------- | ------------ | -------------- |
| User service    | http://localhost:50001/user-ms/users                      | POST         | 사용자 추가    |
|                 | http://localhost:50001/user-ms/users/**{userId}**         | GET          | 사용자 확인    |
| Catalog Service | http://localhost:50003/catalog-ms/catalogs                | GET          | 카테고리 목록  |
| Order service   | http://localhost:50002/order-ms/users/**{userId}**/orders | GET          | 상품 주문 확인 |
|                 | http://localhost:50002/order-ms/users/**{userId}**/orders | POST         | 상품 주문      |

 

## 5.3  시스템 구성도

 

![](./assets/demo-archi.png)

 

## 5.4 미들웨어 구동

### 5.4.1 Zookeeper 실행

```
cd D:\cloudnative\infra\kafka_2.13-3.2.1\bin\windows
.\zookeeper-server-start.bat ..\..\config\zookeeper.properties
```

### 5.4.2 Kafka 실행

```
cd D:\cloudnative\infra\kafka_2.13-3.2.1\bin\windows
.\kafka-server-start.bat ..\..\config\server.properties
#.\kafka-topics.bat --create --bootstrap-server localhost:9092 --topic example-kafka-test
```

### 5.4.3 Redis 실행

```
cd D:\cloudnative\infra\Redis-x64-3.2.100
.\redis-server.exe .\redis.windows.conf
```

### 5.4.4 Zipkin 실행

```
cd D:\cloudnative\infra\zipkin
java -jar zipkin.jar
```



## 5.5  상품 주문 프로세스

### 5.5.1 사용자 등록

> http://localhost/users-ms/users
>

- 먼저, 사용자 정보를 등록하도록 하자. 사용자 서비스에 다음과 같은 정보를 HTTP Post Method로 전달하도록 하자. Kubernetes의 서비스를 NodePort로 설정하였고 각 Node에 설치된 컨테이너의 포트는 다를 수 있기 때문에 직접 확인 후에 접속하도록 하자.

```
{
“name”: “test”, “email”: “test@test.com”, “pwd”: “test1234”
}
```

 ![image-20220823095439646](./assets/image-20220823095439646.png)



### 5.5.2 사용자 조회

> http://localhost/users-ms/users/a3af7fbc-b06c-4edb-95e9-b0efa0abc94b/
>

- 사용자 정보가 성공적으로 등록 되었다면, Response Body에서 “userId”를 확인할 수 있다. 반환된 “userId” 값을 이용하여 등록된 사용자의 정보를 확인해 보도록 하자. 

- 아직 사용자가 주문한 상품이 없기 때문에, “orders” 항목은 비어 있는 것을 확인할 수 있다.

![image-20220823095520646](./assets/image-20220823095520646.png)



### 5.4.3 상품 목록 조회

> http://localhost/catalogs-ms/catalogs
>

- 다음으로 카탈로그 서비스로부터 등록된 상품의 목록을 가져오도록 하자.

![image-20220823095529925](./assets/image-20220823095529925.png)

 

### 5.4.4 상품 주문

> http://localhost/orders-ms/users/a3af7fbc-b06c-4edb-95e9- b0efa0abc94b/orders
>

- 상품 조회를 통해 “productId(상품 코드)”, “unitPrice(상품 단가)”와 “qty(수량)”을 확인 한 다음, 주문하고자 하는 상품의 정보를 전달하여 상품 주문 요청을 하도록 하자.

```
{
“productId”: “CATALOG-0001”,
“qty”: 10,
“unitPrice”: 1500
}
```

 ![image-20220823095605044](./assets/image-20220823095605044.png)

주문한 상품의 내용을 주문 서비스가 사용하고 있는 데이터베이스에서 확인해 보면 다음과 같다.

 ![image-20220823095613029](./assets/image-20220823095613029.png)

[그림 5-16] 주문 서비스의 H2 데이터베이스 조회 화면



### 5.4.5 상품 주문 조회

> http://localhost/orders-ms/users/a3af7fbc-b06c-4edb-95e9- b0efa0abc94b/orders

- 조금 전에 주문했던 내용은 상품 주문 조회 서비스를 통해 확인할 수 있다. 각 사용자 별로 주문한 내용을 확인해 볼 수 있다.

 ![image-20220823095640224](./assets/image-20220823095640224.png)

 

 

## 5.5  MicroService간 통신

- Pilot Application은 상품 주문이 요청되었을 때, 주문 서비스로 사용자가 요청한 주문 정보를 전달하게 된다. 
- 그리고 사용자 서비스에서 사용자의 정보 확인 시, 해당 사용자가 주문한 상품의 목록을 확인할 수 있는데 여기에서 사용자 마이크로서비스로부터 주문 마이크로서비스로 주문 상품 목록을 요청하게 된다. 
- 이 작업을 위해, Pilot Application에서는 Spring Cloud의 FeignClient를 이용하여 사용자 서비스에서 주문 서비스로 정보를 요청하고 있다. 

 <img src="./assets/image-20220823095858586.png" alt="image-20220823095858586" style="zoom:150%;" />



## 5.6  Messaging Service를 통한 데이터 동기화

- 사용자가 상품을 주문할 때 입력했던 주문 수량의 정보는 Kafka Messaging Service를 통해 카탈로그 서비스에 전달된다. 주문 서비스에서 직접 카탈로그 서비스로 정보를 전달하는 것이 아니라, Kafka Messaging Service를 통해 메시지가 전달되며, 이 때 메시지를 전달하는 측을 Publisher, 메시지를 받는 측을 Consumer라고 한다.

- Publisher는 어떤 Consumer가 메시지를 받는지 상관하지 않고 Kafka Messaging Service에게만 메시지를 전달하면되고, Consumer도 어떤 Publisher가 보냈는지 상관하지 않고 Kafka Messaging Service로부터 메시지를 받게 된다.

![image-20220823095917308](./assets/image-20220823095917308.png)
![image-20220823095934001](./assets/image-20220823095934001.png)

- Consumer에서는 Kafka Messaging Service에 메시지가 전달되면 이벤트에 의해 메시지를 전달 받게 된다. 카탈로그 서비스에서 KafkaListener라는 어노테이션을 등록하여 Kafka Messaging Service로부터 메시지를 받겠다고 선언하면, Kafka의 토픽에 전달된 메시지가 있을 경우 바로 전달 받을 수 있게 된다.

![image-20220823095943587](./assets/image-20220823095943587.png)
![image-20220823095952822](./assets/image-20220823095952822.png)

- 카탈로그 서비스에서는 Kafka Messaging Service로부터 전달 받은 주문 상품의 수량만큼 해당 상품의 수량을 업데이트 하게 된다.

- 다시 한 번 카탈로그 서비스의 상품 목록을 확인해 보면 다음과 같이 수량이 변경된 것을 확인할 수 있다.
  ![image-20220823100009787](./assets/image-20220823100009787.png)



## 5.7 Cache Service를 통한 데이터 조회

- 카탈로그 서비스는 사용자가 상품을 주문할때 수량이 업데이트 된다. 카탈로그 서비스는 일반적인  E-commerce 애플리케이션에서 가장 많이 호출되는 서비스이다.

- 모노리틱 환경에서 카탈로그 서비스에 대량으로 조회 시 애플리케이션 전체에 영향을 끼치는 SPOF(*single point* of *failure*)가 된다.

- MSA 환경에는 카탈로그 서비스에 대량으로 조회가 발생하더라eh 해당 서비스에 대한 장애 발생되고 애플리케이션 전체로 전파되는것이 차단된다.

- 이 부분이 MSA가 가지는 주요 장점 중에 하나이다.

- 또한 카탈로그 서비스에 부하발생 시 Cahce 등을 활용하여 해당 서비스의 성능을 향상시킬 수 있는 환경을 제공한다.

* 특히 컨테이너환경에서는 Replica 를 활용하여 서비스에 대한 수평확장을 통한 성능향상을 제공한다.



## 5.8 Git을 통한 외부 설정 관리

- 각각의 마이크로서비스는 Spring Cloud Config 서버를 통해 설정을 외부에서 제어할 수 있다. 이를 통해 마이크로서비스별 설정에 대해 중앙에서 관리할 수 있고 실행환경에서 설정정보를 동적으로 제어할 수 있는 기능을 제공한다. 

```
https://github.com/kirobo77/config.git
```



## 5.9 테스트

| 서비스 명       | URI                                                          | 설명                        |
| --------------- | ------------------------------------------------------------ | --------------------------- |
| User service    | http://localhost:50001/swagger-ui/index.html                 | API 테스트                  |
|                 | http://localhost:50001/h2-console/                           | H2 DB 콘솔                  |
|                 | curl -X 'POST' 'http://localhost:50001/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신               |
|                 | http://localhost:50001/actuator/circuitbreakerevents         | circuit breaker 이벤트 조회 |
| Catalog Service | http://localhost:50003/swagger-ui/index.html                 | API 테스트                  |
|                 | http://localhost:50003/h2-console/                           | H2 DB 콘솔                  |
|                 | curl -X 'POST' 'http://localhost:50003/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신               |
| Order service   | http://localhost:50002/swagger-ui/index.html                 | API 테스트                  |
|                 | http://localhost:50002/h2-console/                           | H2 DB 콘솔                  |
|                 | curl -X 'POST' 'http://localhost:50002/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신               |
| API Gateway     | curl -X 'GET' 'http://localhost/user-ms/users' -H 'accept: */*' curl -X 'GET' 'http://localhost/catalog-ms/catalogs' -H 'accept: */*' curl -X 'GET' 'http://localhost/order-ms/orders' -H 'accept: */*' | API 테스트                  |
| Eureka          | http://localhost:8761/                                       | 서비스 디스커버리 확인      |
| Zipkin          | http://localhost:9411/                                       | 서비스 추적                 |
| Config          | http://localhost:8888/order-ws/local http://localhost:8888/catalog-ws/local http://localhost:8888/user-ws/local | 프로퍼티 조회               |
| Redis           | cd D:\cloudnative\infra\Redis-x64-3.2.100 .\redis-server.exe .\redis.windows.conf .\redis-cli.exe keys * del key "catalogs::SimpleKey []" | Redis 키 조회/삭제          |



## 5.10 리펙토링(Exam)

### 5.10.1 Hexagonal 아키텍처(Port and Adapter 패턴)에 맞게 서비스를 리펙토링

- Apater, Port, Domain 영역으로 패키지를 분리해 본다.



### 5.10.2 성능을 고려하여 서비스를 개선

- Kafka 및 Redis cache를 활용하여 API에 대한 성능을 개선해 본다.



### 5.10.3 JUNIT을 활용한 테스트코드를 작성

- Junit을 사용하여 단위/통합테스트를 작성해 본다.

#### 5.10.3.1 @WebMvcTest

- Application Context 완전하게 Start 시키지 않고 web layer를 테스트 하고 싶을 때 @WebMvcTest를 사용하는 것을 고려한다. Present Layer 관련 컴포넌트만 스캔을 한다.

- Service, Repository dependency가 필요한 경우에는 @MockBean으로 주입받아 테스트를 진행 한다. 

- @SpringBootTest의 경우 모든 빈을 로드하기 때문에 테스트 구동 시간이 오래 걸리고, 테스트 단위가 크기 때문에 디버깅이 어려울 수 있다. Controller 레이어만 슬라이스 테스트 하고 싶을 때에는 @WebMvcTest를 쓰는게 유용하다.

- **특정 Controller 클래스만 지정하여 스캔**

  ```java
  @WebMvcTest(ContentController.class)
  class ContentControllerTest {
  ...
  }
  ```

#### 5.10.3.2 MockMvc

-  애플리케이션을 배포하지 않고도, 서버의 MVC 동작을 테스트 할 수 있는 라이브러리이며 Controller 레이어 단위테스트에 많이 사용된다. 

​     **GET 메소드 테스트**

  ```java
  //when & then
  mockMvc.perform(get("/contents"))
          .andExpect(status().isOk())
          .andExpect(content().contentTypeCompatibleWith(MediaType.APPLICATION_JSON))
          .andExpect(jsonPath("$.data").isArray())
          .andExpect(jsonPath("$.data[0].name").value("user1"))
          .andExpect(jsonPath("$.data[0].title").value("title1"))
          .andExpect(jsonPath("$.code").value(ErrorCode.OK.getCode()))
          .andExpect(jsonPath("$.message").value(ErrorCode.OK.getMessage()));
  ```

#### 5.10.3.3 @MockBean

- 가짜 객체를 생성하며 해당 비지니스의 단위 테스트에만 집중할 수 있도록 도와준다. 

- DB에 대한 Repoistory를  MockBean으로 선언하였고, 서비스 내 의존성 연결고리를 신경 안써도 되며 서비스의 호출, 결과를 임의로 조작하여 테스트를 지원한다.

```java
@RunWith(SpringRunner.class)
public class MockBeanAnnotationIntegrationTest {
    
    @MockBean
    UserRepository mockRepository;
    
    @Autowired
    ApplicationContext context;
    
    @Test
    public void givenCountMethodMocked_WhenCountInvoked_ThenMockValueReturned() {
        Mockito.when(mockRepository.count()).thenReturn(123L);

        UserRepository userRepoFromContext = context.getBean(UserRepository.class);
        long userCount = userRepoFromContext.count();

        Assert.assertEquals(123L, userCount);
        Mockito.verify(mockRepository).count();
    }
}
```



### 5.10.4 컨테이너 환경에서 서비스를 실행

#### 5.10.4.1 JIB

- Jib을 통한 도커 이미지 생성(https://github.com/GoogleContainerTools/jib)
- docker daemon 없이도 Java 애플리케이션을 Docker 혹은 OCI 규격의 컨테이너 이미지를 만들어 주는 도구
-  maven 플러그인 및 gradle 으로 제공되어 Dockerfile 에 대한 별도의 지식 없이도 애플리케이션을 이미지로 만들 수 있다. 
- JAR를 single layer 로 빌드하는 것이 아니라, Application을 종속성, 리소스, 클래스 등으로 좀 더 세분화 한 Layer로 빌드하여 코드 변경시 증분만을 변경할 수 있어 이미지 생성속도가 빠르다.

#### 5.10.4.2 설정

```xml
  			<plugin>
  				<groupId>com.google.cloud.tools</groupId>
  				<artifactId>jib-maven-plugin</artifactId>
  				<version>3.2.1</version>
  				<configuration>
  					<from>
  						<image>eclipse-temurin:17-jre-alpine</image>
  					</from>
  					<to>
  						<image>msa/order-ws</image>
  					</to>
  					<allowInsecureRegistries>true</allowInsecureRegistries>
  				</configuration>
  			</plugin>
```

#### 5.10.4.3 실행

- jib가 제공하는 Maven의  phase와 goal은 아래의 3가지이다.
  - jib:build : image 를 빌드한다, <to> 의 경로로 push한다.
  - jib:dockerBuild : image를 빌드한다, docker daemon에 image를 등록한다. docker가 실행환경에 있어야 한다.
  - jib:buildTar : image를 빌드한다. tar 파일로 만든다. docker CLI에서 load하여 사용할 수 있다.

```shell
mvn clean compile jib:dockerBuild
```

